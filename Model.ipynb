{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfea3a15-4b40-4063-9f57-208b52b40ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67dd8810-6c65-47a7-ae05-53a0139fad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.embedding = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, ntoken)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def get_src_mask(self, size) -> Tensor:\n",
    "        \"\"\"\n",
    "        Generates a squeare matrix where the each row allows one word more to be seen\n",
    "        src shape: [seq_length,batch_size]\n",
    "        then mask shape: [seq_length,seq_length]\n",
    "        e.g. for seq_length = 5,\n",
    "        output = \n",
    "        [[0., 0., 0., 0., 0.],\n",
    "        [-inf, 0., 0., 0., 0.],\n",
    "        [-inf, -inf, 0., 0., 0.],\n",
    "        [-inf, -inf, -inf, 0., 0.],\n",
    "        [-inf, -inf, -inf, -inf, 0.]]\n",
    "\n",
    "        with shape [5,5]\n",
    "        \n",
    "        \"\"\"\n",
    "        mask = torch.triu(torch.ones(size, size) == 1) # Upper triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[seq_len, batch_size]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        src_length,batch_size = src.size()\n",
    "        src_mask = self.get_src_mask(src_length)\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src,mask = src_mask,is_causal = True)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3804dbe5-ea22-4113-b669-bff480be492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "704c7c1a-40ec-48fa-a1aa-569186e6b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b7bdcb-0947-40e9-a226-47937dace90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 256\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape ``[full_seq_len, batch_size]``\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape ``[seq_len, batch_size]`` and\n",
    "        target has shape ``[seq_len * batch_size]``\n",
    "    \"\"\"\n",
    "    data = source[: -1, i: i+bptt]\n",
    "    target = source[1:, i: i+bptt]\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ba3249-3a24-4419-b095-c935d364173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = ZipFile(\"order_products__prior.csv.zip\")\n",
    "train_df = pd.read_csv(zf.extract(\"order_products__prior.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4986ec60-4b6e-4908-b4cb-44c0de393270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32434489 entries, 0 to 32434488\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Dtype\n",
      "---  ------             -----\n",
      " 0   order_id           int64\n",
      " 1   product_id         int64\n",
      " 2   add_to_cart_order  int64\n",
      " 3   reordered          int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 989.8 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c616db6e-8498-4016-93d9-8b52cf46d760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>33120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28985</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9327</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>45918</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>30035</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434484</th>\n",
       "      <td>3421083</td>\n",
       "      <td>39678</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434485</th>\n",
       "      <td>3421083</td>\n",
       "      <td>11352</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434486</th>\n",
       "      <td>3421083</td>\n",
       "      <td>4600</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434487</th>\n",
       "      <td>3421083</td>\n",
       "      <td>24852</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434488</th>\n",
       "      <td>3421083</td>\n",
       "      <td>5020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32434489 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_id  product_id  add_to_cart_order  reordered\n",
       "0                2       33120                  1          1\n",
       "1                2       28985                  2          1\n",
       "2                2        9327                  3          0\n",
       "3                2       45918                  4          1\n",
       "4                2       30035                  5          0\n",
       "...            ...         ...                ...        ...\n",
       "32434484   3421083       39678                  6          1\n",
       "32434485   3421083       11352                  7          0\n",
       "32434486   3421083        4600                  8          0\n",
       "32434487   3421083       24852                  9          1\n",
       "32434488   3421083        5020                 10          1\n",
       "\n",
       "[32434489 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2218664d-562a-4f5d-9d00-7739b2f1d78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id\n",
       "24852    472565\n",
       "13176    379450\n",
       "21137    264683\n",
       "21903    241921\n",
       "47209    213584\n",
       "          ...  \n",
       "20178      2849\n",
       "20588      2848\n",
       "45842      2848\n",
       "24834      2847\n",
       "17747      2847\n",
       "Name: count, Length: 1999, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.product_id.value_counts()[:1999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db7e28f0-cef5-4439-98eb-3a79530e86e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6601896826553981"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate percentage of data included in top k sales products\n",
    "train_df.product_id.value_counts()[:1999].values.sum()/train_df.product_id.value_counts().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f338d6-74ce-4801-9bf7-f676a5301757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract top k prodcuts\n",
    "top_products = train_df.product_id.value_counts()[:1999].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b6a18b6-633e-48dc-8f77-988f9cce07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the top k products into indices from 1 to k\n",
    "product_to_idx = {product:i for i,product in enumerate(top_products,start=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05a0533b-c0e2-4e47-b49b-92f59e64c58e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{24852: 1,\n",
       " 13176: 2,\n",
       " 21137: 3,\n",
       " 21903: 4,\n",
       " 47209: 5,\n",
       " 47766: 6,\n",
       " 47626: 7,\n",
       " 16797: 8,\n",
       " 26209: 9,\n",
       " 27845: 10,\n",
       " 27966: 11,\n",
       " 22935: 12,\n",
       " 24964: 13,\n",
       " 45007: 14,\n",
       " 39275: 15,\n",
       " 49683: 16,\n",
       " 28204: 17,\n",
       " 5876: 18,\n",
       " 8277: 19,\n",
       " 40706: 20,\n",
       " 4920: 21,\n",
       " 30391: 22,\n",
       " 45066: 23,\n",
       " 42265: 24,\n",
       " 49235: 25,\n",
       " 44632: 26,\n",
       " 19057: 27,\n",
       " 4605: 28,\n",
       " 37646: 29,\n",
       " 21616: 30,\n",
       " 17794: 31,\n",
       " 27104: 32,\n",
       " 30489: 33,\n",
       " 31717: 34,\n",
       " 27086: 35,\n",
       " 44359: 36,\n",
       " 28985: 37,\n",
       " 46979: 38,\n",
       " 8518: 39,\n",
       " 41950: 40,\n",
       " 26604: 41,\n",
       " 5077: 42,\n",
       " 34126: 43,\n",
       " 22035: 44,\n",
       " 39877: 45,\n",
       " 35951: 46,\n",
       " 43352: 47,\n",
       " 10749: 48,\n",
       " 19660: 49,\n",
       " 9076: 50,\n",
       " 21938: 51,\n",
       " 43961: 52,\n",
       " 24184: 53,\n",
       " 34969: 54,\n",
       " 46667: 55,\n",
       " 48679: 56,\n",
       " 25890: 57,\n",
       " 31506: 58,\n",
       " 12341: 59,\n",
       " 39928: 60,\n",
       " 24838: 61,\n",
       " 5450: 62,\n",
       " 22825: 63,\n",
       " 5785: 64,\n",
       " 35221: 65,\n",
       " 28842: 66,\n",
       " 33731: 67,\n",
       " 27521: 68,\n",
       " 44142: 69,\n",
       " 33198: 70,\n",
       " 8174: 71,\n",
       " 20114: 72,\n",
       " 8424: 73,\n",
       " 27344: 74,\n",
       " 11520: 75,\n",
       " 29487: 76,\n",
       " 18465: 77,\n",
       " 28199: 78,\n",
       " 15290: 79,\n",
       " 46906: 80,\n",
       " 9839: 81,\n",
       " 27156: 82,\n",
       " 3957: 83,\n",
       " 43122: 84,\n",
       " 23909: 85,\n",
       " 34358: 86,\n",
       " 4799: 87,\n",
       " 9387: 88,\n",
       " 16759: 89,\n",
       " 196: 90,\n",
       " 42736: 91,\n",
       " 38689: 92,\n",
       " 4210: 93,\n",
       " 41787: 94,\n",
       " 41220: 95,\n",
       " 47144: 96,\n",
       " 7781: 97,\n",
       " 33000: 98,\n",
       " 20995: 99,\n",
       " 21709: 100,\n",
       " 19678: 101,\n",
       " 40604: 102,\n",
       " 30233: 103,\n",
       " 34243: 104,\n",
       " 37687: 105,\n",
       " 24489: 106,\n",
       " 42828: 107,\n",
       " 5479: 108,\n",
       " 432: 109,\n",
       " 6184: 110,\n",
       " 16185: 111,\n",
       " 42768: 112,\n",
       " 17948: 113,\n",
       " 33754: 114,\n",
       " 19348: 115,\n",
       " 8193: 116,\n",
       " 26369: 117,\n",
       " 42585: 118,\n",
       " 14992: 119,\n",
       " 14947: 120,\n",
       " 22963: 121,\n",
       " 1463: 122,\n",
       " 28849: 123,\n",
       " 8021: 124,\n",
       " 25659: 125,\n",
       " 21405: 126,\n",
       " 46676: 127,\n",
       " 31343: 128,\n",
       " 41844: 129,\n",
       " 38293: 130,\n",
       " 42701: 131,\n",
       " 43789: 132,\n",
       " 36011: 133,\n",
       " 5025: 134,\n",
       " 39475: 135,\n",
       " 43295: 136,\n",
       " 11777: 137,\n",
       " 20842: 138,\n",
       " 32689: 139,\n",
       " 32655: 140,\n",
       " 2295: 141,\n",
       " 46802: 142,\n",
       " 13870: 143,\n",
       " 25146: 144,\n",
       " 18531: 145,\n",
       " 5212: 146,\n",
       " 31553: 147,\n",
       " 39408: 148,\n",
       " 260: 149,\n",
       " 36695: 150,\n",
       " 10246: 151,\n",
       " 24830: 152,\n",
       " 38383: 153,\n",
       " 43768: 154,\n",
       " 1940: 155,\n",
       " 11182: 156,\n",
       " 18523: 157,\n",
       " 18362: 158,\n",
       " 21288: 159,\n",
       " 6046: 160,\n",
       " 44683: 161,\n",
       " 29987: 162,\n",
       " 890: 163,\n",
       " 38777: 164,\n",
       " 43772: 165,\n",
       " 23734: 166,\n",
       " 7948: 167,\n",
       " 30450: 168,\n",
       " 38456: 169,\n",
       " 46969: 170,\n",
       " 44910: 171,\n",
       " 47734: 172,\n",
       " 38159: 173,\n",
       " 26620: 174,\n",
       " 47672: 175,\n",
       " 4957: 176,\n",
       " 26165: 177,\n",
       " 30776: 178,\n",
       " 44987: 179,\n",
       " 35939: 180,\n",
       " 14678: 181,\n",
       " 16349: 182,\n",
       " 28289: 183,\n",
       " 29447: 184,\n",
       " 44422: 185,\n",
       " 40310: 186,\n",
       " 16953: 187,\n",
       " 23375: 188,\n",
       " 33787: 189,\n",
       " 19048: 190,\n",
       " 2078: 191,\n",
       " 13984: 192,\n",
       " 41290: 193,\n",
       " 23165: 194,\n",
       " 32864: 195,\n",
       " 17600: 196,\n",
       " 39812: 197,\n",
       " 8859: 198,\n",
       " 48364: 199,\n",
       " 33120: 200,\n",
       " 31683: 201,\n",
       " 26940: 202,\n",
       " 28465: 203,\n",
       " 35108: 204,\n",
       " 26283: 205,\n",
       " 37158: 206,\n",
       " 37067: 207,\n",
       " 18370: 208,\n",
       " 45: 209,\n",
       " 41665: 210,\n",
       " 35547: 211,\n",
       " 3952: 212,\n",
       " 10957: 213,\n",
       " 2086: 214,\n",
       " 2966: 215,\n",
       " 43154: 216,\n",
       " 24799: 217,\n",
       " 40571: 218,\n",
       " 10132: 219,\n",
       " 43713: 220,\n",
       " 40396: 221,\n",
       " 18027: 222,\n",
       " 45535: 223,\n",
       " 1158: 224,\n",
       " 25931: 225,\n",
       " 7021: 226,\n",
       " 38739: 227,\n",
       " 13629: 228,\n",
       " 42450: 229,\n",
       " 20119: 230,\n",
       " 15937: 231,\n",
       " 42342: 232,\n",
       " 32478: 233,\n",
       " 48745: 234,\n",
       " 45633: 235,\n",
       " 21019: 236,\n",
       " 34050: 237,\n",
       " 34448: 238,\n",
       " 48205: 239,\n",
       " 39619: 240,\n",
       " 17461: 241,\n",
       " 45603: 242,\n",
       " 30169: 243,\n",
       " 31040: 244,\n",
       " 38400: 245,\n",
       " 13646: 246,\n",
       " 36865: 247,\n",
       " 40174: 248,\n",
       " 21267: 249,\n",
       " 17872: 250,\n",
       " 5818: 251,\n",
       " 26790: 252,\n",
       " 39984: 253,\n",
       " 14084: 254,\n",
       " 23288: 255,\n",
       " 21376: 256,\n",
       " 32734: 257,\n",
       " 33768: 258,\n",
       " 37766: 259,\n",
       " 46654: 260,\n",
       " 12206: 261,\n",
       " 329: 262,\n",
       " 28934: 263,\n",
       " 6187: 264,\n",
       " 6348: 265,\n",
       " 39993: 266,\n",
       " 18441: 267,\n",
       " 5646: 268,\n",
       " 25340: 269,\n",
       " 43086: 270,\n",
       " 6104: 271,\n",
       " 42356: 272,\n",
       " 48775: 273,\n",
       " 651: 274,\n",
       " 10673: 275,\n",
       " 47977: 276,\n",
       " 19508: 277,\n",
       " 39180: 278,\n",
       " 40709: 279,\n",
       " 19677: 280,\n",
       " 10017: 281,\n",
       " 27336: 282,\n",
       " 13535: 283,\n",
       " 13829: 284,\n",
       " 42244: 285,\n",
       " 11782: 286,\n",
       " 27695: 287,\n",
       " 36070: 288,\n",
       " 28156: 289,\n",
       " 6873: 290,\n",
       " 49520: 291,\n",
       " 49383: 292,\n",
       " 8571: 293,\n",
       " 24561: 294,\n",
       " 13249: 295,\n",
       " 49075: 296,\n",
       " 16083: 297,\n",
       " 24024: 298,\n",
       " 40545: 299,\n",
       " 40199: 300,\n",
       " 30720: 301,\n",
       " 17795: 302,\n",
       " 25588: 303,\n",
       " 35921: 304,\n",
       " 17122: 305,\n",
       " 11422: 306,\n",
       " 8670: 307,\n",
       " 31915: 308,\n",
       " 35561: 309,\n",
       " 42445: 310,\n",
       " 14233: 311,\n",
       " 7963: 312,\n",
       " 17706: 313,\n",
       " 3599: 314,\n",
       " 21295: 315,\n",
       " 44449: 316,\n",
       " 36550: 317,\n",
       " 19019: 318,\n",
       " 30827: 319,\n",
       " 20082: 320,\n",
       " 35042: 321,\n",
       " 25466: 322,\n",
       " 33401: 323,\n",
       " 1511: 324,\n",
       " 42625: 325,\n",
       " 5194: 326,\n",
       " 8048: 327,\n",
       " 23537: 328,\n",
       " 2825: 329,\n",
       " 16965: 330,\n",
       " 38928: 331,\n",
       " 21195: 332,\n",
       " 19706: 333,\n",
       " 18288: 334,\n",
       " 13380: 335,\n",
       " 7751: 336,\n",
       " 15872: 337,\n",
       " 4562: 338,\n",
       " 9339: 339,\n",
       " 22395: 340,\n",
       " 38164: 341,\n",
       " 46720: 342,\n",
       " 40723: 343,\n",
       " 15902: 344,\n",
       " 35140: 345,\n",
       " 4472: 346,\n",
       " 3376: 347,\n",
       " 13166: 348,\n",
       " 29662: 349,\n",
       " 2855: 350,\n",
       " 28993: 351,\n",
       " 7175: 352,\n",
       " 13575: 353,\n",
       " 13740: 354,\n",
       " 12916: 355,\n",
       " 40516: 356,\n",
       " 45200: 357,\n",
       " 7503: 358,\n",
       " 5782: 359,\n",
       " 19691: 360,\n",
       " 5134: 361,\n",
       " 40332: 362,\n",
       " 12456: 363,\n",
       " 21174: 364,\n",
       " 5258: 365,\n",
       " 10644: 366,\n",
       " 39561: 367,\n",
       " 4421: 368,\n",
       " 33129: 369,\n",
       " 44765: 370,\n",
       " 20955: 371,\n",
       " 46584: 372,\n",
       " 22124: 373,\n",
       " 44570: 374,\n",
       " 3464: 375,\n",
       " 13198: 376,\n",
       " 43662: 377,\n",
       " 10070: 378,\n",
       " 32691: 379,\n",
       " 7559: 380,\n",
       " 37710: 381,\n",
       " 36735: 382,\n",
       " 35898: 383,\n",
       " 37029: 384,\n",
       " 34262: 385,\n",
       " 1025: 386,\n",
       " 18918: 387,\n",
       " 42719: 388,\n",
       " 11408: 389,\n",
       " 18234: 390,\n",
       " 44560: 391,\n",
       " 23029: 392,\n",
       " 45123: 393,\n",
       " 3896: 394,\n",
       " 9092: 395,\n",
       " 28745: 396,\n",
       " 18811: 397,\n",
       " 26384: 398,\n",
       " 35503: 399,\n",
       " 35628: 400,\n",
       " 47141: 401,\n",
       " 28476: 402,\n",
       " 25138: 403,\n",
       " 21386: 404,\n",
       " 47042: 405,\n",
       " 46820: 406,\n",
       " 21292: 407,\n",
       " 11140: 408,\n",
       " 21573: 409,\n",
       " 38768: 410,\n",
       " 17949: 411,\n",
       " 1999: 412,\n",
       " 14197: 413,\n",
       " 46616: 414,\n",
       " 32433: 415,\n",
       " 47759: 416,\n",
       " 37220: 417,\n",
       " 39947: 418,\n",
       " 24954: 419,\n",
       " 41065: 420,\n",
       " 21333: 421,\n",
       " 25824: 422,\n",
       " 48628: 423,\n",
       " 1194: 424,\n",
       " 43504: 425,\n",
       " 44628: 426,\n",
       " 5456: 427,\n",
       " 38273: 428,\n",
       " 15613: 429,\n",
       " 35535: 430,\n",
       " 15424: 431,\n",
       " 27548: 432,\n",
       " 24841: 433,\n",
       " 39190: 434,\n",
       " 27730: 435,\n",
       " 42110: 436,\n",
       " 29307: 437,\n",
       " 14161: 438,\n",
       " 49175: 439,\n",
       " 14462: 440,\n",
       " 31066: 441,\n",
       " 16696: 442,\n",
       " 26800: 443,\n",
       " 9825: 444,\n",
       " 5322: 445,\n",
       " 27744: 446,\n",
       " 8309: 447,\n",
       " 11005: 448,\n",
       " 41588: 449,\n",
       " 11068: 450,\n",
       " 27796: 451,\n",
       " 27325: 452,\n",
       " 2228: 453,\n",
       " 7969: 454,\n",
       " 22474: 455,\n",
       " 9020: 456,\n",
       " 16521: 457,\n",
       " 3298: 458,\n",
       " 5769: 459,\n",
       " 1244: 460,\n",
       " 13517: 461,\n",
       " 27323: 462,\n",
       " 2452: 463,\n",
       " 28601: 464,\n",
       " 2314: 465,\n",
       " 21927: 466,\n",
       " 32177: 467,\n",
       " 13733: 468,\n",
       " 12980: 469,\n",
       " 15261: 470,\n",
       " 19173: 471,\n",
       " 21872: 472,\n",
       " 20345: 473,\n",
       " 41658: 474,\n",
       " 18479: 475,\n",
       " 49191: 476,\n",
       " 20734: 477,\n",
       " 22849: 478,\n",
       " 4086: 479,\n",
       " 36724: 480,\n",
       " 17316: 481,\n",
       " 5373: 482,\n",
       " 26497: 483,\n",
       " 20738: 484,\n",
       " 44799: 485,\n",
       " 20574: 486,\n",
       " 5161: 487,\n",
       " 35914: 488,\n",
       " 22959: 489,\n",
       " 37524: 490,\n",
       " 6948: 491,\n",
       " 12845: 492,\n",
       " 4656: 493,\n",
       " 17758: 494,\n",
       " 47630: 495,\n",
       " 26348: 496,\n",
       " 25513: 497,\n",
       " 33055: 498,\n",
       " 34584: 499,\n",
       " 11712: 500,\n",
       " 21543: 501,\n",
       " 15649: 502,\n",
       " 35887: 503,\n",
       " 31720: 504,\n",
       " 18926: 505,\n",
       " 40198: 506,\n",
       " 48697: 507,\n",
       " 49131: 508,\n",
       " 39108: 509,\n",
       " 6740: 510,\n",
       " 18963: 511,\n",
       " 31651: 512,\n",
       " 23543: 513,\n",
       " 45104: 514,\n",
       " 5612: 515,\n",
       " 36316: 516,\n",
       " 40377: 517,\n",
       " 30406: 518,\n",
       " 7500: 519,\n",
       " 11512: 520,\n",
       " 44008: 521,\n",
       " 9755: 522,\n",
       " 30639: 523,\n",
       " 44661: 524,\n",
       " 36082: 525,\n",
       " 18656: 526,\n",
       " 23516: 527,\n",
       " 24221: 528,\n",
       " 40063: 529,\n",
       " 10305: 530,\n",
       " 46069: 531,\n",
       " 32303: 532,\n",
       " 13838: 533,\n",
       " 12576: 534,\n",
       " 32403: 535,\n",
       " 12409: 536,\n",
       " 45504: 537,\n",
       " 12872: 538,\n",
       " 43129: 539,\n",
       " 28427: 540,\n",
       " 2450: 541,\n",
       " 39581: 542,\n",
       " 30353: 543,\n",
       " 25718: 544,\n",
       " 11759: 545,\n",
       " 31215: 546,\n",
       " 34668: 547,\n",
       " 47912: 548,\n",
       " 48559: 549,\n",
       " 46842: 550,\n",
       " 30696: 551,\n",
       " 26317: 552,\n",
       " 29941: 553,\n",
       " 25640: 554,\n",
       " 14715: 555,\n",
       " 27690: 556,\n",
       " 6631: 557,\n",
       " 28553: 558,\n",
       " 15392: 559,\n",
       " 43875: 560,\n",
       " 2091: 561,\n",
       " 35163: 562,\n",
       " 1529: 563,\n",
       " 36929: 564,\n",
       " 32747: 565,\n",
       " 41400: 566,\n",
       " 38996: 567,\n",
       " 39558: 568,\n",
       " 13263: 569,\n",
       " 25753: 570,\n",
       " 5550: 571,\n",
       " 31981: 572,\n",
       " 24009: 573,\n",
       " 7628: 574,\n",
       " 14218: 575,\n",
       " 11576: 576,\n",
       " 45948: 577,\n",
       " 23236: 578,\n",
       " 46149: 579,\n",
       " 5652: 580,\n",
       " 14852: 581,\n",
       " 17652: 582,\n",
       " 49533: 583,\n",
       " 12099: 584,\n",
       " 31766: 585,\n",
       " 14129: 586,\n",
       " 22142: 587,\n",
       " 43394: 588,\n",
       " 20940: 589,\n",
       " 11440: 590,\n",
       " 17284: 591,\n",
       " 4461: 592,\n",
       " 14651: 593,\n",
       " 34217: 594,\n",
       " 14633: 595,\n",
       " 7156: 596,\n",
       " 28928: 597,\n",
       " 46886: 598,\n",
       " 41149: 599,\n",
       " 32465: 600,\n",
       " 24810: 601,\n",
       " 29926: 602,\n",
       " 10831: 603,\n",
       " 38772: 604,\n",
       " 48395: 605,\n",
       " 6489: 606,\n",
       " 781: 607,\n",
       " 42557: 608,\n",
       " 10912: 609,\n",
       " 47788: 610,\n",
       " 32429: 611,\n",
       " 2120: 612,\n",
       " 34466: 613,\n",
       " 18594: 614,\n",
       " 40268: 615,\n",
       " 311: 616,\n",
       " 2326: 617,\n",
       " 35004: 618,\n",
       " 7485: 619,\n",
       " 8138: 620,\n",
       " 29675: 621,\n",
       " 9515: 622,\n",
       " 10385: 623,\n",
       " 5240: 624,\n",
       " 33043: 625,\n",
       " 2846: 626,\n",
       " 3142: 627,\n",
       " 12276: 628,\n",
       " 5068: 629,\n",
       " 16616: 630,\n",
       " 38200: 631,\n",
       " 36772: 632,\n",
       " 4367: 633,\n",
       " 19006: 634,\n",
       " 29127: 635,\n",
       " 31433: 636,\n",
       " 4793: 637,\n",
       " 34134: 638,\n",
       " 12745: 639,\n",
       " 13292: 640,\n",
       " 48104: 641,\n",
       " 37119: 642,\n",
       " 44234: 643,\n",
       " 17224: 644,\n",
       " 47792: 645,\n",
       " 3583: 646,\n",
       " 46522: 647,\n",
       " 23405: 648,\n",
       " 44479: 649,\n",
       " 16254: 650,\n",
       " 8555: 651,\n",
       " 34530: 652,\n",
       " 37065: 653,\n",
       " 22025: 654,\n",
       " 16145: 655,\n",
       " 9808: 656,\n",
       " 19816: 657,\n",
       " 4942: 658,\n",
       " 38650: 659,\n",
       " 365: 660,\n",
       " 14901: 661,\n",
       " 39040: 662,\n",
       " 30305: 663,\n",
       " 1700: 664,\n",
       " 33548: 665,\n",
       " 14870: 666,\n",
       " 42460: 667,\n",
       " 1408: 668,\n",
       " 32566: 669,\n",
       " 20580: 670,\n",
       " 16262: 671,\n",
       " 16617: 672,\n",
       " 17429: 673,\n",
       " 45646: 674,\n",
       " 10504: 675,\n",
       " 42495: 676,\n",
       " 23579: 677,\n",
       " 40910: 678,\n",
       " 27243: 679,\n",
       " 44156: 680,\n",
       " 10603: 681,\n",
       " 7644: 682,\n",
       " 31869: 683,\n",
       " 12384: 684,\n",
       " 13083: 685,\n",
       " 48857: 686,\n",
       " 46226: 687,\n",
       " 45763: 688,\n",
       " 2962: 689,\n",
       " 14168: 690,\n",
       " 23622: 691,\n",
       " 28278: 692,\n",
       " 12614: 693,\n",
       " 24759: 694,\n",
       " 9337: 695,\n",
       " 31964: 696,\n",
       " 29370: 697,\n",
       " 3990: 698,\n",
       " 5460: 699,\n",
       " 38890: 700,\n",
       " 8955: 701,\n",
       " 21009: 702,\n",
       " 26128: 703,\n",
       " 33716: 704,\n",
       " 7131: 705,\n",
       " 8479: 706,\n",
       " 1090: 707,\n",
       " 31759: 708,\n",
       " 39922: 709,\n",
       " 17616: 710,\n",
       " 10621: 711,\n",
       " 22504: 712,\n",
       " 3481: 713,\n",
       " 46692: 714,\n",
       " 24535: 715,\n",
       " 18880: 716,\n",
       " 28373: 717,\n",
       " 17341: 718,\n",
       " 6532: 719,\n",
       " 32455: 720,\n",
       " 20754: 721,\n",
       " 23765: 722,\n",
       " 4724: 723,\n",
       " 16823: 724,\n",
       " 17835: 725,\n",
       " 25005: 726,\n",
       " 36389: 727,\n",
       " 30949: 728,\n",
       " 8230: 729,\n",
       " 30442: 730,\n",
       " 49610: 731,\n",
       " 26131: 732,\n",
       " 21417: 733,\n",
       " 16589: 734,\n",
       " 23233: 735,\n",
       " 9124: 736,\n",
       " 19156: 737,\n",
       " 36086: 738,\n",
       " 28123: 739,\n",
       " 45063: 740,\n",
       " 17008: 741,\n",
       " 33572: 742,\n",
       " 28535: 743,\n",
       " 1215: 744,\n",
       " 2611: 745,\n",
       " 38944: 746,\n",
       " 11352: 747,\n",
       " 29553: 748,\n",
       " 45747: 749,\n",
       " 8087: 750,\n",
       " 24082: 751,\n",
       " 31562: 752,\n",
       " 6287: 753,\n",
       " 7521: 754,\n",
       " 9741: 755,\n",
       " 19894: 756,\n",
       " 38028: 757,\n",
       " 41544: 758,\n",
       " 21614: 759,\n",
       " 4138: 760,\n",
       " 40593: 761,\n",
       " 31805: 762,\n",
       " 14467: 763,\n",
       " 37825: 764,\n",
       " 33352: 765,\n",
       " 12606: 766,\n",
       " 13819: 767,\n",
       " 48171: 768,\n",
       " 10814: 769,\n",
       " 17807: 770,\n",
       " 47029: 771,\n",
       " 47601: 772,\n",
       " 10032: 773,\n",
       " 13431: 774,\n",
       " 35383: 775,\n",
       " 18382: 776,\n",
       " 1559: 777,\n",
       " 42803: 778,\n",
       " 3020: 779,\n",
       " 46061: 780,\n",
       " 48595: 781,\n",
       " 45570: 782,\n",
       " 17630: 783,\n",
       " 23341: 784,\n",
       " 22888: 785,\n",
       " 23801: 786,\n",
       " 9366: 787,\n",
       " 17902: 788,\n",
       " 18434: 789,\n",
       " 18987: 790,\n",
       " 29594: 791,\n",
       " 581: 792,\n",
       " 19003: 793,\n",
       " 20632: 794,\n",
       " 43631: 795,\n",
       " 24382: 796,\n",
       " 15200: 797,\n",
       " 5449: 798,\n",
       " 38656: 799,\n",
       " 39121: 800,\n",
       " 17878: 801,\n",
       " 41319: 802,\n",
       " 7916: 803,\n",
       " 25837: 804,\n",
       " 39097: 805,\n",
       " 19488: 806,\n",
       " 9421: 807,\n",
       " 8490: 808,\n",
       " 11461: 809,\n",
       " 27360: 810,\n",
       " 24010: 811,\n",
       " 6615: 812,\n",
       " 34551: 813,\n",
       " 5337: 814,\n",
       " 9550: 815,\n",
       " 37011: 816,\n",
       " 46650: 817,\n",
       " 34: 818,\n",
       " 31371: 819,\n",
       " 41259: 820,\n",
       " 41540: 821,\n",
       " 47866: 822,\n",
       " 7806: 823,\n",
       " 21497: 824,\n",
       " 34234: 825,\n",
       " 47492: 826,\n",
       " 46900: 827,\n",
       " 6347: 828,\n",
       " 44514: 829,\n",
       " 12427: 830,\n",
       " 11136: 831,\n",
       " 33290: 832,\n",
       " 31338: 833,\n",
       " 41276: 834,\n",
       " 14778: 835,\n",
       " 46049: 836,\n",
       " 19478: 837,\n",
       " 4149: 838,\n",
       " 46041: 839,\n",
       " 42240: 840,\n",
       " 38274: 841,\n",
       " 14999: 842,\n",
       " 8467: 843,\n",
       " 22260: 844,\n",
       " 23296: 845,\n",
       " 248: 846,\n",
       " 33636: 847,\n",
       " 45013: 848,\n",
       " 10761: 849,\n",
       " 27307: 850,\n",
       " 28785: 851,\n",
       " 29615: 852,\n",
       " 2180: 853,\n",
       " 43643: 854,\n",
       " 44471: 855,\n",
       " 41593: 856,\n",
       " 2716: 857,\n",
       " 29898: 858,\n",
       " 16290: 859,\n",
       " 9327: 860,\n",
       " 49247: 861,\n",
       " 24390: 862,\n",
       " 47890: 863,\n",
       " 10473: 864,\n",
       " 38544: 865,\n",
       " 35233: 866,\n",
       " 14897: 867,\n",
       " 19049: 868,\n",
       " 3849: 869,\n",
       " 44375: 870,\n",
       " 8239: 871,\n",
       " 47357: 872,\n",
       " 44292: 873,\n",
       " 13802: 874,\n",
       " 36127: 875,\n",
       " 23645: 876,\n",
       " 30480: 877,\n",
       " 18599: 878,\n",
       " 4006: 879,\n",
       " 25133: 880,\n",
       " 20899: 881,\n",
       " 20520: 882,\n",
       " 18564: 883,\n",
       " 5991: 884,\n",
       " 49111: 885,\n",
       " 45681: 886,\n",
       " 38444: 887,\n",
       " 5031: 888,\n",
       " 49478: 889,\n",
       " 45106: 890,\n",
       " 4137: 891,\n",
       " 40002: 892,\n",
       " 5618: 893,\n",
       " 4962: 894,\n",
       " 31663: 895,\n",
       " 33065: 896,\n",
       " 11941: 897,\n",
       " 18019: 898,\n",
       " 48726: 899,\n",
       " 5959: 900,\n",
       " 8736: 901,\n",
       " 14332: 902,\n",
       " 26914: 903,\n",
       " 23044: 904,\n",
       " 26047: 905,\n",
       " 13712: 906,\n",
       " 40348: 907,\n",
       " 20583: 908,\n",
       " 44310: 909,\n",
       " 25544: 910,\n",
       " 33846: 911,\n",
       " 47087: 912,\n",
       " 25705: 913,\n",
       " 47526: 914,\n",
       " 12312: 915,\n",
       " 22802: 916,\n",
       " 7054: 917,\n",
       " 22151: 918,\n",
       " 1695: 919,\n",
       " 46175: 920,\n",
       " 48057: 921,\n",
       " 13852: 922,\n",
       " 23554: 923,\n",
       " 17027: 924,\n",
       " 28597: 925,\n",
       " 32650: 926,\n",
       " 35336: 927,\n",
       " 49605: 928,\n",
       " 16283: 929,\n",
       " 35168: 930,\n",
       " 31927: 931,\n",
       " 28851: 932,\n",
       " 26882: 933,\n",
       " 45064: 934,\n",
       " 46088: 935,\n",
       " 28986: 936,\n",
       " 10369: 937,\n",
       " 43867: 938,\n",
       " 41757: 939,\n",
       " 41273: 940,\n",
       " 5250: 941,\n",
       " 47877: 942,\n",
       " 24850: 943,\n",
       " 27683: 944,\n",
       " 16249: 945,\n",
       " 19068: 946,\n",
       " 7952: 947,\n",
       " 38312: 948,\n",
       " 46346: 949,\n",
       " 3999: 950,\n",
       " 45866: 951,\n",
       " 9623: 952,\n",
       " 46206: 953,\n",
       " 32740: 954,\n",
       " 49215: 955,\n",
       " 13113: 956,\n",
       " 46990: 957,\n",
       " 34024: 958,\n",
       " 4796: 959,\n",
       " 25197: 960,\n",
       " 31640: 961,\n",
       " 11123: 962,\n",
       " 12254: 963,\n",
       " 37464: 964,\n",
       " 13702: 965,\n",
       " 9018: 966,\n",
       " 5491: 967,\n",
       " 18352: 968,\n",
       " 20919: 969,\n",
       " 26648: 970,\n",
       " 21162: 971,\n",
       " 43409: 972,\n",
       " 26629: 973,\n",
       " 44643: 974,\n",
       " 26172: 975,\n",
       " 10326: 976,\n",
       " 40229: 977,\n",
       " 32578: 978,\n",
       " 13885: 979,\n",
       " 12545: 980,\n",
       " 1468: 981,\n",
       " 39216: 982,\n",
       " 9598: 983,\n",
       " 10106: 984,\n",
       " 25256: 985,\n",
       " 2361: 986,\n",
       " 18670: 987,\n",
       " 22556: 988,\n",
       " 12797: 989,\n",
       " 2480: 990,\n",
       " 4945: 991,\n",
       " 13966: 992,\n",
       " 7746: 993,\n",
       " 35199: 994,\n",
       " 45190: 995,\n",
       " 18023: 996,\n",
       " 20378: 997,\n",
       " 43014: 998,\n",
       " 3339: 999,\n",
       " 27020: 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c21e9d-5353-4bf5-bf77-fdf6f53052c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#an reversed dictionary for decode the product indices\n",
    "idx_to_product = {value:key for (key,value) in product_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecdad17e-ef76-4ff8-ad12-4b0dd1d0c8a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 24852,\n",
       " 2: 13176,\n",
       " 3: 21137,\n",
       " 4: 21903,\n",
       " 5: 47209,\n",
       " 6: 47766,\n",
       " 7: 47626,\n",
       " 8: 16797,\n",
       " 9: 26209,\n",
       " 10: 27845,\n",
       " 11: 27966,\n",
       " 12: 22935,\n",
       " 13: 24964,\n",
       " 14: 45007,\n",
       " 15: 39275,\n",
       " 16: 49683,\n",
       " 17: 28204,\n",
       " 18: 5876,\n",
       " 19: 8277,\n",
       " 20: 40706,\n",
       " 21: 4920,\n",
       " 22: 30391,\n",
       " 23: 45066,\n",
       " 24: 42265,\n",
       " 25: 49235,\n",
       " 26: 44632,\n",
       " 27: 19057,\n",
       " 28: 4605,\n",
       " 29: 37646,\n",
       " 30: 21616,\n",
       " 31: 17794,\n",
       " 32: 27104,\n",
       " 33: 30489,\n",
       " 34: 31717,\n",
       " 35: 27086,\n",
       " 36: 44359,\n",
       " 37: 28985,\n",
       " 38: 46979,\n",
       " 39: 8518,\n",
       " 40: 41950,\n",
       " 41: 26604,\n",
       " 42: 5077,\n",
       " 43: 34126,\n",
       " 44: 22035,\n",
       " 45: 39877,\n",
       " 46: 35951,\n",
       " 47: 43352,\n",
       " 48: 10749,\n",
       " 49: 19660,\n",
       " 50: 9076,\n",
       " 51: 21938,\n",
       " 52: 43961,\n",
       " 53: 24184,\n",
       " 54: 34969,\n",
       " 55: 46667,\n",
       " 56: 48679,\n",
       " 57: 25890,\n",
       " 58: 31506,\n",
       " 59: 12341,\n",
       " 60: 39928,\n",
       " 61: 24838,\n",
       " 62: 5450,\n",
       " 63: 22825,\n",
       " 64: 5785,\n",
       " 65: 35221,\n",
       " 66: 28842,\n",
       " 67: 33731,\n",
       " 68: 27521,\n",
       " 69: 44142,\n",
       " 70: 33198,\n",
       " 71: 8174,\n",
       " 72: 20114,\n",
       " 73: 8424,\n",
       " 74: 27344,\n",
       " 75: 11520,\n",
       " 76: 29487,\n",
       " 77: 18465,\n",
       " 78: 28199,\n",
       " 79: 15290,\n",
       " 80: 46906,\n",
       " 81: 9839,\n",
       " 82: 27156,\n",
       " 83: 3957,\n",
       " 84: 43122,\n",
       " 85: 23909,\n",
       " 86: 34358,\n",
       " 87: 4799,\n",
       " 88: 9387,\n",
       " 89: 16759,\n",
       " 90: 196,\n",
       " 91: 42736,\n",
       " 92: 38689,\n",
       " 93: 4210,\n",
       " 94: 41787,\n",
       " 95: 41220,\n",
       " 96: 47144,\n",
       " 97: 7781,\n",
       " 98: 33000,\n",
       " 99: 20995,\n",
       " 100: 21709,\n",
       " 101: 19678,\n",
       " 102: 40604,\n",
       " 103: 30233,\n",
       " 104: 34243,\n",
       " 105: 37687,\n",
       " 106: 24489,\n",
       " 107: 42828,\n",
       " 108: 5479,\n",
       " 109: 432,\n",
       " 110: 6184,\n",
       " 111: 16185,\n",
       " 112: 42768,\n",
       " 113: 17948,\n",
       " 114: 33754,\n",
       " 115: 19348,\n",
       " 116: 8193,\n",
       " 117: 26369,\n",
       " 118: 42585,\n",
       " 119: 14992,\n",
       " 120: 14947,\n",
       " 121: 22963,\n",
       " 122: 1463,\n",
       " 123: 28849,\n",
       " 124: 8021,\n",
       " 125: 25659,\n",
       " 126: 21405,\n",
       " 127: 46676,\n",
       " 128: 31343,\n",
       " 129: 41844,\n",
       " 130: 38293,\n",
       " 131: 42701,\n",
       " 132: 43789,\n",
       " 133: 36011,\n",
       " 134: 5025,\n",
       " 135: 39475,\n",
       " 136: 43295,\n",
       " 137: 11777,\n",
       " 138: 20842,\n",
       " 139: 32689,\n",
       " 140: 32655,\n",
       " 141: 2295,\n",
       " 142: 46802,\n",
       " 143: 13870,\n",
       " 144: 25146,\n",
       " 145: 18531,\n",
       " 146: 5212,\n",
       " 147: 31553,\n",
       " 148: 39408,\n",
       " 149: 260,\n",
       " 150: 36695,\n",
       " 151: 10246,\n",
       " 152: 24830,\n",
       " 153: 38383,\n",
       " 154: 43768,\n",
       " 155: 1940,\n",
       " 156: 11182,\n",
       " 157: 18523,\n",
       " 158: 18362,\n",
       " 159: 21288,\n",
       " 160: 6046,\n",
       " 161: 44683,\n",
       " 162: 29987,\n",
       " 163: 890,\n",
       " 164: 38777,\n",
       " 165: 43772,\n",
       " 166: 23734,\n",
       " 167: 7948,\n",
       " 168: 30450,\n",
       " 169: 38456,\n",
       " 170: 46969,\n",
       " 171: 44910,\n",
       " 172: 47734,\n",
       " 173: 38159,\n",
       " 174: 26620,\n",
       " 175: 47672,\n",
       " 176: 4957,\n",
       " 177: 26165,\n",
       " 178: 30776,\n",
       " 179: 44987,\n",
       " 180: 35939,\n",
       " 181: 14678,\n",
       " 182: 16349,\n",
       " 183: 28289,\n",
       " 184: 29447,\n",
       " 185: 44422,\n",
       " 186: 40310,\n",
       " 187: 16953,\n",
       " 188: 23375,\n",
       " 189: 33787,\n",
       " 190: 19048,\n",
       " 191: 2078,\n",
       " 192: 13984,\n",
       " 193: 41290,\n",
       " 194: 23165,\n",
       " 195: 32864,\n",
       " 196: 17600,\n",
       " 197: 39812,\n",
       " 198: 8859,\n",
       " 199: 48364,\n",
       " 200: 33120,\n",
       " 201: 31683,\n",
       " 202: 26940,\n",
       " 203: 28465,\n",
       " 204: 35108,\n",
       " 205: 26283,\n",
       " 206: 37158,\n",
       " 207: 37067,\n",
       " 208: 18370,\n",
       " 209: 45,\n",
       " 210: 41665,\n",
       " 211: 35547,\n",
       " 212: 3952,\n",
       " 213: 10957,\n",
       " 214: 2086,\n",
       " 215: 2966,\n",
       " 216: 43154,\n",
       " 217: 24799,\n",
       " 218: 40571,\n",
       " 219: 10132,\n",
       " 220: 43713,\n",
       " 221: 40396,\n",
       " 222: 18027,\n",
       " 223: 45535,\n",
       " 224: 1158,\n",
       " 225: 25931,\n",
       " 226: 7021,\n",
       " 227: 38739,\n",
       " 228: 13629,\n",
       " 229: 42450,\n",
       " 230: 20119,\n",
       " 231: 15937,\n",
       " 232: 42342,\n",
       " 233: 32478,\n",
       " 234: 48745,\n",
       " 235: 45633,\n",
       " 236: 21019,\n",
       " 237: 34050,\n",
       " 238: 34448,\n",
       " 239: 48205,\n",
       " 240: 39619,\n",
       " 241: 17461,\n",
       " 242: 45603,\n",
       " 243: 30169,\n",
       " 244: 31040,\n",
       " 245: 38400,\n",
       " 246: 13646,\n",
       " 247: 36865,\n",
       " 248: 40174,\n",
       " 249: 21267,\n",
       " 250: 17872,\n",
       " 251: 5818,\n",
       " 252: 26790,\n",
       " 253: 39984,\n",
       " 254: 14084,\n",
       " 255: 23288,\n",
       " 256: 21376,\n",
       " 257: 32734,\n",
       " 258: 33768,\n",
       " 259: 37766,\n",
       " 260: 46654,\n",
       " 261: 12206,\n",
       " 262: 329,\n",
       " 263: 28934,\n",
       " 264: 6187,\n",
       " 265: 6348,\n",
       " 266: 39993,\n",
       " 267: 18441,\n",
       " 268: 5646,\n",
       " 269: 25340,\n",
       " 270: 43086,\n",
       " 271: 6104,\n",
       " 272: 42356,\n",
       " 273: 48775,\n",
       " 274: 651,\n",
       " 275: 10673,\n",
       " 276: 47977,\n",
       " 277: 19508,\n",
       " 278: 39180,\n",
       " 279: 40709,\n",
       " 280: 19677,\n",
       " 281: 10017,\n",
       " 282: 27336,\n",
       " 283: 13535,\n",
       " 284: 13829,\n",
       " 285: 42244,\n",
       " 286: 11782,\n",
       " 287: 27695,\n",
       " 288: 36070,\n",
       " 289: 28156,\n",
       " 290: 6873,\n",
       " 291: 49520,\n",
       " 292: 49383,\n",
       " 293: 8571,\n",
       " 294: 24561,\n",
       " 295: 13249,\n",
       " 296: 49075,\n",
       " 297: 16083,\n",
       " 298: 24024,\n",
       " 299: 40545,\n",
       " 300: 40199,\n",
       " 301: 30720,\n",
       " 302: 17795,\n",
       " 303: 25588,\n",
       " 304: 35921,\n",
       " 305: 17122,\n",
       " 306: 11422,\n",
       " 307: 8670,\n",
       " 308: 31915,\n",
       " 309: 35561,\n",
       " 310: 42445,\n",
       " 311: 14233,\n",
       " 312: 7963,\n",
       " 313: 17706,\n",
       " 314: 3599,\n",
       " 315: 21295,\n",
       " 316: 44449,\n",
       " 317: 36550,\n",
       " 318: 19019,\n",
       " 319: 30827,\n",
       " 320: 20082,\n",
       " 321: 35042,\n",
       " 322: 25466,\n",
       " 323: 33401,\n",
       " 324: 1511,\n",
       " 325: 42625,\n",
       " 326: 5194,\n",
       " 327: 8048,\n",
       " 328: 23537,\n",
       " 329: 2825,\n",
       " 330: 16965,\n",
       " 331: 38928,\n",
       " 332: 21195,\n",
       " 333: 19706,\n",
       " 334: 18288,\n",
       " 335: 13380,\n",
       " 336: 7751,\n",
       " 337: 15872,\n",
       " 338: 4562,\n",
       " 339: 9339,\n",
       " 340: 22395,\n",
       " 341: 38164,\n",
       " 342: 46720,\n",
       " 343: 40723,\n",
       " 344: 15902,\n",
       " 345: 35140,\n",
       " 346: 4472,\n",
       " 347: 3376,\n",
       " 348: 13166,\n",
       " 349: 29662,\n",
       " 350: 2855,\n",
       " 351: 28993,\n",
       " 352: 7175,\n",
       " 353: 13575,\n",
       " 354: 13740,\n",
       " 355: 12916,\n",
       " 356: 40516,\n",
       " 357: 45200,\n",
       " 358: 7503,\n",
       " 359: 5782,\n",
       " 360: 19691,\n",
       " 361: 5134,\n",
       " 362: 40332,\n",
       " 363: 12456,\n",
       " 364: 21174,\n",
       " 365: 5258,\n",
       " 366: 10644,\n",
       " 367: 39561,\n",
       " 368: 4421,\n",
       " 369: 33129,\n",
       " 370: 44765,\n",
       " 371: 20955,\n",
       " 372: 46584,\n",
       " 373: 22124,\n",
       " 374: 44570,\n",
       " 375: 3464,\n",
       " 376: 13198,\n",
       " 377: 43662,\n",
       " 378: 10070,\n",
       " 379: 32691,\n",
       " 380: 7559,\n",
       " 381: 37710,\n",
       " 382: 36735,\n",
       " 383: 35898,\n",
       " 384: 37029,\n",
       " 385: 34262,\n",
       " 386: 1025,\n",
       " 387: 18918,\n",
       " 388: 42719,\n",
       " 389: 11408,\n",
       " 390: 18234,\n",
       " 391: 44560,\n",
       " 392: 23029,\n",
       " 393: 45123,\n",
       " 394: 3896,\n",
       " 395: 9092,\n",
       " 396: 28745,\n",
       " 397: 18811,\n",
       " 398: 26384,\n",
       " 399: 35503,\n",
       " 400: 35628,\n",
       " 401: 47141,\n",
       " 402: 28476,\n",
       " 403: 25138,\n",
       " 404: 21386,\n",
       " 405: 47042,\n",
       " 406: 46820,\n",
       " 407: 21292,\n",
       " 408: 11140,\n",
       " 409: 21573,\n",
       " 410: 38768,\n",
       " 411: 17949,\n",
       " 412: 1999,\n",
       " 413: 14197,\n",
       " 414: 46616,\n",
       " 415: 32433,\n",
       " 416: 47759,\n",
       " 417: 37220,\n",
       " 418: 39947,\n",
       " 419: 24954,\n",
       " 420: 41065,\n",
       " 421: 21333,\n",
       " 422: 25824,\n",
       " 423: 48628,\n",
       " 424: 1194,\n",
       " 425: 43504,\n",
       " 426: 44628,\n",
       " 427: 5456,\n",
       " 428: 38273,\n",
       " 429: 15613,\n",
       " 430: 35535,\n",
       " 431: 15424,\n",
       " 432: 27548,\n",
       " 433: 24841,\n",
       " 434: 39190,\n",
       " 435: 27730,\n",
       " 436: 42110,\n",
       " 437: 29307,\n",
       " 438: 14161,\n",
       " 439: 49175,\n",
       " 440: 14462,\n",
       " 441: 31066,\n",
       " 442: 16696,\n",
       " 443: 26800,\n",
       " 444: 9825,\n",
       " 445: 5322,\n",
       " 446: 27744,\n",
       " 447: 8309,\n",
       " 448: 11005,\n",
       " 449: 41588,\n",
       " 450: 11068,\n",
       " 451: 27796,\n",
       " 452: 27325,\n",
       " 453: 2228,\n",
       " 454: 7969,\n",
       " 455: 22474,\n",
       " 456: 9020,\n",
       " 457: 16521,\n",
       " 458: 3298,\n",
       " 459: 5769,\n",
       " 460: 1244,\n",
       " 461: 13517,\n",
       " 462: 27323,\n",
       " 463: 2452,\n",
       " 464: 28601,\n",
       " 465: 2314,\n",
       " 466: 21927,\n",
       " 467: 32177,\n",
       " 468: 13733,\n",
       " 469: 12980,\n",
       " 470: 15261,\n",
       " 471: 19173,\n",
       " 472: 21872,\n",
       " 473: 20345,\n",
       " 474: 41658,\n",
       " 475: 18479,\n",
       " 476: 49191,\n",
       " 477: 20734,\n",
       " 478: 22849,\n",
       " 479: 4086,\n",
       " 480: 36724,\n",
       " 481: 17316,\n",
       " 482: 5373,\n",
       " 483: 26497,\n",
       " 484: 20738,\n",
       " 485: 44799,\n",
       " 486: 20574,\n",
       " 487: 5161,\n",
       " 488: 35914,\n",
       " 489: 22959,\n",
       " 490: 37524,\n",
       " 491: 6948,\n",
       " 492: 12845,\n",
       " 493: 4656,\n",
       " 494: 17758,\n",
       " 495: 47630,\n",
       " 496: 26348,\n",
       " 497: 25513,\n",
       " 498: 33055,\n",
       " 499: 34584,\n",
       " 500: 11712,\n",
       " 501: 21543,\n",
       " 502: 15649,\n",
       " 503: 35887,\n",
       " 504: 31720,\n",
       " 505: 18926,\n",
       " 506: 40198,\n",
       " 507: 48697,\n",
       " 508: 49131,\n",
       " 509: 39108,\n",
       " 510: 6740,\n",
       " 511: 18963,\n",
       " 512: 31651,\n",
       " 513: 23543,\n",
       " 514: 45104,\n",
       " 515: 5612,\n",
       " 516: 36316,\n",
       " 517: 40377,\n",
       " 518: 30406,\n",
       " 519: 7500,\n",
       " 520: 11512,\n",
       " 521: 44008,\n",
       " 522: 9755,\n",
       " 523: 30639,\n",
       " 524: 44661,\n",
       " 525: 36082,\n",
       " 526: 18656,\n",
       " 527: 23516,\n",
       " 528: 24221,\n",
       " 529: 40063,\n",
       " 530: 10305,\n",
       " 531: 46069,\n",
       " 532: 32303,\n",
       " 533: 13838,\n",
       " 534: 12576,\n",
       " 535: 32403,\n",
       " 536: 12409,\n",
       " 537: 45504,\n",
       " 538: 12872,\n",
       " 539: 43129,\n",
       " 540: 28427,\n",
       " 541: 2450,\n",
       " 542: 39581,\n",
       " 543: 30353,\n",
       " 544: 25718,\n",
       " 545: 11759,\n",
       " 546: 31215,\n",
       " 547: 34668,\n",
       " 548: 47912,\n",
       " 549: 48559,\n",
       " 550: 46842,\n",
       " 551: 30696,\n",
       " 552: 26317,\n",
       " 553: 29941,\n",
       " 554: 25640,\n",
       " 555: 14715,\n",
       " 556: 27690,\n",
       " 557: 6631,\n",
       " 558: 28553,\n",
       " 559: 15392,\n",
       " 560: 43875,\n",
       " 561: 2091,\n",
       " 562: 35163,\n",
       " 563: 1529,\n",
       " 564: 36929,\n",
       " 565: 32747,\n",
       " 566: 41400,\n",
       " 567: 38996,\n",
       " 568: 39558,\n",
       " 569: 13263,\n",
       " 570: 25753,\n",
       " 571: 5550,\n",
       " 572: 31981,\n",
       " 573: 24009,\n",
       " 574: 7628,\n",
       " 575: 14218,\n",
       " 576: 11576,\n",
       " 577: 45948,\n",
       " 578: 23236,\n",
       " 579: 46149,\n",
       " 580: 5652,\n",
       " 581: 14852,\n",
       " 582: 17652,\n",
       " 583: 49533,\n",
       " 584: 12099,\n",
       " 585: 31766,\n",
       " 586: 14129,\n",
       " 587: 22142,\n",
       " 588: 43394,\n",
       " 589: 20940,\n",
       " 590: 11440,\n",
       " 591: 17284,\n",
       " 592: 4461,\n",
       " 593: 14651,\n",
       " 594: 34217,\n",
       " 595: 14633,\n",
       " 596: 7156,\n",
       " 597: 28928,\n",
       " 598: 46886,\n",
       " 599: 41149,\n",
       " 600: 32465,\n",
       " 601: 24810,\n",
       " 602: 29926,\n",
       " 603: 10831,\n",
       " 604: 38772,\n",
       " 605: 48395,\n",
       " 606: 6489,\n",
       " 607: 781,\n",
       " 608: 42557,\n",
       " 609: 10912,\n",
       " 610: 47788,\n",
       " 611: 32429,\n",
       " 612: 2120,\n",
       " 613: 34466,\n",
       " 614: 18594,\n",
       " 615: 40268,\n",
       " 616: 311,\n",
       " 617: 2326,\n",
       " 618: 35004,\n",
       " 619: 7485,\n",
       " 620: 8138,\n",
       " 621: 29675,\n",
       " 622: 9515,\n",
       " 623: 10385,\n",
       " 624: 5240,\n",
       " 625: 33043,\n",
       " 626: 2846,\n",
       " 627: 3142,\n",
       " 628: 12276,\n",
       " 629: 5068,\n",
       " 630: 16616,\n",
       " 631: 38200,\n",
       " 632: 36772,\n",
       " 633: 4367,\n",
       " 634: 19006,\n",
       " 635: 29127,\n",
       " 636: 31433,\n",
       " 637: 4793,\n",
       " 638: 34134,\n",
       " 639: 12745,\n",
       " 640: 13292,\n",
       " 641: 48104,\n",
       " 642: 37119,\n",
       " 643: 44234,\n",
       " 644: 17224,\n",
       " 645: 47792,\n",
       " 646: 3583,\n",
       " 647: 46522,\n",
       " 648: 23405,\n",
       " 649: 44479,\n",
       " 650: 16254,\n",
       " 651: 8555,\n",
       " 652: 34530,\n",
       " 653: 37065,\n",
       " 654: 22025,\n",
       " 655: 16145,\n",
       " 656: 9808,\n",
       " 657: 19816,\n",
       " 658: 4942,\n",
       " 659: 38650,\n",
       " 660: 365,\n",
       " 661: 14901,\n",
       " 662: 39040,\n",
       " 663: 30305,\n",
       " 664: 1700,\n",
       " 665: 33548,\n",
       " 666: 14870,\n",
       " 667: 42460,\n",
       " 668: 1408,\n",
       " 669: 32566,\n",
       " 670: 20580,\n",
       " 671: 16262,\n",
       " 672: 16617,\n",
       " 673: 17429,\n",
       " 674: 45646,\n",
       " 675: 10504,\n",
       " 676: 42495,\n",
       " 677: 23579,\n",
       " 678: 40910,\n",
       " 679: 27243,\n",
       " 680: 44156,\n",
       " 681: 10603,\n",
       " 682: 7644,\n",
       " 683: 31869,\n",
       " 684: 12384,\n",
       " 685: 13083,\n",
       " 686: 48857,\n",
       " 687: 46226,\n",
       " 688: 45763,\n",
       " 689: 2962,\n",
       " 690: 14168,\n",
       " 691: 23622,\n",
       " 692: 28278,\n",
       " 693: 12614,\n",
       " 694: 24759,\n",
       " 695: 9337,\n",
       " 696: 31964,\n",
       " 697: 29370,\n",
       " 698: 3990,\n",
       " 699: 5460,\n",
       " 700: 38890,\n",
       " 701: 8955,\n",
       " 702: 21009,\n",
       " 703: 26128,\n",
       " 704: 33716,\n",
       " 705: 7131,\n",
       " 706: 8479,\n",
       " 707: 1090,\n",
       " 708: 31759,\n",
       " 709: 39922,\n",
       " 710: 17616,\n",
       " 711: 10621,\n",
       " 712: 22504,\n",
       " 713: 3481,\n",
       " 714: 46692,\n",
       " 715: 24535,\n",
       " 716: 18880,\n",
       " 717: 28373,\n",
       " 718: 17341,\n",
       " 719: 6532,\n",
       " 720: 32455,\n",
       " 721: 20754,\n",
       " 722: 23765,\n",
       " 723: 4724,\n",
       " 724: 16823,\n",
       " 725: 17835,\n",
       " 726: 25005,\n",
       " 727: 36389,\n",
       " 728: 30949,\n",
       " 729: 8230,\n",
       " 730: 30442,\n",
       " 731: 49610,\n",
       " 732: 26131,\n",
       " 733: 21417,\n",
       " 734: 16589,\n",
       " 735: 23233,\n",
       " 736: 9124,\n",
       " 737: 19156,\n",
       " 738: 36086,\n",
       " 739: 28123,\n",
       " 740: 45063,\n",
       " 741: 17008,\n",
       " 742: 33572,\n",
       " 743: 28535,\n",
       " 744: 1215,\n",
       " 745: 2611,\n",
       " 746: 38944,\n",
       " 747: 11352,\n",
       " 748: 29553,\n",
       " 749: 45747,\n",
       " 750: 8087,\n",
       " 751: 24082,\n",
       " 752: 31562,\n",
       " 753: 6287,\n",
       " 754: 7521,\n",
       " 755: 9741,\n",
       " 756: 19894,\n",
       " 757: 38028,\n",
       " 758: 41544,\n",
       " 759: 21614,\n",
       " 760: 4138,\n",
       " 761: 40593,\n",
       " 762: 31805,\n",
       " 763: 14467,\n",
       " 764: 37825,\n",
       " 765: 33352,\n",
       " 766: 12606,\n",
       " 767: 13819,\n",
       " 768: 48171,\n",
       " 769: 10814,\n",
       " 770: 17807,\n",
       " 771: 47029,\n",
       " 772: 47601,\n",
       " 773: 10032,\n",
       " 774: 13431,\n",
       " 775: 35383,\n",
       " 776: 18382,\n",
       " 777: 1559,\n",
       " 778: 42803,\n",
       " 779: 3020,\n",
       " 780: 46061,\n",
       " 781: 48595,\n",
       " 782: 45570,\n",
       " 783: 17630,\n",
       " 784: 23341,\n",
       " 785: 22888,\n",
       " 786: 23801,\n",
       " 787: 9366,\n",
       " 788: 17902,\n",
       " 789: 18434,\n",
       " 790: 18987,\n",
       " 791: 29594,\n",
       " 792: 581,\n",
       " 793: 19003,\n",
       " 794: 20632,\n",
       " 795: 43631,\n",
       " 796: 24382,\n",
       " 797: 15200,\n",
       " 798: 5449,\n",
       " 799: 38656,\n",
       " 800: 39121,\n",
       " 801: 17878,\n",
       " 802: 41319,\n",
       " 803: 7916,\n",
       " 804: 25837,\n",
       " 805: 39097,\n",
       " 806: 19488,\n",
       " 807: 9421,\n",
       " 808: 8490,\n",
       " 809: 11461,\n",
       " 810: 27360,\n",
       " 811: 24010,\n",
       " 812: 6615,\n",
       " 813: 34551,\n",
       " 814: 5337,\n",
       " 815: 9550,\n",
       " 816: 37011,\n",
       " 817: 46650,\n",
       " 818: 34,\n",
       " 819: 31371,\n",
       " 820: 41259,\n",
       " 821: 41540,\n",
       " 822: 47866,\n",
       " 823: 7806,\n",
       " 824: 21497,\n",
       " 825: 34234,\n",
       " 826: 47492,\n",
       " 827: 46900,\n",
       " 828: 6347,\n",
       " 829: 44514,\n",
       " 830: 12427,\n",
       " 831: 11136,\n",
       " 832: 33290,\n",
       " 833: 31338,\n",
       " 834: 41276,\n",
       " 835: 14778,\n",
       " 836: 46049,\n",
       " 837: 19478,\n",
       " 838: 4149,\n",
       " 839: 46041,\n",
       " 840: 42240,\n",
       " 841: 38274,\n",
       " 842: 14999,\n",
       " 843: 8467,\n",
       " 844: 22260,\n",
       " 845: 23296,\n",
       " 846: 248,\n",
       " 847: 33636,\n",
       " 848: 45013,\n",
       " 849: 10761,\n",
       " 850: 27307,\n",
       " 851: 28785,\n",
       " 852: 29615,\n",
       " 853: 2180,\n",
       " 854: 43643,\n",
       " 855: 44471,\n",
       " 856: 41593,\n",
       " 857: 2716,\n",
       " 858: 29898,\n",
       " 859: 16290,\n",
       " 860: 9327,\n",
       " 861: 49247,\n",
       " 862: 24390,\n",
       " 863: 47890,\n",
       " 864: 10473,\n",
       " 865: 38544,\n",
       " 866: 35233,\n",
       " 867: 14897,\n",
       " 868: 19049,\n",
       " 869: 3849,\n",
       " 870: 44375,\n",
       " 871: 8239,\n",
       " 872: 47357,\n",
       " 873: 44292,\n",
       " 874: 13802,\n",
       " 875: 36127,\n",
       " 876: 23645,\n",
       " 877: 30480,\n",
       " 878: 18599,\n",
       " 879: 4006,\n",
       " 880: 25133,\n",
       " 881: 20899,\n",
       " 882: 20520,\n",
       " 883: 18564,\n",
       " 884: 5991,\n",
       " 885: 49111,\n",
       " 886: 45681,\n",
       " 887: 38444,\n",
       " 888: 5031,\n",
       " 889: 49478,\n",
       " 890: 45106,\n",
       " 891: 4137,\n",
       " 892: 40002,\n",
       " 893: 5618,\n",
       " 894: 4962,\n",
       " 895: 31663,\n",
       " 896: 33065,\n",
       " 897: 11941,\n",
       " 898: 18019,\n",
       " 899: 48726,\n",
       " 900: 5959,\n",
       " 901: 8736,\n",
       " 902: 14332,\n",
       " 903: 26914,\n",
       " 904: 23044,\n",
       " 905: 26047,\n",
       " 906: 13712,\n",
       " 907: 40348,\n",
       " 908: 20583,\n",
       " 909: 44310,\n",
       " 910: 25544,\n",
       " 911: 33846,\n",
       " 912: 47087,\n",
       " 913: 25705,\n",
       " 914: 47526,\n",
       " 915: 12312,\n",
       " 916: 22802,\n",
       " 917: 7054,\n",
       " 918: 22151,\n",
       " 919: 1695,\n",
       " 920: 46175,\n",
       " 921: 48057,\n",
       " 922: 13852,\n",
       " 923: 23554,\n",
       " 924: 17027,\n",
       " 925: 28597,\n",
       " 926: 32650,\n",
       " 927: 35336,\n",
       " 928: 49605,\n",
       " 929: 16283,\n",
       " 930: 35168,\n",
       " 931: 31927,\n",
       " 932: 28851,\n",
       " 933: 26882,\n",
       " 934: 45064,\n",
       " 935: 46088,\n",
       " 936: 28986,\n",
       " 937: 10369,\n",
       " 938: 43867,\n",
       " 939: 41757,\n",
       " 940: 41273,\n",
       " 941: 5250,\n",
       " 942: 47877,\n",
       " 943: 24850,\n",
       " 944: 27683,\n",
       " 945: 16249,\n",
       " 946: 19068,\n",
       " 947: 7952,\n",
       " 948: 38312,\n",
       " 949: 46346,\n",
       " 950: 3999,\n",
       " 951: 45866,\n",
       " 952: 9623,\n",
       " 953: 46206,\n",
       " 954: 32740,\n",
       " 955: 49215,\n",
       " 956: 13113,\n",
       " 957: 46990,\n",
       " 958: 34024,\n",
       " 959: 4796,\n",
       " 960: 25197,\n",
       " 961: 31640,\n",
       " 962: 11123,\n",
       " 963: 12254,\n",
       " 964: 37464,\n",
       " 965: 13702,\n",
       " 966: 9018,\n",
       " 967: 5491,\n",
       " 968: 18352,\n",
       " 969: 20919,\n",
       " 970: 26648,\n",
       " 971: 21162,\n",
       " 972: 43409,\n",
       " 973: 26629,\n",
       " 974: 44643,\n",
       " 975: 26172,\n",
       " 976: 10326,\n",
       " 977: 40229,\n",
       " 978: 32578,\n",
       " 979: 13885,\n",
       " 980: 12545,\n",
       " 981: 1468,\n",
       " 982: 39216,\n",
       " 983: 9598,\n",
       " 984: 10106,\n",
       " 985: 25256,\n",
       " 986: 2361,\n",
       " 987: 18670,\n",
       " 988: 22556,\n",
       " 989: 12797,\n",
       " 990: 2480,\n",
       " 991: 4945,\n",
       " 992: 13966,\n",
       " 993: 7746,\n",
       " 994: 35199,\n",
       " 995: 45190,\n",
       " 996: 18023,\n",
       " 997: 20378,\n",
       " 998: 43014,\n",
       " 999: 3339,\n",
       " 1000: 27020,\n",
       " ...}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "558e0d7d-4aa2-4dbd-9383-3b7af3e0eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new columns \"idx\" and fill all non top k products with 0\n",
    "train_df['idx'] = train_df.product_id.map(product_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c55ba089-a343-45db-9abd-4bf9e4bd5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c866c0a-b297-4200-98b4-ae29b05a021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['idx'] = train_df.idx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2214bdff-b184-4b04-89b4-422f8a4ddf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>33120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28985</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9327</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>45918</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>30035</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>17794</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>40141</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1819</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>43668</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>33754</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>24838</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>17704</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>21903</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>17668</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>46667</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>17461</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>32665</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>46842</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>26434</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>39758</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id  product_id  add_to_cart_order  reordered   idx\n",
       "0          2       33120                  1          1   200\n",
       "1          2       28985                  2          1    37\n",
       "2          2        9327                  3          0   860\n",
       "3          2       45918                  4          1     0\n",
       "4          2       30035                  5          0     0\n",
       "5          2       17794                  6          1    31\n",
       "6          2       40141                  7          1     0\n",
       "7          2        1819                  8          1     0\n",
       "8          2       43668                  9          0     0\n",
       "9          3       33754                  1          1   114\n",
       "10         3       24838                  2          1    61\n",
       "11         3       17704                  3          1     0\n",
       "12         3       21903                  4          1     4\n",
       "13         3       17668                  5          1     0\n",
       "14         3       46667                  6          1    55\n",
       "15         3       17461                  7          1   241\n",
       "16         3       32665                  8          1  1107\n",
       "17         4       46842                  1          0   550\n",
       "18         4       26434                  2          1     0\n",
       "19         4       39758                  3          1     0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58d33346-91aa-4574-afe6-25b2dc7f2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = ZipFile(\"order_products__train.csv.zip\")\n",
    "val_df = pd.read_csv(zf.extract(\"order_products__train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec8f8db7-dd2e-4b58-a4cd-a721670ddf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1384617 entries, 0 to 1384616\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count    Dtype\n",
      "---  ------             --------------    -----\n",
      " 0   order_id           1384617 non-null  int64\n",
      " 1   product_id         1384617 non-null  int64\n",
      " 2   add_to_cart_order  1384617 non-null  int64\n",
      " 3   reordered          1384617 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 42.3 MB\n"
     ]
    }
   ],
   "source": [
    "val_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "226a7ebd-4df8-409b-af8d-2715dd02a5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11109</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>49683</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43633</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>13176</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>47209</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>22035</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>39612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "      <td>19660</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36</td>\n",
       "      <td>49235</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>43086</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>46620</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36</td>\n",
       "      <td>34497</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36</td>\n",
       "      <td>48679</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36</td>\n",
       "      <td>46979</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38</td>\n",
       "      <td>11913</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38</td>\n",
       "      <td>18159</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38</td>\n",
       "      <td>4461</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>38</td>\n",
       "      <td>21616</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>38</td>\n",
       "      <td>23622</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>38</td>\n",
       "      <td>32433</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>38</td>\n",
       "      <td>28842</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>38</td>\n",
       "      <td>42625</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>38</td>\n",
       "      <td>39693</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>96</td>\n",
       "      <td>20574</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>96</td>\n",
       "      <td>30391</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>96</td>\n",
       "      <td>40706</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>96</td>\n",
       "      <td>25610</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>96</td>\n",
       "      <td>27966</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>96</td>\n",
       "      <td>24489</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>96</td>\n",
       "      <td>39275</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>98</td>\n",
       "      <td>8859</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>98</td>\n",
       "      <td>19731</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>98</td>\n",
       "      <td>43654</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>98</td>\n",
       "      <td>13176</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>98</td>\n",
       "      <td>4357</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>98</td>\n",
       "      <td>37664</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>98</td>\n",
       "      <td>34065</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>98</td>\n",
       "      <td>35951</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>98</td>\n",
       "      <td>43560</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>98</td>\n",
       "      <td>9896</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>98</td>\n",
       "      <td>27509</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>98</td>\n",
       "      <td>15455</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>98</td>\n",
       "      <td>27966</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>98</td>\n",
       "      <td>47601</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>98</td>\n",
       "      <td>40396</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>98</td>\n",
       "      <td>35042</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>98</td>\n",
       "      <td>40986</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>98</td>\n",
       "      <td>1939</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id  product_id  add_to_cart_order  reordered\n",
       "0          1       49302                  1          1\n",
       "1          1       11109                  2          1\n",
       "2          1       10246                  3          0\n",
       "3          1       49683                  4          0\n",
       "4          1       43633                  5          1\n",
       "5          1       13176                  6          0\n",
       "6          1       47209                  7          0\n",
       "7          1       22035                  8          1\n",
       "8         36       39612                  1          0\n",
       "9         36       19660                  2          1\n",
       "10        36       49235                  3          0\n",
       "11        36       43086                  4          1\n",
       "12        36       46620                  5          1\n",
       "13        36       34497                  6          1\n",
       "14        36       48679                  7          1\n",
       "15        36       46979                  8          1\n",
       "16        38       11913                  1          0\n",
       "17        38       18159                  2          0\n",
       "18        38        4461                  3          0\n",
       "19        38       21616                  4          1\n",
       "20        38       23622                  5          0\n",
       "21        38       32433                  6          0\n",
       "22        38       28842                  7          0\n",
       "23        38       42625                  8          0\n",
       "24        38       39693                  9          0\n",
       "25        96       20574                  1          1\n",
       "26        96       30391                  2          0\n",
       "27        96       40706                  3          1\n",
       "28        96       25610                  4          0\n",
       "29        96       27966                  5          1\n",
       "30        96       24489                  6          1\n",
       "31        96       39275                  7          1\n",
       "32        98        8859                  1          1\n",
       "33        98       19731                  2          1\n",
       "34        98       43654                  3          1\n",
       "35        98       13176                  4          1\n",
       "36        98        4357                  5          1\n",
       "37        98       37664                  6          1\n",
       "38        98       34065                  7          1\n",
       "39        98       35951                  8          1\n",
       "40        98       43560                  9          1\n",
       "41        98        9896                 10          1\n",
       "42        98       27509                 11          1\n",
       "43        98       15455                 12          1\n",
       "44        98       27966                 13          1\n",
       "45        98       47601                 14          1\n",
       "46        98       40396                 15          1\n",
       "47        98       35042                 16          1\n",
       "48        98       40986                 17          1\n",
       "49        98        1939                 18          1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f7bb25f-219b-45b0-8ec7-0d935e779450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same thing to validation dataframe\n",
    "val_df['idx'] = val_df.product_id.map(product_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "430e1a6c-4940-4092-91f4-5cb7ca1a03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "891c2ed4-0515-4a31-9866-c3f5caafabad",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['idx'] = val_df.idx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e272906-757b-4f32-9300-cd6c45274ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11109</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>49683</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43633</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>13176</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>47209</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>22035</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>39612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "      <td>19660</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36</td>\n",
       "      <td>49235</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>43086</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>46620</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36</td>\n",
       "      <td>34497</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36</td>\n",
       "      <td>48679</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36</td>\n",
       "      <td>46979</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38</td>\n",
       "      <td>11913</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38</td>\n",
       "      <td>18159</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38</td>\n",
       "      <td>4461</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>38</td>\n",
       "      <td>21616</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id  product_id  add_to_cart_order  reordered   idx\n",
       "0          1       49302                  1          1     0\n",
       "1          1       11109                  2          1  1254\n",
       "2          1       10246                  3          0   151\n",
       "3          1       49683                  4          0    16\n",
       "4          1       43633                  5          1     0\n",
       "5          1       13176                  6          0     2\n",
       "6          1       47209                  7          0     5\n",
       "7          1       22035                  8          1    44\n",
       "8         36       39612                  1          0     0\n",
       "9         36       19660                  2          1    49\n",
       "10        36       49235                  3          0    25\n",
       "11        36       43086                  4          1   270\n",
       "12        36       46620                  5          1     0\n",
       "13        36       34497                  6          1  1290\n",
       "14        36       48679                  7          1    56\n",
       "15        36       46979                  8          1    38\n",
       "16        38       11913                  1          0     0\n",
       "17        38       18159                  2          0  1257\n",
       "18        38        4461                  3          0   592\n",
       "19        38       21616                  4          1    30"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d18263e-005a-4883-8f08-6f3ced621967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32434469</th>\n",
       "      <td>3421081</td>\n",
       "      <td>20539</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434470</th>\n",
       "      <td>3421081</td>\n",
       "      <td>35221</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434471</th>\n",
       "      <td>3421081</td>\n",
       "      <td>12861</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434472</th>\n",
       "      <td>3421082</td>\n",
       "      <td>17279</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434473</th>\n",
       "      <td>3421082</td>\n",
       "      <td>12738</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434474</th>\n",
       "      <td>3421082</td>\n",
       "      <td>16797</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434475</th>\n",
       "      <td>3421082</td>\n",
       "      <td>43352</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434476</th>\n",
       "      <td>3421082</td>\n",
       "      <td>32700</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434477</th>\n",
       "      <td>3421082</td>\n",
       "      <td>12023</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434478</th>\n",
       "      <td>3421082</td>\n",
       "      <td>47941</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434479</th>\n",
       "      <td>3421083</td>\n",
       "      <td>7854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434480</th>\n",
       "      <td>3421083</td>\n",
       "      <td>45309</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434481</th>\n",
       "      <td>3421083</td>\n",
       "      <td>21162</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434482</th>\n",
       "      <td>3421083</td>\n",
       "      <td>18176</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434483</th>\n",
       "      <td>3421083</td>\n",
       "      <td>35211</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434484</th>\n",
       "      <td>3421083</td>\n",
       "      <td>39678</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434485</th>\n",
       "      <td>3421083</td>\n",
       "      <td>11352</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434486</th>\n",
       "      <td>3421083</td>\n",
       "      <td>4600</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434487</th>\n",
       "      <td>3421083</td>\n",
       "      <td>24852</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434488</th>\n",
       "      <td>3421083</td>\n",
       "      <td>5020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_id  product_id  add_to_cart_order  reordered   idx\n",
       "32434469   3421081       20539                  5          0     0\n",
       "32434470   3421081       35221                  6          0    65\n",
       "32434471   3421081       12861                  7          0     0\n",
       "32434472   3421082       17279                  1          1     0\n",
       "32434473   3421082       12738                  2          1     0\n",
       "32434474   3421082       16797                  3          0     8\n",
       "32434475   3421082       43352                  4          1    47\n",
       "32434476   3421082       32700                  5          1  1799\n",
       "32434477   3421082       12023                  6          0  1636\n",
       "32434478   3421082       47941                  7          0     0\n",
       "32434479   3421083        7854                  1          0     0\n",
       "32434480   3421083       45309                  2          0     0\n",
       "32434481   3421083       21162                  3          0   971\n",
       "32434482   3421083       18176                  4          1  1234\n",
       "32434483   3421083       35211                  5          0     0\n",
       "32434484   3421083       39678                  6          1     0\n",
       "32434485   3421083       11352                  7          0   747\n",
       "32434486   3421083        4600                  8          0     0\n",
       "32434487   3421083       24852                  9          1     1\n",
       "32434488   3421083        5020                 10          1     0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f83dad07-faee-4239-afb1-e8efec76eda2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1384567</th>\n",
       "      <td>3420998</td>\n",
       "      <td>31717</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384568</th>\n",
       "      <td>3420998</td>\n",
       "      <td>5337</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384569</th>\n",
       "      <td>3420998</td>\n",
       "      <td>23801</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384570</th>\n",
       "      <td>3420998</td>\n",
       "      <td>46665</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384571</th>\n",
       "      <td>3420998</td>\n",
       "      <td>9366</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384572</th>\n",
       "      <td>3420998</td>\n",
       "      <td>36606</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384573</th>\n",
       "      <td>3420998</td>\n",
       "      <td>5240</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384574</th>\n",
       "      <td>3420998</td>\n",
       "      <td>45002</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384575</th>\n",
       "      <td>3420998</td>\n",
       "      <td>23430</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384576</th>\n",
       "      <td>3420998</td>\n",
       "      <td>8277</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384577</th>\n",
       "      <td>3420998</td>\n",
       "      <td>38383</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384578</th>\n",
       "      <td>3420998</td>\n",
       "      <td>39527</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384579</th>\n",
       "      <td>3420998</td>\n",
       "      <td>24830</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384580</th>\n",
       "      <td>3420998</td>\n",
       "      <td>16185</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384581</th>\n",
       "      <td>3420998</td>\n",
       "      <td>6719</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384582</th>\n",
       "      <td>3420998</td>\n",
       "      <td>41950</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384583</th>\n",
       "      <td>3420998</td>\n",
       "      <td>8174</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384584</th>\n",
       "      <td>3420998</td>\n",
       "      <td>7615</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384585</th>\n",
       "      <td>3421026</td>\n",
       "      <td>24535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384586</th>\n",
       "      <td>3421026</td>\n",
       "      <td>15261</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384587</th>\n",
       "      <td>3421026</td>\n",
       "      <td>32237</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384588</th>\n",
       "      <td>3421026</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384589</th>\n",
       "      <td>3421026</td>\n",
       "      <td>4493</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384590</th>\n",
       "      <td>3421026</td>\n",
       "      <td>7781</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384591</th>\n",
       "      <td>3421049</td>\n",
       "      <td>40800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384592</th>\n",
       "      <td>3421049</td>\n",
       "      <td>17706</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384593</th>\n",
       "      <td>3421049</td>\n",
       "      <td>33424</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384594</th>\n",
       "      <td>3421049</td>\n",
       "      <td>17299</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384595</th>\n",
       "      <td>3421049</td>\n",
       "      <td>26800</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384596</th>\n",
       "      <td>3421049</td>\n",
       "      <td>34243</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384597</th>\n",
       "      <td>3421056</td>\n",
       "      <td>5750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384598</th>\n",
       "      <td>3421056</td>\n",
       "      <td>9340</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384599</th>\n",
       "      <td>3421056</td>\n",
       "      <td>21709</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384600</th>\n",
       "      <td>3421056</td>\n",
       "      <td>16475</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384601</th>\n",
       "      <td>3421056</td>\n",
       "      <td>12432</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384602</th>\n",
       "      <td>3421058</td>\n",
       "      <td>15629</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384603</th>\n",
       "      <td>3421058</td>\n",
       "      <td>4347</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384604</th>\n",
       "      <td>3421058</td>\n",
       "      <td>34466</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384605</th>\n",
       "      <td>3421058</td>\n",
       "      <td>6244</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384606</th>\n",
       "      <td>3421058</td>\n",
       "      <td>6858</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384607</th>\n",
       "      <td>3421058</td>\n",
       "      <td>30316</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384608</th>\n",
       "      <td>3421058</td>\n",
       "      <td>35578</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384609</th>\n",
       "      <td>3421058</td>\n",
       "      <td>32650</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384610</th>\n",
       "      <td>3421063</td>\n",
       "      <td>49235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384611</th>\n",
       "      <td>3421063</td>\n",
       "      <td>13565</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384612</th>\n",
       "      <td>3421063</td>\n",
       "      <td>14233</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384613</th>\n",
       "      <td>3421063</td>\n",
       "      <td>35548</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384614</th>\n",
       "      <td>3421070</td>\n",
       "      <td>35951</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384615</th>\n",
       "      <td>3421070</td>\n",
       "      <td>16953</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384616</th>\n",
       "      <td>3421070</td>\n",
       "      <td>4724</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  product_id  add_to_cart_order  reordered   idx\n",
       "1384567   3420998       31717                 11          1    34\n",
       "1384568   3420998        5337                 12          1   814\n",
       "1384569   3420998       23801                 13          0   786\n",
       "1384570   3420998       46665                 14          0     0\n",
       "1384571   3420998        9366                 15          0   787\n",
       "1384572   3420998       36606                 16          1  1019\n",
       "1384573   3420998        5240                 17          0   624\n",
       "1384574   3420998       45002                 18          1  1148\n",
       "1384575   3420998       23430                 19          1     0\n",
       "1384576   3420998        8277                 20          1    19\n",
       "1384577   3420998       38383                 21          0   153\n",
       "1384578   3420998       39527                 22          1  1195\n",
       "1384579   3420998       24830                 23          0   152\n",
       "1384580   3420998       16185                 24          0   111\n",
       "1384581   3420998        6719                 25          0     0\n",
       "1384582   3420998       41950                 26          0    40\n",
       "1384583   3420998        8174                 27          0    71\n",
       "1384584   3420998        7615                 28          0     0\n",
       "1384585   3421026       24535                  1          0   715\n",
       "1384586   3421026       15261                  2          0   470\n",
       "1384587   3421026       32237                  3          0     0\n",
       "1384588   3421026          10                  4          0     0\n",
       "1384589   3421026        4493                  5          0     0\n",
       "1384590   3421026        7781                  6          0    97\n",
       "1384591   3421049       40800                  1          0     0\n",
       "1384592   3421049       17706                  2          0   313\n",
       "1384593   3421049       33424                  3          1     0\n",
       "1384594   3421049       17299                  4          0     0\n",
       "1384595   3421049       26800                  5          0   443\n",
       "1384596   3421049       34243                  6          0   104\n",
       "1384597   3421056        5750                  1          1  1075\n",
       "1384598   3421056        9340                  2          1     0\n",
       "1384599   3421056       21709                  3          1   100\n",
       "1384600   3421056       16475                  4          0     0\n",
       "1384601   3421056       12432                  5          0     0\n",
       "1384602   3421058       15629                  1          1     0\n",
       "1384603   3421058        4347                  2          1  1572\n",
       "1384604   3421058       34466                  3          1   613\n",
       "1384605   3421058        6244                  4          1     0\n",
       "1384606   3421058        6858                  5          1     0\n",
       "1384607   3421058       30316                  6          1     0\n",
       "1384608   3421058       35578                  7          0     0\n",
       "1384609   3421058       32650                  8          1   926\n",
       "1384610   3421063       49235                  1          1    25\n",
       "1384611   3421063       13565                  2          1     0\n",
       "1384612   3421063       14233                  3          1   311\n",
       "1384613   3421063       35548                  4          1     0\n",
       "1384614   3421070       35951                  1          1    46\n",
       "1384615   3421070       16953                  2          1   187\n",
       "1384616   3421070        4724                  3          1   723"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c832bef-8837-48df-a9cd-8fcd47c39888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx\n",
       "0       11021574\n",
       "1         472565\n",
       "2         379450\n",
       "3         264683\n",
       "4         241921\n",
       "          ...   \n",
       "1995        2849\n",
       "1996        2848\n",
       "1997        2848\n",
       "1998        2847\n",
       "1999        2847\n",
       "Name: count, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.idx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b4b58d7-0f65-46b7-ad1e-547e12fbcb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customized way to create dataset\n",
    "\n",
    "def create_dataset(df,max_len,max_sequence_start=0, max_sequence_end=100000):\n",
    "    df_values = df[['order_id','idx']].values\n",
    "    catch_index = df_values[0][0]\n",
    "    one_row = [0]*max_len\n",
    "    data = []\n",
    "    idx = 0\n",
    "    df_leng = len(df)\n",
    "    for row in range(df_leng-1):\n",
    "            \n",
    "        if df_values[row][1] > 0 and idx < max_len:\n",
    "            one_row[idx] = df_values[row][1]\n",
    "            idx += 1\n",
    "            \n",
    "        if df_values[row+1][0] != catch_index and one_row != [0]*max_len:\n",
    "            data.append(torch.tensor(one_row,dtype = torch.long))\n",
    "            del one_row\n",
    "            torch.cuda.empty_cache()\n",
    "            one_row = [0]*max_len\n",
    "            catch_index = df_values[row+1][0]\n",
    "            idx = 0\n",
    "\n",
    "        if row == df_leng -2 and df_values[row+1][1] > 0:\n",
    "            one_row.append(df_values[row+1][1])\n",
    "            data.append(torch.tensor(one_row,dtype = torch.long))\n",
    "            del one_row\n",
    "            torch.cuda.empty_cache()\n",
    "            catch_index = df_values[row+1][0]\n",
    "  \n",
    "    return torch.stack(data[max_sequence_start:max_sequence_end]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "754711c8-295a-46b7-ba51-dc008049533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data\n",
    "torch.cuda.empty_cache()\n",
    "train_data = create_dataset(train_df,5,max_sequence_start=0,max_sequence_end=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35311ddc-1490-4d06-a848-cdaba76bf98c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3200520, 5])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5495311-4e7d-4c85-ac4a-bfcce979b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3edf8d6-05e2-4d49-b37b-b7f24e836879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3200520])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d918d259-949f-4962-94af-d97162b83204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del val_data\n",
    "# torch.cuda.empty_cache()\n",
    "val_data = create_dataset(val_df,5,max_sequence_start=0,max_sequence_end=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eec53bb0-0426-4805-9e83-8896e51be4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1254,  151,   16,    2,    5],\n",
       "        [  49,   25,  270, 1290,   56],\n",
       "        [1257,  592,   30,  691,  415],\n",
       "        ...,\n",
       "        [1075,  100,    0,    0,    0],\n",
       "        [1572,  613,  926,    0,    0],\n",
       "        [  25,  311,    0,    0,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "035bc1b6-3210-4105-8b0f-31991ca1b9bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([130433, 5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8f1c4bb-e65a-4397-b1d3-43fde7c78b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = val_data.t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a3e89ad-aa70-4778-b3af-b59f6887d2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1254,   49, 1257,  ..., 1075, 1572,   25],\n",
       "        [ 151,   25,  592,  ...,  100,  613,  311],\n",
       "        [  16,  270,   30,  ...,    0,  926,    0],\n",
       "        [   2, 1290,  691,  ...,    0,    0,    0],\n",
       "        [   5,   56,  415,  ...,    0,    0,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d766771-1d92-4ff3-96c6-6884c2742db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4eafecb9-a268-40ac-82f9-c2907416c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = 2000 # size of vocabulary\n",
    "emsize = 64  # embedding dimension\n",
    "d_hid = 128 # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 2  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 2  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "56a5a93d-3fe3-4a75-aad8-979630107aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (embedding): Embedding(2000, 64)\n",
       "  (linear): Linear(in_features=64, out_features=2000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0abf5912-d9df-43ca-a1e8-2205bee82326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "lr = 5  # learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       mode='min',\n",
    "                                                       factor =0.9,\n",
    "                                                       patience=10,\n",
    "                                                       threshold=0.001)\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 1000\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_batches = train_data.size(-1) // bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(-1) - bptt , bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        output = model(data)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        targets_flat = targets.reshape(-1)\n",
    "        loss = criterion(output_flat, targets_flat)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            scheduler.step(cur_loss)\n",
    "            # print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "            #       f'lr {lr:02.4f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "            #       f'loss {cur_loss:5.4f} | ppl {ppl:8.4f}')\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.4f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.4f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(-1) - bptt, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            output = model(data)\n",
    "            target_flat = targets.reshape(-1)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += seq_len * criterion(output_flat, target_flat).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "534f8295-0ae7-49fd-ba1d-a7ba9ba2a93e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1000/12502 batches | lr 5.0000 | ms/batch 10.04 | loss 892.8067\n",
      "| epoch   1 |  2000/12502 batches | lr 5.0000 | ms/batch 10.28 | loss 807.4324\n",
      "| epoch   1 |  3000/12502 batches | lr 5.0000 | ms/batch 10.06 | loss 680.3477\n",
      "| epoch   1 |  4000/12502 batches | lr 5.0000 | ms/batch 10.48 | loss 671.5349\n",
      "| epoch   1 |  5000/12502 batches | lr 5.0000 | ms/batch  9.89 | loss 636.3292\n",
      "| epoch   1 |  6000/12502 batches | lr 5.0000 | ms/batch 10.37 | loss 583.7743\n",
      "| epoch   1 |  7000/12502 batches | lr 5.0000 | ms/batch  9.97 | loss 604.4817\n",
      "| epoch   1 |  8000/12502 batches | lr 5.0000 | ms/batch 10.47 | loss 615.2389\n",
      "| epoch   1 |  9000/12502 batches | lr 5.0000 | ms/batch 10.80 | loss 584.0190\n",
      "| epoch   1 | 10000/12502 batches | lr 5.0000 | ms/batch 10.78 | loss 551.9331\n",
      "| epoch   1 | 11000/12502 batches | lr 5.0000 | ms/batch 11.04 | loss 564.5204\n",
      "| epoch   1 | 12000/12502 batches | lr 5.0000 | ms/batch 10.19 | loss 558.0569\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 130.55s | valid loss 173136.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |  1000/12502 batches | lr 5.0000 | ms/batch 10.01 | loss 566.9386\n",
      "| epoch   2 |  2000/12502 batches | lr 5.0000 | ms/batch 10.07 | loss 547.8680\n",
      "| epoch   2 |  3000/12502 batches | lr 5.0000 | ms/batch 10.04 | loss 598.7130\n",
      "| epoch   2 |  4000/12502 batches | lr 5.0000 | ms/batch 10.04 | loss 572.4367\n",
      "| epoch   2 |  5000/12502 batches | lr 5.0000 | ms/batch  9.96 | loss 574.6368\n",
      "| epoch   2 |  6000/12502 batches | lr 5.0000 | ms/batch 10.54 | loss 534.0901\n",
      "| epoch   2 |  7000/12502 batches | lr 5.0000 | ms/batch 10.88 | loss 544.0873\n",
      "| epoch   2 |  8000/12502 batches | lr 5.0000 | ms/batch 10.35 | loss 558.0603\n",
      "| epoch   2 |  9000/12502 batches | lr 5.0000 | ms/batch 11.28 | loss 557.2628\n",
      "| epoch   2 | 10000/12502 batches | lr 5.0000 | ms/batch 10.13 | loss 568.6131\n",
      "| epoch   2 | 11000/12502 batches | lr 5.0000 | ms/batch  9.98 | loss 566.9395\n",
      "| epoch   2 | 12000/12502 batches | lr 5.0000 | ms/batch  9.94 | loss 535.7475\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 129.57s | valid loss 321178.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |  1000/12502 batches | lr 5.0000 | ms/batch 11.16 | loss 618.7644\n",
      "| epoch   3 |  2000/12502 batches | lr 5.0000 | ms/batch 10.54 | loss 566.5358\n",
      "| epoch   3 |  3000/12502 batches | lr 5.0000 | ms/batch 10.43 | loss 598.6097\n",
      "| epoch   3 |  4000/12502 batches | lr 5.0000 | ms/batch 10.49 | loss 583.1358\n",
      "| epoch   3 |  5000/12502 batches | lr 4.5000 | ms/batch 10.43 | loss 489.8518\n",
      "| epoch   3 |  6000/12502 batches | lr 4.5000 | ms/batch 10.42 | loss 481.0505\n",
      "| epoch   3 |  7000/12502 batches | lr 4.5000 | ms/batch 10.51 | loss 483.8665\n",
      "| epoch   3 |  8000/12502 batches | lr 4.5000 | ms/batch 10.47 | loss 481.3611\n",
      "| epoch   3 |  9000/12502 batches | lr 4.5000 | ms/batch 10.39 | loss 453.0329\n",
      "| epoch   3 | 10000/12502 batches | lr 4.5000 | ms/batch 10.37 | loss 471.6513\n",
      "| epoch   3 | 11000/12502 batches | lr 4.5000 | ms/batch 10.51 | loss 465.9142\n",
      "| epoch   3 | 12000/12502 batches | lr 4.5000 | ms/batch 10.46 | loss 479.6321\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 132.65s | valid loss 209801.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |  1000/12502 batches | lr 4.5000 | ms/batch 10.40 | loss 475.0272\n",
      "| epoch   4 |  2000/12502 batches | lr 4.5000 | ms/batch 10.40 | loss 498.5453\n",
      "| epoch   4 |  3000/12502 batches | lr 4.5000 | ms/batch 10.48 | loss 495.5580\n",
      "| epoch   4 |  4000/12502 batches | lr 4.5000 | ms/batch 10.45 | loss 506.1894\n",
      "| epoch   4 |  5000/12502 batches | lr 4.5000 | ms/batch 11.06 | loss 470.7651\n",
      "| epoch   4 |  6000/12502 batches | lr 4.5000 | ms/batch 10.36 | loss 469.9923\n",
      "| epoch   4 |  7000/12502 batches | lr 4.5000 | ms/batch 10.39 | loss 507.3019\n",
      "| epoch   4 |  8000/12502 batches | lr 4.0500 | ms/batch 10.34 | loss 383.4413\n",
      "| epoch   4 |  9000/12502 batches | lr 4.0500 | ms/batch 10.26 | loss 399.2577\n",
      "| epoch   4 | 10000/12502 batches | lr 4.0500 | ms/batch 11.41 | loss 406.3344\n",
      "| epoch   4 | 11000/12502 batches | lr 4.0500 | ms/batch 10.57 | loss 386.4560\n",
      "| epoch   4 | 12000/12502 batches | lr 4.0500 | ms/batch 10.42 | loss 452.0893\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 133.06s | valid loss   nan\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |  1000/12502 batches | lr 4.0500 | ms/batch 10.40 | loss 418.0889\n",
      "| epoch   5 |  2000/12502 batches | lr 4.0500 | ms/batch 10.40 | loss 413.6026\n",
      "| epoch   5 |  3000/12502 batches | lr 4.0500 | ms/batch 10.37 | loss 417.5410\n",
      "| epoch   5 |  4000/12502 batches | lr 4.0500 | ms/batch 10.38 | loss 388.4915\n",
      "| epoch   5 |  5000/12502 batches | lr 4.0500 | ms/batch 10.46 | loss 401.3243\n",
      "| epoch   5 |  6000/12502 batches | lr 4.0500 | ms/batch 10.43 | loss 407.3735\n",
      "| epoch   5 |  7000/12502 batches | lr 3.6450 | ms/batch 10.43 | loss 358.8661\n",
      "| epoch   5 |  8000/12502 batches | lr 3.6450 | ms/batch 10.40 | loss 337.4820\n",
      "| epoch   5 |  9000/12502 batches | lr 3.6450 | ms/batch 10.42 | loss 350.7531\n",
      "| epoch   5 | 10000/12502 batches | lr 3.6450 | ms/batch 10.50 | loss 334.3941\n",
      "| epoch   5 | 11000/12502 batches | lr 3.6450 | ms/batch 10.83 | loss 360.5205\n",
      "| epoch   5 | 12000/12502 batches | lr 3.6450 | ms/batch 10.38 | loss 354.1136\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 131.65s | valid loss   nan\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      8\u001b[0m     epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, val_data)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# val_ppl = math.exp(val_loss)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[83], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output_flat, targets_flat)\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Capstone_Project\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Capstone_Project\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 10\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss = evaluate(model, val_data)\n",
    "        # val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print('-' * 89)\n",
    "        # print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "        #     f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "              f'valid loss {val_loss:5.2f}')\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step(best_val_loss)\n",
    "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fadc23d8-e1b4-44d1-a76a-fabe38ffac56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "705.25"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2821/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8fdc8c-af2f-4bc4-994d-57863eea0e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"trans4rec.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955ca9d-01ef-4cf4-93fb-512d72f34ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluate(model, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a3f0761-a838-4c23-9c29-3dd0e27ffe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(-1) - bptt, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            output = model(data)\n",
    "            target_flat = targets.reshape(-1)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "    return target_flat, output_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "191e036a-af2c-4d30-aa06-18ef52e3141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = get_batch(val_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba54f16-e00a-48c7-9723-005d382f2383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "974fa341-60f5-4b14-a62e-8484c3a6a069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets, predictions = test(model, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd5bd36b-5afa-4c79-847d-4b2e80ee6c35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "59f3faa0-dbbe-4d87-a753-bc532fb5b899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1902,   10,    0,  ...,  350,  203,    0], device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f178d27b-4a2f-461a-adb5-47a4fd2cb3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 2000])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b17dd5d6-562a-40fc-b25e-fd354f3e83a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: 1902| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 10| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 357| predictions: tensor([1, 0, 2, 4, 3], device='cuda:0')\n",
      "target: 49| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 369| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 195| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 590| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 11| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1631| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 22| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 49| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 635| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 719| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 70| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 61| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1082| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 495| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 810| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1316| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1475| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 624| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 825| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 3| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 601| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 21| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 8| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 165| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 744| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 32| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 82| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 493| predictions: tensor([1, 0, 2, 4, 3], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1522| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 14| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 18| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 672| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 82| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1021| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 214| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 61| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 18| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 119| predictions: tensor([1, 0, 2, 4, 3], device='cuda:0')\n",
      "target: 1673| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 2| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1319| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 15| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1661| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 3| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 523| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 277| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 159| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 976| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 55| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 50| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 17| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1297| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 8| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 457| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1232| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1652| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 25| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1280| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 62| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 51| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 121| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 336| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 65| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 294| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 264| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 477| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([1, 0, 2, 4, 3], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 10| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1701| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 159| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 896| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1119| predictions: tensor([1, 0, 2, 4, 3], device='cuda:0')\n",
      "target: 1075| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 746| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 231| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 192| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 317| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 963| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 175| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 25| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 3| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1231| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 84| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1866| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 255| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 312| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 332| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1108| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 326| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 12| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 291| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 3| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 7| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1350| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 683| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 489| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 433| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 413| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 421| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 387| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1236| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 49| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 26| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 281| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 39| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 50| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 239| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1093| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1421| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 699| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1677| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 19| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 2| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 111| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 36| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 126| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 681| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1875| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 716| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 472| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 214| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 336| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1314| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 961| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 11| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 4| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 240| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 926| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 233| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 227| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 354| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([1, 0, 2, 4, 3], device='cuda:0')\n",
      "target: 21| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 179| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 488| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 111| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1352| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 11| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1010| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 21| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1338| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 641| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 462| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1459| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 133| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 765| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 883| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 574| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 5| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1323| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1810| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 544| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1155| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 18| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 11| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 188| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 69| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 2| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1576| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1889| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1318| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 545| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 571| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 251| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1309| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 31| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 49| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 410| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1012| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 631| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 87| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 371| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 484| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 275| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 716| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 39| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 214| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 154| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1924| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 26| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 20| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 6| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 2| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 6| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 518| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 140| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 168| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 963| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 31| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1076| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1512| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 13| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 49| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 8| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1720| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 122| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 819| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 28| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 300| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 8| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 230| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 442| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1076| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 97| predictions: tensor([1, 0, 2, 4, 3], device='cuda:0')\n",
      "target: 684| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 73| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 461| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 496| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 853| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 194| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1519| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1426| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1135| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 227| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 30| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 35| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 71| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 787| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1106| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 4| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 6| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 155| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1872| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 50| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 38| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 439| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 3| predictions: tensor([1, 0, 2, 4, 3], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 511| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 52| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 86| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 437| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 46| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 6| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 9| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 156| predictions: tensor([1, 0, 2, 4, 3], device='cuda:0')\n",
      "target: 182| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 374| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 533| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1490| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 165| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 293| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1113| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 24| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 920| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 2| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1686| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 3| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 248| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 913| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 33| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 45| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1354| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 49| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 463| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 62| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1267| predictions: tensor([1, 0, 2, 4, 3], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 198| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 62| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 496| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 419| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1163| predictions: tensor([1, 0, 2, 4, 3], device='cuda:0')\n",
      "target: 3| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 193| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1163| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 115| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 670| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 227| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 859| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 177| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1728| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 62| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 49| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1264| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1473| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 2| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 505| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 634| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1391| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 473| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 30| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1741| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1863| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 989| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 275| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 399| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 471| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 291| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 207| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 51| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1085| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 42| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1146| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 11| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1891| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 21| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1712| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 81| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 283| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1365| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1888| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 565| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 2| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 519| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 25| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1093| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 185| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 338| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 12| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 410| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1631| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 839| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 21| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([1, 0, 2, 4, 3], device='cuda:0')\n",
      "target: 1| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 669| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 14| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1537| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 71| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 183| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 745| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 336| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 211| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 470| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 254| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 146| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 318| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 600| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1476| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1422| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 5| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 844| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 75| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 4| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 75| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1020| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 19| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 408| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1395| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1049| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 110| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 15| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 35| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1970| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 151| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 308| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 516| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1198| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 42| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 179| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 253| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 12| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1097| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1697| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 232| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 45| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1680| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1541| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 415| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 1609| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 0| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 383| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 198| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 34| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 5| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n",
      "target: 921| predictions: tensor([ 151,   79,   59,  793, 1576], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "samples =500\n",
    "true = targets[:samples]\n",
    "prob_pred = predictions[:samples,:]\n",
    "_,pred = torch.topk(prob_pred, 5)\n",
    "for i in range(samples):\n",
    "    print(f'target: {true[i]}| predictions: {pred[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba07ea2-5e52-424b-91da-04db15fd5153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
