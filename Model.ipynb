{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfea3a15-4b40-4063-9f57-208b52b40ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "67dd8810-6c65-47a7-ae05-53a0139fad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.embedding = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, ntoken)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def get_src_mask(self, size) -> Tensor:\n",
    "        \"\"\"\n",
    "        Generates a squeare matrix where the each row allows one word more to be seen\n",
    "        src shape: [seq_length,batch_size]\n",
    "        then mask shape: [seq_length,seq_length]\n",
    "        e.g. for seq_length = 5,\n",
    "        output = \n",
    "        [[0., 0., 0., 0., 0.],\n",
    "        [-inf, 0., 0., 0., 0.],\n",
    "        [-inf, -inf, 0., 0., 0.],\n",
    "        [-inf, -inf, -inf, 0., 0.],\n",
    "        [-inf, -inf, -inf, -inf, 0.]]\n",
    "\n",
    "        with shape [5,5]\n",
    "        \n",
    "        \"\"\"\n",
    "        mask = torch.triu(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[seq_len, batch_size]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        src_length,batch_size = src.size()\n",
    "        src_mask = self.get_src_mask(src_length)\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src,mask = src_mask,is_causal = True)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3804dbe5-ea22-4113-b669-bff480be492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "704c7c1a-40ec-48fa-a1aa-569186e6b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d6b7bdcb-0947-40e9-a226-47937dace90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 32\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape ``[full_seq_len, batch_size]``\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape ``[seq_len, batch_size]`` and\n",
    "        target has shape ``[seq_len * batch_size]``\n",
    "    \"\"\"\n",
    "    data = source[: -1, i: i+bptt]\n",
    "    target = source[1:, i: i+bptt]\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ba3249-3a24-4419-b095-c935d364173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = ZipFile(\"order_products__prior.csv.zip\")\n",
    "train_df = pd.read_csv(zf.extract(\"order_products__prior.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4986ec60-4b6e-4908-b4cb-44c0de393270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32434489 entries, 0 to 32434488\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Dtype\n",
      "---  ------             -----\n",
      " 0   order_id           int64\n",
      " 1   product_id         int64\n",
      " 2   add_to_cart_order  int64\n",
      " 3   reordered          int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 989.8 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c616db6e-8498-4016-93d9-8b52cf46d760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>33120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28985</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9327</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>45918</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>30035</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434484</th>\n",
       "      <td>3421083</td>\n",
       "      <td>39678</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434485</th>\n",
       "      <td>3421083</td>\n",
       "      <td>11352</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434486</th>\n",
       "      <td>3421083</td>\n",
       "      <td>4600</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434487</th>\n",
       "      <td>3421083</td>\n",
       "      <td>24852</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434488</th>\n",
       "      <td>3421083</td>\n",
       "      <td>5020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32434489 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_id  product_id  add_to_cart_order  reordered\n",
       "0                2       33120                  1          1\n",
       "1                2       28985                  2          1\n",
       "2                2        9327                  3          0\n",
       "3                2       45918                  4          1\n",
       "4                2       30035                  5          0\n",
       "...            ...         ...                ...        ...\n",
       "32434484   3421083       39678                  6          1\n",
       "32434485   3421083       11352                  7          0\n",
       "32434486   3421083        4600                  8          0\n",
       "32434487   3421083       24852                  9          1\n",
       "32434488   3421083        5020                 10          1\n",
       "\n",
       "[32434489 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db7e28f0-cef5-4439-98eb-3a79530e86e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5398444846780228"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate percentage of data included in top k sales products\n",
    "train_df.product_id.value_counts()[:999].values.sum()/train_df.product_id.value_counts().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14f338d6-74ce-4801-9bf7-f676a5301757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract top k prodcuts\n",
    "top_products = train_df.product_id.value_counts()[:999].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b6a18b6-633e-48dc-8f77-988f9cce07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the top k products into indices from 1 to k\n",
    "product_to_idx = {product:i for i,product in enumerate(top_products,start=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05a0533b-c0e2-4e47-b49b-92f59e64c58e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{24852: 1,\n",
       " 13176: 2,\n",
       " 21137: 3,\n",
       " 21903: 4,\n",
       " 47209: 5,\n",
       " 47766: 6,\n",
       " 47626: 7,\n",
       " 16797: 8,\n",
       " 26209: 9,\n",
       " 27845: 10,\n",
       " 27966: 11,\n",
       " 22935: 12,\n",
       " 24964: 13,\n",
       " 45007: 14,\n",
       " 39275: 15,\n",
       " 49683: 16,\n",
       " 28204: 17,\n",
       " 5876: 18,\n",
       " 8277: 19,\n",
       " 40706: 20,\n",
       " 4920: 21,\n",
       " 30391: 22,\n",
       " 45066: 23,\n",
       " 42265: 24,\n",
       " 49235: 25,\n",
       " 44632: 26,\n",
       " 19057: 27,\n",
       " 4605: 28,\n",
       " 37646: 29,\n",
       " 21616: 30,\n",
       " 17794: 31,\n",
       " 27104: 32,\n",
       " 30489: 33,\n",
       " 31717: 34,\n",
       " 27086: 35,\n",
       " 44359: 36,\n",
       " 28985: 37,\n",
       " 46979: 38,\n",
       " 8518: 39,\n",
       " 41950: 40,\n",
       " 26604: 41,\n",
       " 5077: 42,\n",
       " 34126: 43,\n",
       " 22035: 44,\n",
       " 39877: 45,\n",
       " 35951: 46,\n",
       " 43352: 47,\n",
       " 10749: 48,\n",
       " 19660: 49,\n",
       " 9076: 50,\n",
       " 21938: 51,\n",
       " 43961: 52,\n",
       " 24184: 53,\n",
       " 34969: 54,\n",
       " 46667: 55,\n",
       " 48679: 56,\n",
       " 25890: 57,\n",
       " 31506: 58,\n",
       " 12341: 59,\n",
       " 39928: 60,\n",
       " 24838: 61,\n",
       " 5450: 62,\n",
       " 22825: 63,\n",
       " 5785: 64,\n",
       " 35221: 65,\n",
       " 28842: 66,\n",
       " 33731: 67,\n",
       " 27521: 68,\n",
       " 44142: 69,\n",
       " 33198: 70,\n",
       " 8174: 71,\n",
       " 20114: 72,\n",
       " 8424: 73,\n",
       " 27344: 74,\n",
       " 11520: 75,\n",
       " 29487: 76,\n",
       " 18465: 77,\n",
       " 28199: 78,\n",
       " 15290: 79,\n",
       " 46906: 80,\n",
       " 9839: 81,\n",
       " 27156: 82,\n",
       " 3957: 83,\n",
       " 43122: 84,\n",
       " 23909: 85,\n",
       " 34358: 86,\n",
       " 4799: 87,\n",
       " 9387: 88,\n",
       " 16759: 89,\n",
       " 196: 90,\n",
       " 42736: 91,\n",
       " 38689: 92,\n",
       " 4210: 93,\n",
       " 41787: 94,\n",
       " 41220: 95,\n",
       " 47144: 96,\n",
       " 7781: 97,\n",
       " 33000: 98,\n",
       " 20995: 99,\n",
       " 21709: 100,\n",
       " 19678: 101,\n",
       " 40604: 102,\n",
       " 30233: 103,\n",
       " 34243: 104,\n",
       " 37687: 105,\n",
       " 24489: 106,\n",
       " 42828: 107,\n",
       " 5479: 108,\n",
       " 432: 109,\n",
       " 6184: 110,\n",
       " 16185: 111,\n",
       " 42768: 112,\n",
       " 17948: 113,\n",
       " 33754: 114,\n",
       " 19348: 115,\n",
       " 8193: 116,\n",
       " 26369: 117,\n",
       " 42585: 118,\n",
       " 14992: 119,\n",
       " 14947: 120,\n",
       " 22963: 121,\n",
       " 1463: 122,\n",
       " 28849: 123,\n",
       " 8021: 124,\n",
       " 25659: 125,\n",
       " 21405: 126,\n",
       " 46676: 127,\n",
       " 31343: 128,\n",
       " 41844: 129,\n",
       " 38293: 130,\n",
       " 42701: 131,\n",
       " 43789: 132,\n",
       " 36011: 133,\n",
       " 5025: 134,\n",
       " 39475: 135,\n",
       " 43295: 136,\n",
       " 11777: 137,\n",
       " 20842: 138,\n",
       " 32689: 139,\n",
       " 32655: 140,\n",
       " 2295: 141,\n",
       " 46802: 142,\n",
       " 13870: 143,\n",
       " 25146: 144,\n",
       " 18531: 145,\n",
       " 5212: 146,\n",
       " 31553: 147,\n",
       " 39408: 148,\n",
       " 260: 149,\n",
       " 36695: 150,\n",
       " 10246: 151,\n",
       " 24830: 152,\n",
       " 38383: 153,\n",
       " 43768: 154,\n",
       " 1940: 155,\n",
       " 11182: 156,\n",
       " 18523: 157,\n",
       " 18362: 158,\n",
       " 21288: 159,\n",
       " 6046: 160,\n",
       " 44683: 161,\n",
       " 29987: 162,\n",
       " 890: 163,\n",
       " 38777: 164,\n",
       " 43772: 165,\n",
       " 23734: 166,\n",
       " 7948: 167,\n",
       " 30450: 168,\n",
       " 38456: 169,\n",
       " 46969: 170,\n",
       " 44910: 171,\n",
       " 47734: 172,\n",
       " 38159: 173,\n",
       " 26620: 174,\n",
       " 47672: 175,\n",
       " 4957: 176,\n",
       " 26165: 177,\n",
       " 30776: 178,\n",
       " 44987: 179,\n",
       " 35939: 180,\n",
       " 14678: 181,\n",
       " 16349: 182,\n",
       " 28289: 183,\n",
       " 29447: 184,\n",
       " 44422: 185,\n",
       " 40310: 186,\n",
       " 16953: 187,\n",
       " 23375: 188,\n",
       " 33787: 189,\n",
       " 19048: 190,\n",
       " 2078: 191,\n",
       " 13984: 192,\n",
       " 41290: 193,\n",
       " 23165: 194,\n",
       " 32864: 195,\n",
       " 17600: 196,\n",
       " 39812: 197,\n",
       " 8859: 198,\n",
       " 48364: 199,\n",
       " 33120: 200,\n",
       " 31683: 201,\n",
       " 26940: 202,\n",
       " 28465: 203,\n",
       " 35108: 204,\n",
       " 26283: 205,\n",
       " 37158: 206,\n",
       " 37067: 207,\n",
       " 18370: 208,\n",
       " 45: 209,\n",
       " 41665: 210,\n",
       " 35547: 211,\n",
       " 3952: 212,\n",
       " 10957: 213,\n",
       " 2086: 214,\n",
       " 2966: 215,\n",
       " 43154: 216,\n",
       " 24799: 217,\n",
       " 40571: 218,\n",
       " 10132: 219,\n",
       " 43713: 220,\n",
       " 40396: 221,\n",
       " 18027: 222,\n",
       " 45535: 223,\n",
       " 1158: 224,\n",
       " 25931: 225,\n",
       " 7021: 226,\n",
       " 38739: 227,\n",
       " 13629: 228,\n",
       " 42450: 229,\n",
       " 20119: 230,\n",
       " 15937: 231,\n",
       " 42342: 232,\n",
       " 32478: 233,\n",
       " 48745: 234,\n",
       " 45633: 235,\n",
       " 21019: 236,\n",
       " 34050: 237,\n",
       " 34448: 238,\n",
       " 48205: 239,\n",
       " 39619: 240,\n",
       " 17461: 241,\n",
       " 45603: 242,\n",
       " 30169: 243,\n",
       " 31040: 244,\n",
       " 38400: 245,\n",
       " 13646: 246,\n",
       " 36865: 247,\n",
       " 40174: 248,\n",
       " 21267: 249,\n",
       " 17872: 250,\n",
       " 5818: 251,\n",
       " 26790: 252,\n",
       " 39984: 253,\n",
       " 14084: 254,\n",
       " 23288: 255,\n",
       " 21376: 256,\n",
       " 32734: 257,\n",
       " 33768: 258,\n",
       " 37766: 259,\n",
       " 46654: 260,\n",
       " 12206: 261,\n",
       " 329: 262,\n",
       " 28934: 263,\n",
       " 6187: 264,\n",
       " 6348: 265,\n",
       " 39993: 266,\n",
       " 18441: 267,\n",
       " 5646: 268,\n",
       " 25340: 269,\n",
       " 43086: 270,\n",
       " 6104: 271,\n",
       " 42356: 272,\n",
       " 48775: 273,\n",
       " 651: 274,\n",
       " 10673: 275,\n",
       " 47977: 276,\n",
       " 19508: 277,\n",
       " 39180: 278,\n",
       " 40709: 279,\n",
       " 19677: 280,\n",
       " 10017: 281,\n",
       " 27336: 282,\n",
       " 13535: 283,\n",
       " 13829: 284,\n",
       " 42244: 285,\n",
       " 11782: 286,\n",
       " 27695: 287,\n",
       " 36070: 288,\n",
       " 28156: 289,\n",
       " 6873: 290,\n",
       " 49520: 291,\n",
       " 49383: 292,\n",
       " 8571: 293,\n",
       " 24561: 294,\n",
       " 13249: 295,\n",
       " 49075: 296,\n",
       " 16083: 297,\n",
       " 24024: 298,\n",
       " 40545: 299,\n",
       " 40199: 300,\n",
       " 30720: 301,\n",
       " 17795: 302,\n",
       " 25588: 303,\n",
       " 35921: 304,\n",
       " 17122: 305,\n",
       " 11422: 306,\n",
       " 8670: 307,\n",
       " 31915: 308,\n",
       " 35561: 309,\n",
       " 42445: 310,\n",
       " 14233: 311,\n",
       " 7963: 312,\n",
       " 17706: 313,\n",
       " 3599: 314,\n",
       " 21295: 315,\n",
       " 44449: 316,\n",
       " 36550: 317,\n",
       " 19019: 318,\n",
       " 30827: 319,\n",
       " 20082: 320,\n",
       " 35042: 321,\n",
       " 25466: 322,\n",
       " 33401: 323,\n",
       " 1511: 324,\n",
       " 42625: 325,\n",
       " 5194: 326,\n",
       " 8048: 327,\n",
       " 23537: 328,\n",
       " 2825: 329,\n",
       " 16965: 330,\n",
       " 38928: 331,\n",
       " 21195: 332,\n",
       " 19706: 333,\n",
       " 18288: 334,\n",
       " 13380: 335,\n",
       " 7751: 336,\n",
       " 15872: 337,\n",
       " 4562: 338,\n",
       " 9339: 339,\n",
       " 22395: 340,\n",
       " 38164: 341,\n",
       " 46720: 342,\n",
       " 40723: 343,\n",
       " 15902: 344,\n",
       " 35140: 345,\n",
       " 4472: 346,\n",
       " 3376: 347,\n",
       " 13166: 348,\n",
       " 29662: 349,\n",
       " 2855: 350,\n",
       " 28993: 351,\n",
       " 7175: 352,\n",
       " 13575: 353,\n",
       " 13740: 354,\n",
       " 12916: 355,\n",
       " 40516: 356,\n",
       " 45200: 357,\n",
       " 7503: 358,\n",
       " 5782: 359,\n",
       " 19691: 360,\n",
       " 5134: 361,\n",
       " 40332: 362,\n",
       " 12456: 363,\n",
       " 21174: 364,\n",
       " 5258: 365,\n",
       " 10644: 366,\n",
       " 39561: 367,\n",
       " 4421: 368,\n",
       " 33129: 369,\n",
       " 44765: 370,\n",
       " 20955: 371,\n",
       " 46584: 372,\n",
       " 22124: 373,\n",
       " 44570: 374,\n",
       " 3464: 375,\n",
       " 13198: 376,\n",
       " 43662: 377,\n",
       " 10070: 378,\n",
       " 32691: 379,\n",
       " 7559: 380,\n",
       " 37710: 381,\n",
       " 36735: 382,\n",
       " 35898: 383,\n",
       " 37029: 384,\n",
       " 34262: 385,\n",
       " 1025: 386,\n",
       " 18918: 387,\n",
       " 42719: 388,\n",
       " 11408: 389,\n",
       " 18234: 390,\n",
       " 44560: 391,\n",
       " 23029: 392,\n",
       " 45123: 393,\n",
       " 3896: 394,\n",
       " 9092: 395,\n",
       " 28745: 396,\n",
       " 18811: 397,\n",
       " 26384: 398,\n",
       " 35503: 399,\n",
       " 35628: 400,\n",
       " 47141: 401,\n",
       " 28476: 402,\n",
       " 25138: 403,\n",
       " 21386: 404,\n",
       " 47042: 405,\n",
       " 46820: 406,\n",
       " 21292: 407,\n",
       " 11140: 408,\n",
       " 21573: 409,\n",
       " 38768: 410,\n",
       " 17949: 411,\n",
       " 1999: 412,\n",
       " 14197: 413,\n",
       " 46616: 414,\n",
       " 32433: 415,\n",
       " 47759: 416,\n",
       " 37220: 417,\n",
       " 39947: 418,\n",
       " 24954: 419,\n",
       " 41065: 420,\n",
       " 21333: 421,\n",
       " 25824: 422,\n",
       " 48628: 423,\n",
       " 1194: 424,\n",
       " 43504: 425,\n",
       " 44628: 426,\n",
       " 5456: 427,\n",
       " 38273: 428,\n",
       " 15613: 429,\n",
       " 35535: 430,\n",
       " 15424: 431,\n",
       " 27548: 432,\n",
       " 24841: 433,\n",
       " 39190: 434,\n",
       " 27730: 435,\n",
       " 42110: 436,\n",
       " 29307: 437,\n",
       " 14161: 438,\n",
       " 49175: 439,\n",
       " 14462: 440,\n",
       " 31066: 441,\n",
       " 16696: 442,\n",
       " 26800: 443,\n",
       " 9825: 444,\n",
       " 5322: 445,\n",
       " 27744: 446,\n",
       " 8309: 447,\n",
       " 11005: 448,\n",
       " 41588: 449,\n",
       " 11068: 450,\n",
       " 27796: 451,\n",
       " 27325: 452,\n",
       " 2228: 453,\n",
       " 7969: 454,\n",
       " 22474: 455,\n",
       " 9020: 456,\n",
       " 16521: 457,\n",
       " 3298: 458,\n",
       " 5769: 459,\n",
       " 1244: 460,\n",
       " 13517: 461,\n",
       " 27323: 462,\n",
       " 2452: 463,\n",
       " 28601: 464,\n",
       " 2314: 465,\n",
       " 21927: 466,\n",
       " 32177: 467,\n",
       " 13733: 468,\n",
       " 12980: 469,\n",
       " 15261: 470,\n",
       " 19173: 471,\n",
       " 21872: 472,\n",
       " 20345: 473,\n",
       " 41658: 474,\n",
       " 18479: 475,\n",
       " 49191: 476,\n",
       " 20734: 477,\n",
       " 22849: 478,\n",
       " 4086: 479,\n",
       " 36724: 480,\n",
       " 17316: 481,\n",
       " 5373: 482,\n",
       " 26497: 483,\n",
       " 20738: 484,\n",
       " 44799: 485,\n",
       " 20574: 486,\n",
       " 5161: 487,\n",
       " 35914: 488,\n",
       " 22959: 489,\n",
       " 37524: 490,\n",
       " 6948: 491,\n",
       " 12845: 492,\n",
       " 4656: 493,\n",
       " 17758: 494,\n",
       " 47630: 495,\n",
       " 26348: 496,\n",
       " 25513: 497,\n",
       " 33055: 498,\n",
       " 34584: 499,\n",
       " 11712: 500,\n",
       " 21543: 501,\n",
       " 15649: 502,\n",
       " 35887: 503,\n",
       " 31720: 504,\n",
       " 18926: 505,\n",
       " 40198: 506,\n",
       " 48697: 507,\n",
       " 49131: 508,\n",
       " 39108: 509,\n",
       " 6740: 510,\n",
       " 18963: 511,\n",
       " 31651: 512,\n",
       " 23543: 513,\n",
       " 45104: 514,\n",
       " 5612: 515,\n",
       " 36316: 516,\n",
       " 40377: 517,\n",
       " 30406: 518,\n",
       " 7500: 519,\n",
       " 11512: 520,\n",
       " 44008: 521,\n",
       " 9755: 522,\n",
       " 30639: 523,\n",
       " 44661: 524,\n",
       " 36082: 525,\n",
       " 18656: 526,\n",
       " 23516: 527,\n",
       " 24221: 528,\n",
       " 40063: 529,\n",
       " 10305: 530,\n",
       " 46069: 531,\n",
       " 32303: 532,\n",
       " 13838: 533,\n",
       " 12576: 534,\n",
       " 32403: 535,\n",
       " 12409: 536,\n",
       " 45504: 537,\n",
       " 12872: 538,\n",
       " 43129: 539,\n",
       " 28427: 540,\n",
       " 2450: 541,\n",
       " 39581: 542,\n",
       " 30353: 543,\n",
       " 25718: 544,\n",
       " 11759: 545,\n",
       " 31215: 546,\n",
       " 34668: 547,\n",
       " 47912: 548,\n",
       " 48559: 549,\n",
       " 46842: 550,\n",
       " 30696: 551,\n",
       " 26317: 552,\n",
       " 29941: 553,\n",
       " 25640: 554,\n",
       " 14715: 555,\n",
       " 27690: 556,\n",
       " 6631: 557,\n",
       " 28553: 558,\n",
       " 15392: 559,\n",
       " 43875: 560,\n",
       " 2091: 561,\n",
       " 35163: 562,\n",
       " 1529: 563,\n",
       " 36929: 564,\n",
       " 32747: 565,\n",
       " 41400: 566,\n",
       " 38996: 567,\n",
       " 39558: 568,\n",
       " 13263: 569,\n",
       " 25753: 570,\n",
       " 5550: 571,\n",
       " 31981: 572,\n",
       " 24009: 573,\n",
       " 7628: 574,\n",
       " 14218: 575,\n",
       " 11576: 576,\n",
       " 45948: 577,\n",
       " 23236: 578,\n",
       " 46149: 579,\n",
       " 5652: 580,\n",
       " 14852: 581,\n",
       " 17652: 582,\n",
       " 49533: 583,\n",
       " 12099: 584,\n",
       " 31766: 585,\n",
       " 14129: 586,\n",
       " 22142: 587,\n",
       " 43394: 588,\n",
       " 20940: 589,\n",
       " 11440: 590,\n",
       " 17284: 591,\n",
       " 4461: 592,\n",
       " 14651: 593,\n",
       " 34217: 594,\n",
       " 14633: 595,\n",
       " 7156: 596,\n",
       " 28928: 597,\n",
       " 46886: 598,\n",
       " 41149: 599,\n",
       " 32465: 600,\n",
       " 24810: 601,\n",
       " 29926: 602,\n",
       " 10831: 603,\n",
       " 38772: 604,\n",
       " 48395: 605,\n",
       " 6489: 606,\n",
       " 781: 607,\n",
       " 42557: 608,\n",
       " 10912: 609,\n",
       " 47788: 610,\n",
       " 32429: 611,\n",
       " 2120: 612,\n",
       " 34466: 613,\n",
       " 18594: 614,\n",
       " 40268: 615,\n",
       " 311: 616,\n",
       " 2326: 617,\n",
       " 35004: 618,\n",
       " 7485: 619,\n",
       " 8138: 620,\n",
       " 29675: 621,\n",
       " 9515: 622,\n",
       " 10385: 623,\n",
       " 5240: 624,\n",
       " 33043: 625,\n",
       " 2846: 626,\n",
       " 3142: 627,\n",
       " 12276: 628,\n",
       " 5068: 629,\n",
       " 16616: 630,\n",
       " 38200: 631,\n",
       " 36772: 632,\n",
       " 4367: 633,\n",
       " 19006: 634,\n",
       " 29127: 635,\n",
       " 31433: 636,\n",
       " 4793: 637,\n",
       " 34134: 638,\n",
       " 12745: 639,\n",
       " 13292: 640,\n",
       " 48104: 641,\n",
       " 37119: 642,\n",
       " 44234: 643,\n",
       " 17224: 644,\n",
       " 47792: 645,\n",
       " 3583: 646,\n",
       " 46522: 647,\n",
       " 23405: 648,\n",
       " 44479: 649,\n",
       " 16254: 650,\n",
       " 8555: 651,\n",
       " 34530: 652,\n",
       " 37065: 653,\n",
       " 22025: 654,\n",
       " 16145: 655,\n",
       " 9808: 656,\n",
       " 19816: 657,\n",
       " 4942: 658,\n",
       " 38650: 659,\n",
       " 365: 660,\n",
       " 14901: 661,\n",
       " 39040: 662,\n",
       " 30305: 663,\n",
       " 1700: 664,\n",
       " 33548: 665,\n",
       " 14870: 666,\n",
       " 42460: 667,\n",
       " 1408: 668,\n",
       " 32566: 669,\n",
       " 20580: 670,\n",
       " 16262: 671,\n",
       " 16617: 672,\n",
       " 17429: 673,\n",
       " 45646: 674,\n",
       " 10504: 675,\n",
       " 42495: 676,\n",
       " 23579: 677,\n",
       " 40910: 678,\n",
       " 27243: 679,\n",
       " 44156: 680,\n",
       " 10603: 681,\n",
       " 7644: 682,\n",
       " 31869: 683,\n",
       " 12384: 684,\n",
       " 13083: 685,\n",
       " 48857: 686,\n",
       " 46226: 687,\n",
       " 45763: 688,\n",
       " 2962: 689,\n",
       " 14168: 690,\n",
       " 23622: 691,\n",
       " 28278: 692,\n",
       " 12614: 693,\n",
       " 24759: 694,\n",
       " 9337: 695,\n",
       " 31964: 696,\n",
       " 29370: 697,\n",
       " 3990: 698,\n",
       " 5460: 699,\n",
       " 38890: 700,\n",
       " 8955: 701,\n",
       " 21009: 702,\n",
       " 26128: 703,\n",
       " 33716: 704,\n",
       " 7131: 705,\n",
       " 8479: 706,\n",
       " 1090: 707,\n",
       " 31759: 708,\n",
       " 39922: 709,\n",
       " 17616: 710,\n",
       " 10621: 711,\n",
       " 22504: 712,\n",
       " 3481: 713,\n",
       " 46692: 714,\n",
       " 24535: 715,\n",
       " 18880: 716,\n",
       " 28373: 717,\n",
       " 17341: 718,\n",
       " 6532: 719,\n",
       " 32455: 720,\n",
       " 20754: 721,\n",
       " 23765: 722,\n",
       " 4724: 723,\n",
       " 16823: 724,\n",
       " 17835: 725,\n",
       " 25005: 726,\n",
       " 36389: 727,\n",
       " 30949: 728,\n",
       " 8230: 729,\n",
       " 30442: 730,\n",
       " 49610: 731,\n",
       " 26131: 732,\n",
       " 21417: 733,\n",
       " 16589: 734,\n",
       " 23233: 735,\n",
       " 9124: 736,\n",
       " 19156: 737,\n",
       " 36086: 738,\n",
       " 28123: 739,\n",
       " 45063: 740,\n",
       " 17008: 741,\n",
       " 33572: 742,\n",
       " 28535: 743,\n",
       " 1215: 744,\n",
       " 2611: 745,\n",
       " 38944: 746,\n",
       " 11352: 747,\n",
       " 29553: 748,\n",
       " 45747: 749,\n",
       " 8087: 750,\n",
       " 24082: 751,\n",
       " 31562: 752,\n",
       " 6287: 753,\n",
       " 7521: 754,\n",
       " 9741: 755,\n",
       " 19894: 756,\n",
       " 38028: 757,\n",
       " 41544: 758,\n",
       " 21614: 759,\n",
       " 4138: 760,\n",
       " 40593: 761,\n",
       " 31805: 762,\n",
       " 14467: 763,\n",
       " 37825: 764,\n",
       " 33352: 765,\n",
       " 12606: 766,\n",
       " 13819: 767,\n",
       " 48171: 768,\n",
       " 10814: 769,\n",
       " 17807: 770,\n",
       " 47029: 771,\n",
       " 47601: 772,\n",
       " 10032: 773,\n",
       " 13431: 774,\n",
       " 35383: 775,\n",
       " 18382: 776,\n",
       " 1559: 777,\n",
       " 42803: 778,\n",
       " 3020: 779,\n",
       " 46061: 780,\n",
       " 48595: 781,\n",
       " 45570: 782,\n",
       " 17630: 783,\n",
       " 23341: 784,\n",
       " 22888: 785,\n",
       " 23801: 786,\n",
       " 9366: 787,\n",
       " 17902: 788,\n",
       " 18434: 789,\n",
       " 18987: 790,\n",
       " 29594: 791,\n",
       " 581: 792,\n",
       " 19003: 793,\n",
       " 20632: 794,\n",
       " 43631: 795,\n",
       " 24382: 796,\n",
       " 15200: 797,\n",
       " 5449: 798,\n",
       " 38656: 799,\n",
       " 39121: 800,\n",
       " 17878: 801,\n",
       " 41319: 802,\n",
       " 7916: 803,\n",
       " 25837: 804,\n",
       " 39097: 805,\n",
       " 19488: 806,\n",
       " 9421: 807,\n",
       " 8490: 808,\n",
       " 11461: 809,\n",
       " 27360: 810,\n",
       " 24010: 811,\n",
       " 6615: 812,\n",
       " 34551: 813,\n",
       " 5337: 814,\n",
       " 9550: 815,\n",
       " 37011: 816,\n",
       " 46650: 817,\n",
       " 34: 818,\n",
       " 31371: 819,\n",
       " 41259: 820,\n",
       " 41540: 821,\n",
       " 47866: 822,\n",
       " 7806: 823,\n",
       " 21497: 824,\n",
       " 34234: 825,\n",
       " 47492: 826,\n",
       " 46900: 827,\n",
       " 6347: 828,\n",
       " 44514: 829,\n",
       " 12427: 830,\n",
       " 11136: 831,\n",
       " 33290: 832,\n",
       " 31338: 833,\n",
       " 41276: 834,\n",
       " 14778: 835,\n",
       " 46049: 836,\n",
       " 19478: 837,\n",
       " 4149: 838,\n",
       " 46041: 839,\n",
       " 42240: 840,\n",
       " 38274: 841,\n",
       " 14999: 842,\n",
       " 8467: 843,\n",
       " 22260: 844,\n",
       " 23296: 845,\n",
       " 248: 846,\n",
       " 33636: 847,\n",
       " 45013: 848,\n",
       " 10761: 849,\n",
       " 27307: 850,\n",
       " 28785: 851,\n",
       " 29615: 852,\n",
       " 2180: 853,\n",
       " 43643: 854,\n",
       " 44471: 855,\n",
       " 41593: 856,\n",
       " 2716: 857,\n",
       " 29898: 858,\n",
       " 16290: 859,\n",
       " 9327: 860,\n",
       " 49247: 861,\n",
       " 24390: 862,\n",
       " 47890: 863,\n",
       " 10473: 864,\n",
       " 38544: 865,\n",
       " 35233: 866,\n",
       " 14897: 867,\n",
       " 19049: 868,\n",
       " 3849: 869,\n",
       " 44375: 870,\n",
       " 8239: 871,\n",
       " 47357: 872,\n",
       " 44292: 873,\n",
       " 13802: 874,\n",
       " 36127: 875,\n",
       " 23645: 876,\n",
       " 30480: 877,\n",
       " 18599: 878,\n",
       " 4006: 879,\n",
       " 25133: 880,\n",
       " 20899: 881,\n",
       " 20520: 882,\n",
       " 18564: 883,\n",
       " 5991: 884,\n",
       " 49111: 885,\n",
       " 45681: 886,\n",
       " 38444: 887,\n",
       " 5031: 888,\n",
       " 49478: 889,\n",
       " 45106: 890,\n",
       " 4137: 891,\n",
       " 40002: 892,\n",
       " 5618: 893,\n",
       " 4962: 894,\n",
       " 31663: 895,\n",
       " 33065: 896,\n",
       " 11941: 897,\n",
       " 18019: 898,\n",
       " 48726: 899,\n",
       " 5959: 900,\n",
       " 8736: 901,\n",
       " 14332: 902,\n",
       " 26914: 903,\n",
       " 23044: 904,\n",
       " 26047: 905,\n",
       " 13712: 906,\n",
       " 40348: 907,\n",
       " 20583: 908,\n",
       " 44310: 909,\n",
       " 25544: 910,\n",
       " 33846: 911,\n",
       " 47087: 912,\n",
       " 25705: 913,\n",
       " 47526: 914,\n",
       " 12312: 915,\n",
       " 22802: 916,\n",
       " 7054: 917,\n",
       " 22151: 918,\n",
       " 1695: 919,\n",
       " 46175: 920,\n",
       " 48057: 921,\n",
       " 13852: 922,\n",
       " 23554: 923,\n",
       " 17027: 924,\n",
       " 28597: 925,\n",
       " 32650: 926,\n",
       " 35336: 927,\n",
       " 49605: 928,\n",
       " 16283: 929,\n",
       " 35168: 930,\n",
       " 31927: 931,\n",
       " 28851: 932,\n",
       " 26882: 933,\n",
       " 45064: 934,\n",
       " 46088: 935,\n",
       " 28986: 936,\n",
       " 10369: 937,\n",
       " 43867: 938,\n",
       " 41757: 939,\n",
       " 41273: 940,\n",
       " 5250: 941,\n",
       " 47877: 942,\n",
       " 24850: 943,\n",
       " 27683: 944,\n",
       " 16249: 945,\n",
       " 19068: 946,\n",
       " 7952: 947,\n",
       " 38312: 948,\n",
       " 46346: 949,\n",
       " 3999: 950,\n",
       " 45866: 951,\n",
       " 9623: 952,\n",
       " 46206: 953,\n",
       " 32740: 954,\n",
       " 49215: 955,\n",
       " 13113: 956,\n",
       " 46990: 957,\n",
       " 34024: 958,\n",
       " 4796: 959,\n",
       " 25197: 960,\n",
       " 31640: 961,\n",
       " 11123: 962,\n",
       " 12254: 963,\n",
       " 37464: 964,\n",
       " 13702: 965,\n",
       " 9018: 966,\n",
       " 5491: 967,\n",
       " 18352: 968,\n",
       " 20919: 969,\n",
       " 26648: 970,\n",
       " 21162: 971,\n",
       " 43409: 972,\n",
       " 26629: 973,\n",
       " 44643: 974,\n",
       " 26172: 975,\n",
       " 10326: 976,\n",
       " 40229: 977,\n",
       " 32578: 978,\n",
       " 13885: 979,\n",
       " 12545: 980,\n",
       " 1468: 981,\n",
       " 39216: 982,\n",
       " 9598: 983,\n",
       " 10106: 984,\n",
       " 25256: 985,\n",
       " 2361: 986,\n",
       " 18670: 987,\n",
       " 22556: 988,\n",
       " 12797: 989,\n",
       " 2480: 990,\n",
       " 4945: 991,\n",
       " 13966: 992,\n",
       " 7746: 993,\n",
       " 35199: 994,\n",
       " 45190: 995,\n",
       " 18023: 996,\n",
       " 20378: 997,\n",
       " 43014: 998,\n",
       " 3339: 999}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49c21e9d-5353-4bf5-bf77-fdf6f53052c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#an reversed dictionary for decode the product indices\n",
    "idx_to_product = {value:key for (key,value) in product_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecdad17e-ef76-4ff8-ad12-4b0dd1d0c8a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 24852,\n",
       " 2: 13176,\n",
       " 3: 21137,\n",
       " 4: 21903,\n",
       " 5: 47209,\n",
       " 6: 47766,\n",
       " 7: 47626,\n",
       " 8: 16797,\n",
       " 9: 26209,\n",
       " 10: 27845,\n",
       " 11: 27966,\n",
       " 12: 22935,\n",
       " 13: 24964,\n",
       " 14: 45007,\n",
       " 15: 39275,\n",
       " 16: 49683,\n",
       " 17: 28204,\n",
       " 18: 5876,\n",
       " 19: 8277,\n",
       " 20: 40706,\n",
       " 21: 4920,\n",
       " 22: 30391,\n",
       " 23: 45066,\n",
       " 24: 42265,\n",
       " 25: 49235,\n",
       " 26: 44632,\n",
       " 27: 19057,\n",
       " 28: 4605,\n",
       " 29: 37646,\n",
       " 30: 21616,\n",
       " 31: 17794,\n",
       " 32: 27104,\n",
       " 33: 30489,\n",
       " 34: 31717,\n",
       " 35: 27086,\n",
       " 36: 44359,\n",
       " 37: 28985,\n",
       " 38: 46979,\n",
       " 39: 8518,\n",
       " 40: 41950,\n",
       " 41: 26604,\n",
       " 42: 5077,\n",
       " 43: 34126,\n",
       " 44: 22035,\n",
       " 45: 39877,\n",
       " 46: 35951,\n",
       " 47: 43352,\n",
       " 48: 10749,\n",
       " 49: 19660,\n",
       " 50: 9076,\n",
       " 51: 21938,\n",
       " 52: 43961,\n",
       " 53: 24184,\n",
       " 54: 34969,\n",
       " 55: 46667,\n",
       " 56: 48679,\n",
       " 57: 25890,\n",
       " 58: 31506,\n",
       " 59: 12341,\n",
       " 60: 39928,\n",
       " 61: 24838,\n",
       " 62: 5450,\n",
       " 63: 22825,\n",
       " 64: 5785,\n",
       " 65: 35221,\n",
       " 66: 28842,\n",
       " 67: 33731,\n",
       " 68: 27521,\n",
       " 69: 44142,\n",
       " 70: 33198,\n",
       " 71: 8174,\n",
       " 72: 20114,\n",
       " 73: 8424,\n",
       " 74: 27344,\n",
       " 75: 11520,\n",
       " 76: 29487,\n",
       " 77: 18465,\n",
       " 78: 28199,\n",
       " 79: 15290,\n",
       " 80: 46906,\n",
       " 81: 9839,\n",
       " 82: 27156,\n",
       " 83: 3957,\n",
       " 84: 43122,\n",
       " 85: 23909,\n",
       " 86: 34358,\n",
       " 87: 4799,\n",
       " 88: 9387,\n",
       " 89: 16759,\n",
       " 90: 196,\n",
       " 91: 42736,\n",
       " 92: 38689,\n",
       " 93: 4210,\n",
       " 94: 41787,\n",
       " 95: 41220,\n",
       " 96: 47144,\n",
       " 97: 7781,\n",
       " 98: 33000,\n",
       " 99: 20995,\n",
       " 100: 21709,\n",
       " 101: 19678,\n",
       " 102: 40604,\n",
       " 103: 30233,\n",
       " 104: 34243,\n",
       " 105: 37687,\n",
       " 106: 24489,\n",
       " 107: 42828,\n",
       " 108: 5479,\n",
       " 109: 432,\n",
       " 110: 6184,\n",
       " 111: 16185,\n",
       " 112: 42768,\n",
       " 113: 17948,\n",
       " 114: 33754,\n",
       " 115: 19348,\n",
       " 116: 8193,\n",
       " 117: 26369,\n",
       " 118: 42585,\n",
       " 119: 14992,\n",
       " 120: 14947,\n",
       " 121: 22963,\n",
       " 122: 1463,\n",
       " 123: 28849,\n",
       " 124: 8021,\n",
       " 125: 25659,\n",
       " 126: 21405,\n",
       " 127: 46676,\n",
       " 128: 31343,\n",
       " 129: 41844,\n",
       " 130: 38293,\n",
       " 131: 42701,\n",
       " 132: 43789,\n",
       " 133: 36011,\n",
       " 134: 5025,\n",
       " 135: 39475,\n",
       " 136: 43295,\n",
       " 137: 11777,\n",
       " 138: 20842,\n",
       " 139: 32689,\n",
       " 140: 32655,\n",
       " 141: 2295,\n",
       " 142: 46802,\n",
       " 143: 13870,\n",
       " 144: 25146,\n",
       " 145: 18531,\n",
       " 146: 5212,\n",
       " 147: 31553,\n",
       " 148: 39408,\n",
       " 149: 260,\n",
       " 150: 36695,\n",
       " 151: 10246,\n",
       " 152: 24830,\n",
       " 153: 38383,\n",
       " 154: 43768,\n",
       " 155: 1940,\n",
       " 156: 11182,\n",
       " 157: 18523,\n",
       " 158: 18362,\n",
       " 159: 21288,\n",
       " 160: 6046,\n",
       " 161: 44683,\n",
       " 162: 29987,\n",
       " 163: 890,\n",
       " 164: 38777,\n",
       " 165: 43772,\n",
       " 166: 23734,\n",
       " 167: 7948,\n",
       " 168: 30450,\n",
       " 169: 38456,\n",
       " 170: 46969,\n",
       " 171: 44910,\n",
       " 172: 47734,\n",
       " 173: 38159,\n",
       " 174: 26620,\n",
       " 175: 47672,\n",
       " 176: 4957,\n",
       " 177: 26165,\n",
       " 178: 30776,\n",
       " 179: 44987,\n",
       " 180: 35939,\n",
       " 181: 14678,\n",
       " 182: 16349,\n",
       " 183: 28289,\n",
       " 184: 29447,\n",
       " 185: 44422,\n",
       " 186: 40310,\n",
       " 187: 16953,\n",
       " 188: 23375,\n",
       " 189: 33787,\n",
       " 190: 19048,\n",
       " 191: 2078,\n",
       " 192: 13984,\n",
       " 193: 41290,\n",
       " 194: 23165,\n",
       " 195: 32864,\n",
       " 196: 17600,\n",
       " 197: 39812,\n",
       " 198: 8859,\n",
       " 199: 48364,\n",
       " 200: 33120,\n",
       " 201: 31683,\n",
       " 202: 26940,\n",
       " 203: 28465,\n",
       " 204: 35108,\n",
       " 205: 26283,\n",
       " 206: 37158,\n",
       " 207: 37067,\n",
       " 208: 18370,\n",
       " 209: 45,\n",
       " 210: 41665,\n",
       " 211: 35547,\n",
       " 212: 3952,\n",
       " 213: 10957,\n",
       " 214: 2086,\n",
       " 215: 2966,\n",
       " 216: 43154,\n",
       " 217: 24799,\n",
       " 218: 40571,\n",
       " 219: 10132,\n",
       " 220: 43713,\n",
       " 221: 40396,\n",
       " 222: 18027,\n",
       " 223: 45535,\n",
       " 224: 1158,\n",
       " 225: 25931,\n",
       " 226: 7021,\n",
       " 227: 38739,\n",
       " 228: 13629,\n",
       " 229: 42450,\n",
       " 230: 20119,\n",
       " 231: 15937,\n",
       " 232: 42342,\n",
       " 233: 32478,\n",
       " 234: 48745,\n",
       " 235: 45633,\n",
       " 236: 21019,\n",
       " 237: 34050,\n",
       " 238: 34448,\n",
       " 239: 48205,\n",
       " 240: 39619,\n",
       " 241: 17461,\n",
       " 242: 45603,\n",
       " 243: 30169,\n",
       " 244: 31040,\n",
       " 245: 38400,\n",
       " 246: 13646,\n",
       " 247: 36865,\n",
       " 248: 40174,\n",
       " 249: 21267,\n",
       " 250: 17872,\n",
       " 251: 5818,\n",
       " 252: 26790,\n",
       " 253: 39984,\n",
       " 254: 14084,\n",
       " 255: 23288,\n",
       " 256: 21376,\n",
       " 257: 32734,\n",
       " 258: 33768,\n",
       " 259: 37766,\n",
       " 260: 46654,\n",
       " 261: 12206,\n",
       " 262: 329,\n",
       " 263: 28934,\n",
       " 264: 6187,\n",
       " 265: 6348,\n",
       " 266: 39993,\n",
       " 267: 18441,\n",
       " 268: 5646,\n",
       " 269: 25340,\n",
       " 270: 43086,\n",
       " 271: 6104,\n",
       " 272: 42356,\n",
       " 273: 48775,\n",
       " 274: 651,\n",
       " 275: 10673,\n",
       " 276: 47977,\n",
       " 277: 19508,\n",
       " 278: 39180,\n",
       " 279: 40709,\n",
       " 280: 19677,\n",
       " 281: 10017,\n",
       " 282: 27336,\n",
       " 283: 13535,\n",
       " 284: 13829,\n",
       " 285: 42244,\n",
       " 286: 11782,\n",
       " 287: 27695,\n",
       " 288: 36070,\n",
       " 289: 28156,\n",
       " 290: 6873,\n",
       " 291: 49520,\n",
       " 292: 49383,\n",
       " 293: 8571,\n",
       " 294: 24561,\n",
       " 295: 13249,\n",
       " 296: 49075,\n",
       " 297: 16083,\n",
       " 298: 24024,\n",
       " 299: 40545,\n",
       " 300: 40199,\n",
       " 301: 30720,\n",
       " 302: 17795,\n",
       " 303: 25588,\n",
       " 304: 35921,\n",
       " 305: 17122,\n",
       " 306: 11422,\n",
       " 307: 8670,\n",
       " 308: 31915,\n",
       " 309: 35561,\n",
       " 310: 42445,\n",
       " 311: 14233,\n",
       " 312: 7963,\n",
       " 313: 17706,\n",
       " 314: 3599,\n",
       " 315: 21295,\n",
       " 316: 44449,\n",
       " 317: 36550,\n",
       " 318: 19019,\n",
       " 319: 30827,\n",
       " 320: 20082,\n",
       " 321: 35042,\n",
       " 322: 25466,\n",
       " 323: 33401,\n",
       " 324: 1511,\n",
       " 325: 42625,\n",
       " 326: 5194,\n",
       " 327: 8048,\n",
       " 328: 23537,\n",
       " 329: 2825,\n",
       " 330: 16965,\n",
       " 331: 38928,\n",
       " 332: 21195,\n",
       " 333: 19706,\n",
       " 334: 18288,\n",
       " 335: 13380,\n",
       " 336: 7751,\n",
       " 337: 15872,\n",
       " 338: 4562,\n",
       " 339: 9339,\n",
       " 340: 22395,\n",
       " 341: 38164,\n",
       " 342: 46720,\n",
       " 343: 40723,\n",
       " 344: 15902,\n",
       " 345: 35140,\n",
       " 346: 4472,\n",
       " 347: 3376,\n",
       " 348: 13166,\n",
       " 349: 29662,\n",
       " 350: 2855,\n",
       " 351: 28993,\n",
       " 352: 7175,\n",
       " 353: 13575,\n",
       " 354: 13740,\n",
       " 355: 12916,\n",
       " 356: 40516,\n",
       " 357: 45200,\n",
       " 358: 7503,\n",
       " 359: 5782,\n",
       " 360: 19691,\n",
       " 361: 5134,\n",
       " 362: 40332,\n",
       " 363: 12456,\n",
       " 364: 21174,\n",
       " 365: 5258,\n",
       " 366: 10644,\n",
       " 367: 39561,\n",
       " 368: 4421,\n",
       " 369: 33129,\n",
       " 370: 44765,\n",
       " 371: 20955,\n",
       " 372: 46584,\n",
       " 373: 22124,\n",
       " 374: 44570,\n",
       " 375: 3464,\n",
       " 376: 13198,\n",
       " 377: 43662,\n",
       " 378: 10070,\n",
       " 379: 32691,\n",
       " 380: 7559,\n",
       " 381: 37710,\n",
       " 382: 36735,\n",
       " 383: 35898,\n",
       " 384: 37029,\n",
       " 385: 34262,\n",
       " 386: 1025,\n",
       " 387: 18918,\n",
       " 388: 42719,\n",
       " 389: 11408,\n",
       " 390: 18234,\n",
       " 391: 44560,\n",
       " 392: 23029,\n",
       " 393: 45123,\n",
       " 394: 3896,\n",
       " 395: 9092,\n",
       " 396: 28745,\n",
       " 397: 18811,\n",
       " 398: 26384,\n",
       " 399: 35503,\n",
       " 400: 35628,\n",
       " 401: 47141,\n",
       " 402: 28476,\n",
       " 403: 25138,\n",
       " 404: 21386,\n",
       " 405: 47042,\n",
       " 406: 46820,\n",
       " 407: 21292,\n",
       " 408: 11140,\n",
       " 409: 21573,\n",
       " 410: 38768,\n",
       " 411: 17949,\n",
       " 412: 1999,\n",
       " 413: 14197,\n",
       " 414: 46616,\n",
       " 415: 32433,\n",
       " 416: 47759,\n",
       " 417: 37220,\n",
       " 418: 39947,\n",
       " 419: 24954,\n",
       " 420: 41065,\n",
       " 421: 21333,\n",
       " 422: 25824,\n",
       " 423: 48628,\n",
       " 424: 1194,\n",
       " 425: 43504,\n",
       " 426: 44628,\n",
       " 427: 5456,\n",
       " 428: 38273,\n",
       " 429: 15613,\n",
       " 430: 35535,\n",
       " 431: 15424,\n",
       " 432: 27548,\n",
       " 433: 24841,\n",
       " 434: 39190,\n",
       " 435: 27730,\n",
       " 436: 42110,\n",
       " 437: 29307,\n",
       " 438: 14161,\n",
       " 439: 49175,\n",
       " 440: 14462,\n",
       " 441: 31066,\n",
       " 442: 16696,\n",
       " 443: 26800,\n",
       " 444: 9825,\n",
       " 445: 5322,\n",
       " 446: 27744,\n",
       " 447: 8309,\n",
       " 448: 11005,\n",
       " 449: 41588,\n",
       " 450: 11068,\n",
       " 451: 27796,\n",
       " 452: 27325,\n",
       " 453: 2228,\n",
       " 454: 7969,\n",
       " 455: 22474,\n",
       " 456: 9020,\n",
       " 457: 16521,\n",
       " 458: 3298,\n",
       " 459: 5769,\n",
       " 460: 1244,\n",
       " 461: 13517,\n",
       " 462: 27323,\n",
       " 463: 2452,\n",
       " 464: 28601,\n",
       " 465: 2314,\n",
       " 466: 21927,\n",
       " 467: 32177,\n",
       " 468: 13733,\n",
       " 469: 12980,\n",
       " 470: 15261,\n",
       " 471: 19173,\n",
       " 472: 21872,\n",
       " 473: 20345,\n",
       " 474: 41658,\n",
       " 475: 18479,\n",
       " 476: 49191,\n",
       " 477: 20734,\n",
       " 478: 22849,\n",
       " 479: 4086,\n",
       " 480: 36724,\n",
       " 481: 17316,\n",
       " 482: 5373,\n",
       " 483: 26497,\n",
       " 484: 20738,\n",
       " 485: 44799,\n",
       " 486: 20574,\n",
       " 487: 5161,\n",
       " 488: 35914,\n",
       " 489: 22959,\n",
       " 490: 37524,\n",
       " 491: 6948,\n",
       " 492: 12845,\n",
       " 493: 4656,\n",
       " 494: 17758,\n",
       " 495: 47630,\n",
       " 496: 26348,\n",
       " 497: 25513,\n",
       " 498: 33055,\n",
       " 499: 34584,\n",
       " 500: 11712,\n",
       " 501: 21543,\n",
       " 502: 15649,\n",
       " 503: 35887,\n",
       " 504: 31720,\n",
       " 505: 18926,\n",
       " 506: 40198,\n",
       " 507: 48697,\n",
       " 508: 49131,\n",
       " 509: 39108,\n",
       " 510: 6740,\n",
       " 511: 18963,\n",
       " 512: 31651,\n",
       " 513: 23543,\n",
       " 514: 45104,\n",
       " 515: 5612,\n",
       " 516: 36316,\n",
       " 517: 40377,\n",
       " 518: 30406,\n",
       " 519: 7500,\n",
       " 520: 11512,\n",
       " 521: 44008,\n",
       " 522: 9755,\n",
       " 523: 30639,\n",
       " 524: 44661,\n",
       " 525: 36082,\n",
       " 526: 18656,\n",
       " 527: 23516,\n",
       " 528: 24221,\n",
       " 529: 40063,\n",
       " 530: 10305,\n",
       " 531: 46069,\n",
       " 532: 32303,\n",
       " 533: 13838,\n",
       " 534: 12576,\n",
       " 535: 32403,\n",
       " 536: 12409,\n",
       " 537: 45504,\n",
       " 538: 12872,\n",
       " 539: 43129,\n",
       " 540: 28427,\n",
       " 541: 2450,\n",
       " 542: 39581,\n",
       " 543: 30353,\n",
       " 544: 25718,\n",
       " 545: 11759,\n",
       " 546: 31215,\n",
       " 547: 34668,\n",
       " 548: 47912,\n",
       " 549: 48559,\n",
       " 550: 46842,\n",
       " 551: 30696,\n",
       " 552: 26317,\n",
       " 553: 29941,\n",
       " 554: 25640,\n",
       " 555: 14715,\n",
       " 556: 27690,\n",
       " 557: 6631,\n",
       " 558: 28553,\n",
       " 559: 15392,\n",
       " 560: 43875,\n",
       " 561: 2091,\n",
       " 562: 35163,\n",
       " 563: 1529,\n",
       " 564: 36929,\n",
       " 565: 32747,\n",
       " 566: 41400,\n",
       " 567: 38996,\n",
       " 568: 39558,\n",
       " 569: 13263,\n",
       " 570: 25753,\n",
       " 571: 5550,\n",
       " 572: 31981,\n",
       " 573: 24009,\n",
       " 574: 7628,\n",
       " 575: 14218,\n",
       " 576: 11576,\n",
       " 577: 45948,\n",
       " 578: 23236,\n",
       " 579: 46149,\n",
       " 580: 5652,\n",
       " 581: 14852,\n",
       " 582: 17652,\n",
       " 583: 49533,\n",
       " 584: 12099,\n",
       " 585: 31766,\n",
       " 586: 14129,\n",
       " 587: 22142,\n",
       " 588: 43394,\n",
       " 589: 20940,\n",
       " 590: 11440,\n",
       " 591: 17284,\n",
       " 592: 4461,\n",
       " 593: 14651,\n",
       " 594: 34217,\n",
       " 595: 14633,\n",
       " 596: 7156,\n",
       " 597: 28928,\n",
       " 598: 46886,\n",
       " 599: 41149,\n",
       " 600: 32465,\n",
       " 601: 24810,\n",
       " 602: 29926,\n",
       " 603: 10831,\n",
       " 604: 38772,\n",
       " 605: 48395,\n",
       " 606: 6489,\n",
       " 607: 781,\n",
       " 608: 42557,\n",
       " 609: 10912,\n",
       " 610: 47788,\n",
       " 611: 32429,\n",
       " 612: 2120,\n",
       " 613: 34466,\n",
       " 614: 18594,\n",
       " 615: 40268,\n",
       " 616: 311,\n",
       " 617: 2326,\n",
       " 618: 35004,\n",
       " 619: 7485,\n",
       " 620: 8138,\n",
       " 621: 29675,\n",
       " 622: 9515,\n",
       " 623: 10385,\n",
       " 624: 5240,\n",
       " 625: 33043,\n",
       " 626: 2846,\n",
       " 627: 3142,\n",
       " 628: 12276,\n",
       " 629: 5068,\n",
       " 630: 16616,\n",
       " 631: 38200,\n",
       " 632: 36772,\n",
       " 633: 4367,\n",
       " 634: 19006,\n",
       " 635: 29127,\n",
       " 636: 31433,\n",
       " 637: 4793,\n",
       " 638: 34134,\n",
       " 639: 12745,\n",
       " 640: 13292,\n",
       " 641: 48104,\n",
       " 642: 37119,\n",
       " 643: 44234,\n",
       " 644: 17224,\n",
       " 645: 47792,\n",
       " 646: 3583,\n",
       " 647: 46522,\n",
       " 648: 23405,\n",
       " 649: 44479,\n",
       " 650: 16254,\n",
       " 651: 8555,\n",
       " 652: 34530,\n",
       " 653: 37065,\n",
       " 654: 22025,\n",
       " 655: 16145,\n",
       " 656: 9808,\n",
       " 657: 19816,\n",
       " 658: 4942,\n",
       " 659: 38650,\n",
       " 660: 365,\n",
       " 661: 14901,\n",
       " 662: 39040,\n",
       " 663: 30305,\n",
       " 664: 1700,\n",
       " 665: 33548,\n",
       " 666: 14870,\n",
       " 667: 42460,\n",
       " 668: 1408,\n",
       " 669: 32566,\n",
       " 670: 20580,\n",
       " 671: 16262,\n",
       " 672: 16617,\n",
       " 673: 17429,\n",
       " 674: 45646,\n",
       " 675: 10504,\n",
       " 676: 42495,\n",
       " 677: 23579,\n",
       " 678: 40910,\n",
       " 679: 27243,\n",
       " 680: 44156,\n",
       " 681: 10603,\n",
       " 682: 7644,\n",
       " 683: 31869,\n",
       " 684: 12384,\n",
       " 685: 13083,\n",
       " 686: 48857,\n",
       " 687: 46226,\n",
       " 688: 45763,\n",
       " 689: 2962,\n",
       " 690: 14168,\n",
       " 691: 23622,\n",
       " 692: 28278,\n",
       " 693: 12614,\n",
       " 694: 24759,\n",
       " 695: 9337,\n",
       " 696: 31964,\n",
       " 697: 29370,\n",
       " 698: 3990,\n",
       " 699: 5460,\n",
       " 700: 38890,\n",
       " 701: 8955,\n",
       " 702: 21009,\n",
       " 703: 26128,\n",
       " 704: 33716,\n",
       " 705: 7131,\n",
       " 706: 8479,\n",
       " 707: 1090,\n",
       " 708: 31759,\n",
       " 709: 39922,\n",
       " 710: 17616,\n",
       " 711: 10621,\n",
       " 712: 22504,\n",
       " 713: 3481,\n",
       " 714: 46692,\n",
       " 715: 24535,\n",
       " 716: 18880,\n",
       " 717: 28373,\n",
       " 718: 17341,\n",
       " 719: 6532,\n",
       " 720: 32455,\n",
       " 721: 20754,\n",
       " 722: 23765,\n",
       " 723: 4724,\n",
       " 724: 16823,\n",
       " 725: 17835,\n",
       " 726: 25005,\n",
       " 727: 36389,\n",
       " 728: 30949,\n",
       " 729: 8230,\n",
       " 730: 30442,\n",
       " 731: 49610,\n",
       " 732: 26131,\n",
       " 733: 21417,\n",
       " 734: 16589,\n",
       " 735: 23233,\n",
       " 736: 9124,\n",
       " 737: 19156,\n",
       " 738: 36086,\n",
       " 739: 28123,\n",
       " 740: 45063,\n",
       " 741: 17008,\n",
       " 742: 33572,\n",
       " 743: 28535,\n",
       " 744: 1215,\n",
       " 745: 2611,\n",
       " 746: 38944,\n",
       " 747: 11352,\n",
       " 748: 29553,\n",
       " 749: 45747,\n",
       " 750: 8087,\n",
       " 751: 24082,\n",
       " 752: 31562,\n",
       " 753: 6287,\n",
       " 754: 7521,\n",
       " 755: 9741,\n",
       " 756: 19894,\n",
       " 757: 38028,\n",
       " 758: 41544,\n",
       " 759: 21614,\n",
       " 760: 4138,\n",
       " 761: 40593,\n",
       " 762: 31805,\n",
       " 763: 14467,\n",
       " 764: 37825,\n",
       " 765: 33352,\n",
       " 766: 12606,\n",
       " 767: 13819,\n",
       " 768: 48171,\n",
       " 769: 10814,\n",
       " 770: 17807,\n",
       " 771: 47029,\n",
       " 772: 47601,\n",
       " 773: 10032,\n",
       " 774: 13431,\n",
       " 775: 35383,\n",
       " 776: 18382,\n",
       " 777: 1559,\n",
       " 778: 42803,\n",
       " 779: 3020,\n",
       " 780: 46061,\n",
       " 781: 48595,\n",
       " 782: 45570,\n",
       " 783: 17630,\n",
       " 784: 23341,\n",
       " 785: 22888,\n",
       " 786: 23801,\n",
       " 787: 9366,\n",
       " 788: 17902,\n",
       " 789: 18434,\n",
       " 790: 18987,\n",
       " 791: 29594,\n",
       " 792: 581,\n",
       " 793: 19003,\n",
       " 794: 20632,\n",
       " 795: 43631,\n",
       " 796: 24382,\n",
       " 797: 15200,\n",
       " 798: 5449,\n",
       " 799: 38656,\n",
       " 800: 39121,\n",
       " 801: 17878,\n",
       " 802: 41319,\n",
       " 803: 7916,\n",
       " 804: 25837,\n",
       " 805: 39097,\n",
       " 806: 19488,\n",
       " 807: 9421,\n",
       " 808: 8490,\n",
       " 809: 11461,\n",
       " 810: 27360,\n",
       " 811: 24010,\n",
       " 812: 6615,\n",
       " 813: 34551,\n",
       " 814: 5337,\n",
       " 815: 9550,\n",
       " 816: 37011,\n",
       " 817: 46650,\n",
       " 818: 34,\n",
       " 819: 31371,\n",
       " 820: 41259,\n",
       " 821: 41540,\n",
       " 822: 47866,\n",
       " 823: 7806,\n",
       " 824: 21497,\n",
       " 825: 34234,\n",
       " 826: 47492,\n",
       " 827: 46900,\n",
       " 828: 6347,\n",
       " 829: 44514,\n",
       " 830: 12427,\n",
       " 831: 11136,\n",
       " 832: 33290,\n",
       " 833: 31338,\n",
       " 834: 41276,\n",
       " 835: 14778,\n",
       " 836: 46049,\n",
       " 837: 19478,\n",
       " 838: 4149,\n",
       " 839: 46041,\n",
       " 840: 42240,\n",
       " 841: 38274,\n",
       " 842: 14999,\n",
       " 843: 8467,\n",
       " 844: 22260,\n",
       " 845: 23296,\n",
       " 846: 248,\n",
       " 847: 33636,\n",
       " 848: 45013,\n",
       " 849: 10761,\n",
       " 850: 27307,\n",
       " 851: 28785,\n",
       " 852: 29615,\n",
       " 853: 2180,\n",
       " 854: 43643,\n",
       " 855: 44471,\n",
       " 856: 41593,\n",
       " 857: 2716,\n",
       " 858: 29898,\n",
       " 859: 16290,\n",
       " 860: 9327,\n",
       " 861: 49247,\n",
       " 862: 24390,\n",
       " 863: 47890,\n",
       " 864: 10473,\n",
       " 865: 38544,\n",
       " 866: 35233,\n",
       " 867: 14897,\n",
       " 868: 19049,\n",
       " 869: 3849,\n",
       " 870: 44375,\n",
       " 871: 8239,\n",
       " 872: 47357,\n",
       " 873: 44292,\n",
       " 874: 13802,\n",
       " 875: 36127,\n",
       " 876: 23645,\n",
       " 877: 30480,\n",
       " 878: 18599,\n",
       " 879: 4006,\n",
       " 880: 25133,\n",
       " 881: 20899,\n",
       " 882: 20520,\n",
       " 883: 18564,\n",
       " 884: 5991,\n",
       " 885: 49111,\n",
       " 886: 45681,\n",
       " 887: 38444,\n",
       " 888: 5031,\n",
       " 889: 49478,\n",
       " 890: 45106,\n",
       " 891: 4137,\n",
       " 892: 40002,\n",
       " 893: 5618,\n",
       " 894: 4962,\n",
       " 895: 31663,\n",
       " 896: 33065,\n",
       " 897: 11941,\n",
       " 898: 18019,\n",
       " 899: 48726,\n",
       " 900: 5959,\n",
       " 901: 8736,\n",
       " 902: 14332,\n",
       " 903: 26914,\n",
       " 904: 23044,\n",
       " 905: 26047,\n",
       " 906: 13712,\n",
       " 907: 40348,\n",
       " 908: 20583,\n",
       " 909: 44310,\n",
       " 910: 25544,\n",
       " 911: 33846,\n",
       " 912: 47087,\n",
       " 913: 25705,\n",
       " 914: 47526,\n",
       " 915: 12312,\n",
       " 916: 22802,\n",
       " 917: 7054,\n",
       " 918: 22151,\n",
       " 919: 1695,\n",
       " 920: 46175,\n",
       " 921: 48057,\n",
       " 922: 13852,\n",
       " 923: 23554,\n",
       " 924: 17027,\n",
       " 925: 28597,\n",
       " 926: 32650,\n",
       " 927: 35336,\n",
       " 928: 49605,\n",
       " 929: 16283,\n",
       " 930: 35168,\n",
       " 931: 31927,\n",
       " 932: 28851,\n",
       " 933: 26882,\n",
       " 934: 45064,\n",
       " 935: 46088,\n",
       " 936: 28986,\n",
       " 937: 10369,\n",
       " 938: 43867,\n",
       " 939: 41757,\n",
       " 940: 41273,\n",
       " 941: 5250,\n",
       " 942: 47877,\n",
       " 943: 24850,\n",
       " 944: 27683,\n",
       " 945: 16249,\n",
       " 946: 19068,\n",
       " 947: 7952,\n",
       " 948: 38312,\n",
       " 949: 46346,\n",
       " 950: 3999,\n",
       " 951: 45866,\n",
       " 952: 9623,\n",
       " 953: 46206,\n",
       " 954: 32740,\n",
       " 955: 49215,\n",
       " 956: 13113,\n",
       " 957: 46990,\n",
       " 958: 34024,\n",
       " 959: 4796,\n",
       " 960: 25197,\n",
       " 961: 31640,\n",
       " 962: 11123,\n",
       " 963: 12254,\n",
       " 964: 37464,\n",
       " 965: 13702,\n",
       " 966: 9018,\n",
       " 967: 5491,\n",
       " 968: 18352,\n",
       " 969: 20919,\n",
       " 970: 26648,\n",
       " 971: 21162,\n",
       " 972: 43409,\n",
       " 973: 26629,\n",
       " 974: 44643,\n",
       " 975: 26172,\n",
       " 976: 10326,\n",
       " 977: 40229,\n",
       " 978: 32578,\n",
       " 979: 13885,\n",
       " 980: 12545,\n",
       " 981: 1468,\n",
       " 982: 39216,\n",
       " 983: 9598,\n",
       " 984: 10106,\n",
       " 985: 25256,\n",
       " 986: 2361,\n",
       " 987: 18670,\n",
       " 988: 22556,\n",
       " 989: 12797,\n",
       " 990: 2480,\n",
       " 991: 4945,\n",
       " 992: 13966,\n",
       " 993: 7746,\n",
       " 994: 35199,\n",
       " 995: 45190,\n",
       " 996: 18023,\n",
       " 997: 20378,\n",
       " 998: 43014,\n",
       " 999: 3339}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "558e0d7d-4aa2-4dbd-9383-3b7af3e0eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new columns \"idx\" and fill all non top k products with 0\n",
    "train_df['idx'] = train_df.product_id.map(product_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c55ba089-a343-45db-9abd-4bf9e4bd5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c866c0a-b297-4200-98b4-ae29b05a021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['idx'] = train_df.idx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2214bdff-b184-4b04-89b4-422f8a4ddf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>33120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28985</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9327</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>45918</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>30035</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>17794</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>40141</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1819</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>43668</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>33754</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>24838</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>17704</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>21903</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>17668</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>46667</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>17461</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>32665</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>46842</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>26434</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>39758</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id  product_id  add_to_cart_order  reordered  idx\n",
       "0          2       33120                  1          1  200\n",
       "1          2       28985                  2          1   37\n",
       "2          2        9327                  3          0  860\n",
       "3          2       45918                  4          1    0\n",
       "4          2       30035                  5          0    0\n",
       "5          2       17794                  6          1   31\n",
       "6          2       40141                  7          1    0\n",
       "7          2        1819                  8          1    0\n",
       "8          2       43668                  9          0    0\n",
       "9          3       33754                  1          1  114\n",
       "10         3       24838                  2          1   61\n",
       "11         3       17704                  3          1    0\n",
       "12         3       21903                  4          1    4\n",
       "13         3       17668                  5          1    0\n",
       "14         3       46667                  6          1   55\n",
       "15         3       17461                  7          1  241\n",
       "16         3       32665                  8          1    0\n",
       "17         4       46842                  1          0  550\n",
       "18         4       26434                  2          1    0\n",
       "19         4       39758                  3          1    0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58d33346-91aa-4574-afe6-25b2dc7f2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = ZipFile(\"order_products__train.csv.zip\")\n",
    "val_df = pd.read_csv(zf.extract(\"order_products__train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec8f8db7-dd2e-4b58-a4cd-a721670ddf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1384617 entries, 0 to 1384616\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count    Dtype\n",
      "---  ------             --------------    -----\n",
      " 0   order_id           1384617 non-null  int64\n",
      " 1   product_id         1384617 non-null  int64\n",
      " 2   add_to_cart_order  1384617 non-null  int64\n",
      " 3   reordered          1384617 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 42.3 MB\n"
     ]
    }
   ],
   "source": [
    "val_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "226a7ebd-4df8-409b-af8d-2715dd02a5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11109</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>49683</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43633</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>13176</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>47209</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>22035</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>39612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "      <td>19660</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36</td>\n",
       "      <td>49235</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>43086</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>46620</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36</td>\n",
       "      <td>34497</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36</td>\n",
       "      <td>48679</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36</td>\n",
       "      <td>46979</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38</td>\n",
       "      <td>11913</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38</td>\n",
       "      <td>18159</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38</td>\n",
       "      <td>4461</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>38</td>\n",
       "      <td>21616</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>38</td>\n",
       "      <td>23622</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>38</td>\n",
       "      <td>32433</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>38</td>\n",
       "      <td>28842</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>38</td>\n",
       "      <td>42625</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>38</td>\n",
       "      <td>39693</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>96</td>\n",
       "      <td>20574</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>96</td>\n",
       "      <td>30391</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>96</td>\n",
       "      <td>40706</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>96</td>\n",
       "      <td>25610</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>96</td>\n",
       "      <td>27966</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>96</td>\n",
       "      <td>24489</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>96</td>\n",
       "      <td>39275</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>98</td>\n",
       "      <td>8859</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>98</td>\n",
       "      <td>19731</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>98</td>\n",
       "      <td>43654</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>98</td>\n",
       "      <td>13176</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>98</td>\n",
       "      <td>4357</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>98</td>\n",
       "      <td>37664</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>98</td>\n",
       "      <td>34065</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>98</td>\n",
       "      <td>35951</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>98</td>\n",
       "      <td>43560</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>98</td>\n",
       "      <td>9896</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>98</td>\n",
       "      <td>27509</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>98</td>\n",
       "      <td>15455</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>98</td>\n",
       "      <td>27966</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>98</td>\n",
       "      <td>47601</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>98</td>\n",
       "      <td>40396</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>98</td>\n",
       "      <td>35042</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>98</td>\n",
       "      <td>40986</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>98</td>\n",
       "      <td>1939</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id  product_id  add_to_cart_order  reordered\n",
       "0          1       49302                  1          1\n",
       "1          1       11109                  2          1\n",
       "2          1       10246                  3          0\n",
       "3          1       49683                  4          0\n",
       "4          1       43633                  5          1\n",
       "5          1       13176                  6          0\n",
       "6          1       47209                  7          0\n",
       "7          1       22035                  8          1\n",
       "8         36       39612                  1          0\n",
       "9         36       19660                  2          1\n",
       "10        36       49235                  3          0\n",
       "11        36       43086                  4          1\n",
       "12        36       46620                  5          1\n",
       "13        36       34497                  6          1\n",
       "14        36       48679                  7          1\n",
       "15        36       46979                  8          1\n",
       "16        38       11913                  1          0\n",
       "17        38       18159                  2          0\n",
       "18        38        4461                  3          0\n",
       "19        38       21616                  4          1\n",
       "20        38       23622                  5          0\n",
       "21        38       32433                  6          0\n",
       "22        38       28842                  7          0\n",
       "23        38       42625                  8          0\n",
       "24        38       39693                  9          0\n",
       "25        96       20574                  1          1\n",
       "26        96       30391                  2          0\n",
       "27        96       40706                  3          1\n",
       "28        96       25610                  4          0\n",
       "29        96       27966                  5          1\n",
       "30        96       24489                  6          1\n",
       "31        96       39275                  7          1\n",
       "32        98        8859                  1          1\n",
       "33        98       19731                  2          1\n",
       "34        98       43654                  3          1\n",
       "35        98       13176                  4          1\n",
       "36        98        4357                  5          1\n",
       "37        98       37664                  6          1\n",
       "38        98       34065                  7          1\n",
       "39        98       35951                  8          1\n",
       "40        98       43560                  9          1\n",
       "41        98        9896                 10          1\n",
       "42        98       27509                 11          1\n",
       "43        98       15455                 12          1\n",
       "44        98       27966                 13          1\n",
       "45        98       47601                 14          1\n",
       "46        98       40396                 15          1\n",
       "47        98       35042                 16          1\n",
       "48        98       40986                 17          1\n",
       "49        98        1939                 18          1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f7bb25f-219b-45b0-8ec7-0d935e779450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same thing to validation dataframe\n",
    "val_df['idx'] = val_df.product_id.map(product_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "430e1a6c-4940-4092-91f4-5cb7ca1a03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "891c2ed4-0515-4a31-9866-c3f5caafabad",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['idx'] = val_df.idx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e272906-757b-4f32-9300-cd6c45274ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11109</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>49683</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43633</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>13176</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>47209</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>22035</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>39612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "      <td>19660</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36</td>\n",
       "      <td>49235</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>43086</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>46620</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36</td>\n",
       "      <td>34497</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36</td>\n",
       "      <td>48679</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36</td>\n",
       "      <td>46979</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38</td>\n",
       "      <td>11913</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38</td>\n",
       "      <td>18159</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38</td>\n",
       "      <td>4461</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>38</td>\n",
       "      <td>21616</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id  product_id  add_to_cart_order  reordered  idx\n",
       "0          1       49302                  1          1    0\n",
       "1          1       11109                  2          1    0\n",
       "2          1       10246                  3          0  151\n",
       "3          1       49683                  4          0   16\n",
       "4          1       43633                  5          1    0\n",
       "5          1       13176                  6          0    2\n",
       "6          1       47209                  7          0    5\n",
       "7          1       22035                  8          1   44\n",
       "8         36       39612                  1          0    0\n",
       "9         36       19660                  2          1   49\n",
       "10        36       49235                  3          0   25\n",
       "11        36       43086                  4          1  270\n",
       "12        36       46620                  5          1    0\n",
       "13        36       34497                  6          1    0\n",
       "14        36       48679                  7          1   56\n",
       "15        36       46979                  8          1   38\n",
       "16        38       11913                  1          0    0\n",
       "17        38       18159                  2          0    0\n",
       "18        38        4461                  3          0  592\n",
       "19        38       21616                  4          1   30"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d18263e-005a-4883-8f08-6f3ced621967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32434469</th>\n",
       "      <td>3421081</td>\n",
       "      <td>20539</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434470</th>\n",
       "      <td>3421081</td>\n",
       "      <td>35221</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434471</th>\n",
       "      <td>3421081</td>\n",
       "      <td>12861</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434472</th>\n",
       "      <td>3421082</td>\n",
       "      <td>17279</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434473</th>\n",
       "      <td>3421082</td>\n",
       "      <td>12738</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434474</th>\n",
       "      <td>3421082</td>\n",
       "      <td>16797</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434475</th>\n",
       "      <td>3421082</td>\n",
       "      <td>43352</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434476</th>\n",
       "      <td>3421082</td>\n",
       "      <td>32700</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434477</th>\n",
       "      <td>3421082</td>\n",
       "      <td>12023</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434478</th>\n",
       "      <td>3421082</td>\n",
       "      <td>47941</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434479</th>\n",
       "      <td>3421083</td>\n",
       "      <td>7854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434480</th>\n",
       "      <td>3421083</td>\n",
       "      <td>45309</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434481</th>\n",
       "      <td>3421083</td>\n",
       "      <td>21162</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434482</th>\n",
       "      <td>3421083</td>\n",
       "      <td>18176</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434483</th>\n",
       "      <td>3421083</td>\n",
       "      <td>35211</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434484</th>\n",
       "      <td>3421083</td>\n",
       "      <td>39678</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434485</th>\n",
       "      <td>3421083</td>\n",
       "      <td>11352</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434486</th>\n",
       "      <td>3421083</td>\n",
       "      <td>4600</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434487</th>\n",
       "      <td>3421083</td>\n",
       "      <td>24852</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434488</th>\n",
       "      <td>3421083</td>\n",
       "      <td>5020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_id  product_id  add_to_cart_order  reordered  idx\n",
       "32434469   3421081       20539                  5          0    0\n",
       "32434470   3421081       35221                  6          0   65\n",
       "32434471   3421081       12861                  7          0    0\n",
       "32434472   3421082       17279                  1          1    0\n",
       "32434473   3421082       12738                  2          1    0\n",
       "32434474   3421082       16797                  3          0    8\n",
       "32434475   3421082       43352                  4          1   47\n",
       "32434476   3421082       32700                  5          1    0\n",
       "32434477   3421082       12023                  6          0    0\n",
       "32434478   3421082       47941                  7          0    0\n",
       "32434479   3421083        7854                  1          0    0\n",
       "32434480   3421083       45309                  2          0    0\n",
       "32434481   3421083       21162                  3          0  971\n",
       "32434482   3421083       18176                  4          1    0\n",
       "32434483   3421083       35211                  5          0    0\n",
       "32434484   3421083       39678                  6          1    0\n",
       "32434485   3421083       11352                  7          0  747\n",
       "32434486   3421083        4600                  8          0    0\n",
       "32434487   3421083       24852                  9          1    1\n",
       "32434488   3421083        5020                 10          1    0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f83dad07-faee-4239-afb1-e8efec76eda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1384567</th>\n",
       "      <td>3420998</td>\n",
       "      <td>31717</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384568</th>\n",
       "      <td>3420998</td>\n",
       "      <td>5337</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384569</th>\n",
       "      <td>3420998</td>\n",
       "      <td>23801</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384570</th>\n",
       "      <td>3420998</td>\n",
       "      <td>46665</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384571</th>\n",
       "      <td>3420998</td>\n",
       "      <td>9366</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384572</th>\n",
       "      <td>3420998</td>\n",
       "      <td>36606</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384573</th>\n",
       "      <td>3420998</td>\n",
       "      <td>5240</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384574</th>\n",
       "      <td>3420998</td>\n",
       "      <td>45002</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384575</th>\n",
       "      <td>3420998</td>\n",
       "      <td>23430</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384576</th>\n",
       "      <td>3420998</td>\n",
       "      <td>8277</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384577</th>\n",
       "      <td>3420998</td>\n",
       "      <td>38383</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384578</th>\n",
       "      <td>3420998</td>\n",
       "      <td>39527</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384579</th>\n",
       "      <td>3420998</td>\n",
       "      <td>24830</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384580</th>\n",
       "      <td>3420998</td>\n",
       "      <td>16185</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384581</th>\n",
       "      <td>3420998</td>\n",
       "      <td>6719</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384582</th>\n",
       "      <td>3420998</td>\n",
       "      <td>41950</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384583</th>\n",
       "      <td>3420998</td>\n",
       "      <td>8174</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384584</th>\n",
       "      <td>3420998</td>\n",
       "      <td>7615</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384585</th>\n",
       "      <td>3421026</td>\n",
       "      <td>24535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384586</th>\n",
       "      <td>3421026</td>\n",
       "      <td>15261</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384587</th>\n",
       "      <td>3421026</td>\n",
       "      <td>32237</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384588</th>\n",
       "      <td>3421026</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384589</th>\n",
       "      <td>3421026</td>\n",
       "      <td>4493</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384590</th>\n",
       "      <td>3421026</td>\n",
       "      <td>7781</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384591</th>\n",
       "      <td>3421049</td>\n",
       "      <td>40800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384592</th>\n",
       "      <td>3421049</td>\n",
       "      <td>17706</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384593</th>\n",
       "      <td>3421049</td>\n",
       "      <td>33424</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384594</th>\n",
       "      <td>3421049</td>\n",
       "      <td>17299</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384595</th>\n",
       "      <td>3421049</td>\n",
       "      <td>26800</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384596</th>\n",
       "      <td>3421049</td>\n",
       "      <td>34243</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384597</th>\n",
       "      <td>3421056</td>\n",
       "      <td>5750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384598</th>\n",
       "      <td>3421056</td>\n",
       "      <td>9340</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384599</th>\n",
       "      <td>3421056</td>\n",
       "      <td>21709</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384600</th>\n",
       "      <td>3421056</td>\n",
       "      <td>16475</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384601</th>\n",
       "      <td>3421056</td>\n",
       "      <td>12432</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384602</th>\n",
       "      <td>3421058</td>\n",
       "      <td>15629</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384603</th>\n",
       "      <td>3421058</td>\n",
       "      <td>4347</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384604</th>\n",
       "      <td>3421058</td>\n",
       "      <td>34466</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384605</th>\n",
       "      <td>3421058</td>\n",
       "      <td>6244</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384606</th>\n",
       "      <td>3421058</td>\n",
       "      <td>6858</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384607</th>\n",
       "      <td>3421058</td>\n",
       "      <td>30316</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384608</th>\n",
       "      <td>3421058</td>\n",
       "      <td>35578</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384609</th>\n",
       "      <td>3421058</td>\n",
       "      <td>32650</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384610</th>\n",
       "      <td>3421063</td>\n",
       "      <td>49235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384611</th>\n",
       "      <td>3421063</td>\n",
       "      <td>13565</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384612</th>\n",
       "      <td>3421063</td>\n",
       "      <td>14233</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384613</th>\n",
       "      <td>3421063</td>\n",
       "      <td>35548</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384614</th>\n",
       "      <td>3421070</td>\n",
       "      <td>35951</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384615</th>\n",
       "      <td>3421070</td>\n",
       "      <td>16953</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384616</th>\n",
       "      <td>3421070</td>\n",
       "      <td>4724</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  product_id  add_to_cart_order  reordered  idx\n",
       "1384567   3420998       31717                 11          1   34\n",
       "1384568   3420998        5337                 12          1  814\n",
       "1384569   3420998       23801                 13          0  786\n",
       "1384570   3420998       46665                 14          0    0\n",
       "1384571   3420998        9366                 15          0  787\n",
       "1384572   3420998       36606                 16          1    0\n",
       "1384573   3420998        5240                 17          0  624\n",
       "1384574   3420998       45002                 18          1    0\n",
       "1384575   3420998       23430                 19          1    0\n",
       "1384576   3420998        8277                 20          1   19\n",
       "1384577   3420998       38383                 21          0  153\n",
       "1384578   3420998       39527                 22          1    0\n",
       "1384579   3420998       24830                 23          0  152\n",
       "1384580   3420998       16185                 24          0  111\n",
       "1384581   3420998        6719                 25          0    0\n",
       "1384582   3420998       41950                 26          0   40\n",
       "1384583   3420998        8174                 27          0   71\n",
       "1384584   3420998        7615                 28          0    0\n",
       "1384585   3421026       24535                  1          0  715\n",
       "1384586   3421026       15261                  2          0  470\n",
       "1384587   3421026       32237                  3          0    0\n",
       "1384588   3421026          10                  4          0    0\n",
       "1384589   3421026        4493                  5          0    0\n",
       "1384590   3421026        7781                  6          0   97\n",
       "1384591   3421049       40800                  1          0    0\n",
       "1384592   3421049       17706                  2          0  313\n",
       "1384593   3421049       33424                  3          1    0\n",
       "1384594   3421049       17299                  4          0    0\n",
       "1384595   3421049       26800                  5          0  443\n",
       "1384596   3421049       34243                  6          0  104\n",
       "1384597   3421056        5750                  1          1    0\n",
       "1384598   3421056        9340                  2          1    0\n",
       "1384599   3421056       21709                  3          1  100\n",
       "1384600   3421056       16475                  4          0    0\n",
       "1384601   3421056       12432                  5          0    0\n",
       "1384602   3421058       15629                  1          1    0\n",
       "1384603   3421058        4347                  2          1    0\n",
       "1384604   3421058       34466                  3          1  613\n",
       "1384605   3421058        6244                  4          1    0\n",
       "1384606   3421058        6858                  5          1    0\n",
       "1384607   3421058       30316                  6          1    0\n",
       "1384608   3421058       35578                  7          0    0\n",
       "1384609   3421058       32650                  8          1  926\n",
       "1384610   3421063       49235                  1          1   25\n",
       "1384611   3421063       13565                  2          1    0\n",
       "1384612   3421063       14233                  3          1  311\n",
       "1384613   3421063       35548                  4          1    0\n",
       "1384614   3421070       35951                  1          1   46\n",
       "1384615   3421070       16953                  2          1  187\n",
       "1384616   3421070        4724                  3          1  723"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b4b58d7-0f65-46b7-ad1e-547e12fbcb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customized way to create dataset\n",
    "\n",
    "def create_dataset(df,max_len,max_sequence_start=0, max_sequence_end=100000):\n",
    "    df_values = df[['order_id','idx']].values\n",
    "    catch_index = df_values[0][0]\n",
    "    one_row = [0]*max_len\n",
    "    data = []\n",
    "    idx = 0\n",
    "    df_leng = len(df)\n",
    "    for row in range(df_leng-1):\n",
    "            \n",
    "        if df_values[row][1] > 0 and idx < max_len:\n",
    "            one_row[idx] = df_values[row][1]\n",
    "            idx += 1\n",
    "            \n",
    "        if df_values[row+1][0] != catch_index and one_row != [0]*max_len:\n",
    "            data.append(torch.tensor(one_row,dtype = torch.long))\n",
    "            del one_row\n",
    "            torch.cuda.empty_cache()\n",
    "            one_row = [0]*max_len\n",
    "            catch_index = df_values[row+1][0]\n",
    "            idx = 0\n",
    "\n",
    "        if row == df_leng -2 and df_values[row+1][1] > 0:\n",
    "            one_row.append(df_values[row+1][1])\n",
    "            data.append(torch.tensor(one_row,dtype = torch.long))\n",
    "            del one_row\n",
    "            torch.cuda.empty_cache()\n",
    "            catch_index = df_values[row+1][0]\n",
    "  \n",
    "    return torch.stack(data[max_sequence_start:max_sequence_end]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "754711c8-295a-46b7-ba51-dc008049533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# del train_data\n",
    "# torch.cuda.empty_cache()\n",
    "train_data = create_dataset(train_df,20,max_sequence_start=0,max_sequence_end=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35311ddc-1490-4d06-a848-cdaba76bf98c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 20])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5495311-4e7d-4c85-ac4a-bfcce979b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eab757dc-14a6-4b01-b767-3c3c7225ff87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[200, 114, 550,  ..., 700,   1, 491],\n",
       "        [ 37,  61, 710,  ...,   0,   0, 904],\n",
       "        [860,   4, 144,  ...,   0,   0,  29],\n",
       "        ...,\n",
       "        [  0,   0,   0,  ...,   0,   0,   0],\n",
       "        [  0,   0,   0,  ...,   0,   0,   0],\n",
       "        [  0,   0,   0,  ...,   0,   0,   0]], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3edf8d6-05e2-4d49-b37b-b7f24e836879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 100000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d918d259-949f-4962-94af-d97162b83204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del val_data\n",
    "# torch.cuda.empty_cache()\n",
    "val_data = create_dataset(val_df,20,max_sequence_start=0,max_sequence_end=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eec53bb0-0426-4805-9e83-8896e51be4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151,  49, 592,  ..., 178, 275, 588],\n",
       "        [ 16,  25,  30,  ..., 753,   0,  19],\n",
       "        [  2, 270, 691,  ...,   0,   0,  34],\n",
       "        ...,\n",
       "        [  0,   0,   0,  ...,   0,   0,   0],\n",
       "        [  0,   0,   0,  ...,   0,   0,   0],\n",
       "        [  0,   0,   0,  ...,   0,   0,   0]], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "035bc1b6-3210-4105-8b0f-31991ca1b9bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 20])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8f1c4bb-e65a-4397-b1d3-43fde7c78b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = val_data.t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ce67fe6-23c1-4c77-b0a6-664fe3d8631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set is the subset of training set:  False\n"
     ]
    }
   ],
   "source": [
    "products_in_train = train_df.product_id.unique()\n",
    "products_in_val = val_df.product_id.unique()\n",
    "print(\"validation set is the subset of training set: \",set(products_in_val).issubset(products_in_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e92c41f-56de-4cab-892a-325924d25a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set, validation set is the subset of training set:  True True\n"
     ]
    }
   ],
   "source": [
    "total_product = np.concatenate((products_in_train,products_in_val),axis=None)\n",
    "unique_total_product = np.unique(total_product)\n",
    "print(\"training set, validation set is the subset of training set: \",set(products_in_train).issubset(unique_total_product),set(products_in_val).issubset(unique_total_product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d766771-1d92-4ff3-96c6-6884c2742db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4eafecb9-a268-40ac-82f9-c2907416c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = 1000 # size of vocabulary\n",
    "emsize = 64  # embedding dimension\n",
    "d_hid = 128 # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 8  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 8  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "56a5a93d-3fe3-4a75-aad8-979630107aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (embedding): Embedding(1000, 64)\n",
       "  (linear): Linear(in_features=64, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dd2b0eb-ba05-4d0d-a633-3f2d8b3f06a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  18004 KiB |  32768 KiB |  34470 KiB |  16466 KiB |\n",
      "|       from large pool |  17634 KiB |  32768 KiB |  34018 KiB |  16384 KiB |\n",
      "|       from small pool |    370 KiB |    370 KiB |    452 KiB |     82 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  18004 KiB |  32768 KiB |  34470 KiB |  16466 KiB |\n",
      "|       from large pool |  17634 KiB |  32768 KiB |  34018 KiB |  16384 KiB |\n",
      "|       from small pool |    370 KiB |    370 KiB |    452 KiB |     82 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  17240 KiB |  31250 KiB |  32944 KiB |  15703 KiB |\n",
      "|       from large pool |  16875 KiB |  31250 KiB |  32500 KiB |  15625 KiB |\n",
      "|       from small pool |    365 KiB |    365 KiB |    444 KiB |     78 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  38912 KiB |  38912 KiB |  57344 KiB |  18432 KiB |\n",
      "|       from large pool |  36864 KiB |  36864 KiB |  53248 KiB |  16384 KiB |\n",
      "|       from small pool |   2048 KiB |   2048 KiB |   4096 KiB |   2048 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  20908 KiB |  21199 KiB |  23328 KiB |   2420 KiB |\n",
      "|       from large pool |  19230 KiB |  19230 KiB |  19230 KiB |      0 KiB |\n",
      "|       from small pool |   1678 KiB |   2047 KiB |   4098 KiB |   2420 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      30    |      30    |      39    |       9    |\n",
      "|       from large pool |       2    |       2    |       3    |       1    |\n",
      "|       from small pool |      28    |      28    |      36    |       8    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      30    |      30    |      39    |       9    |\n",
      "|       from large pool |       2    |       2    |       3    |       1    |\n",
      "|       from small pool |      28    |      28    |      36    |       8    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       3    |       3    |       5    |       2    |\n",
      "|       from large pool |       2    |       2    |       3    |       1    |\n",
      "|       from small pool |       1    |       1    |       2    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       3    |       3    |       5    |       2    |\n",
      "|       from large pool |       1    |       1    |       1    |       0    |\n",
      "|       from small pool |       2    |       2    |       4    |       2    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=\"cuda\", abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0abf5912-d9df-43ca-a1e8-2205bee82326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 1e-2  # learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       mode='min',\n",
    "                                                       factor =0.9,\n",
    "                                                       patience=5,\n",
    "                                                       threshold=0.001)\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_batches = train_data.size(-1) // bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(-1) - bptt , bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        output = model(data)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        targets_flat = targets.reshape(-1)\n",
    "        loss = criterion(output_flat, targets_flat)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            scheduler.step(cur_loss)\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.4f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.4f} | ppl {ppl:8.4f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            output = model(data)\n",
    "            target_flat = targets.reshape(-1)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += seq_len * criterion(output_flat, target_flat).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "534f8295-0ae7-49fd-ba1d-a7ba9ba2a93e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 3125 batches | lr 0.0100 | ms/batch 33.16 | loss 2.0986 | ppl   8.1550\n",
      "| epoch   1 |   400/ 3125 batches | lr 0.0100 | ms/batch 32.52 | loss 1.9449 | ppl   6.9932\n",
      "| epoch   1 |   600/ 3125 batches | lr 0.0100 | ms/batch 32.22 | loss 1.9497 | ppl   7.0268\n",
      "| epoch   1 |   800/ 3125 batches | lr 0.0100 | ms/batch 32.49 | loss 1.9724 | ppl   7.1882\n",
      "| epoch   1 |  1000/ 3125 batches | lr 0.0100 | ms/batch 32.32 | loss 1.9508 | ppl   7.0344\n",
      "| epoch   1 |  1200/ 3125 batches | lr 0.0100 | ms/batch 32.79 | loss 1.9608 | ppl   7.1049\n",
      "| epoch   1 |  1400/ 3125 batches | lr 0.0100 | ms/batch 32.95 | loss 1.9101 | ppl   6.7541\n",
      "| epoch   1 |  1600/ 3125 batches | lr 0.0100 | ms/batch 32.47 | loss 1.9624 | ppl   7.1166\n",
      "| epoch   1 |  1800/ 3125 batches | lr 0.0100 | ms/batch 32.39 | loss 1.9408 | ppl   6.9642\n",
      "| epoch   1 |  2000/ 3125 batches | lr 0.0100 | ms/batch 32.28 | loss 1.9309 | ppl   6.8958\n",
      "| epoch   1 |  2200/ 3125 batches | lr 0.0100 | ms/batch 32.24 | loss 1.9280 | ppl   6.8760\n",
      "| epoch   1 |  2400/ 3125 batches | lr 0.0100 | ms/batch 32.32 | loss 1.9373 | ppl   6.9397\n",
      "| epoch   1 |  2600/ 3125 batches | lr 0.0100 | ms/batch 32.23 | loss 1.8857 | ppl   6.5909\n",
      "| epoch   1 |  2800/ 3125 batches | lr 0.0100 | ms/batch 32.40 | loss 1.9931 | ppl   7.3385\n",
      "| epoch   1 |  3000/ 3125 batches | lr 0.0100 | ms/batch 31.84 | loss 1.8912 | ppl   6.6272\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 101.29s | valid loss  2.69 | valid ppl    14.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/ 3125 batches | lr 0.0100 | ms/batch 33.15 | loss 1.9137 | ppl   6.7779\n",
      "| epoch   2 |   400/ 3125 batches | lr 0.0100 | ms/batch 35.22 | loss 1.9108 | ppl   6.7587\n",
      "| epoch   2 |   600/ 3125 batches | lr 0.0100 | ms/batch 33.92 | loss 1.9246 | ppl   6.8526\n",
      "| epoch   2 |   800/ 3125 batches | lr 0.0090 | ms/batch 33.75 | loss 1.9492 | ppl   7.0229\n",
      "| epoch   2 |  1000/ 3125 batches | lr 0.0090 | ms/batch 34.74 | loss 1.9246 | ppl   6.8524\n",
      "| epoch   2 |  1200/ 3125 batches | lr 0.0090 | ms/batch 34.17 | loss 1.9404 | ppl   6.9613\n",
      "| epoch   2 |  1400/ 3125 batches | lr 0.0090 | ms/batch 33.24 | loss 1.8977 | ppl   6.6707\n",
      "| epoch   2 |  1600/ 3125 batches | lr 0.0090 | ms/batch 33.41 | loss 1.9464 | ppl   7.0037\n",
      "| epoch   2 |  1800/ 3125 batches | lr 0.0090 | ms/batch 32.62 | loss 1.9285 | ppl   6.8795\n",
      "| epoch   2 |  2000/ 3125 batches | lr 0.0081 | ms/batch 32.28 | loss 1.9175 | ppl   6.8039\n",
      "| epoch   2 |  2200/ 3125 batches | lr 0.0081 | ms/batch 33.92 | loss 1.9155 | ppl   6.7903\n",
      "| epoch   2 |  2400/ 3125 batches | lr 0.0081 | ms/batch 32.26 | loss 1.9232 | ppl   6.8428\n",
      "| epoch   2 |  2600/ 3125 batches | lr 0.0081 | ms/batch 32.02 | loss 1.8730 | ppl   6.5077\n",
      "| epoch   2 |  2800/ 3125 batches | lr 0.0081 | ms/batch 32.22 | loss 1.9845 | ppl   7.2754\n",
      "| epoch   2 |  3000/ 3125 batches | lr 0.0081 | ms/batch 32.17 | loss 1.8790 | ppl   6.5468\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 103.77s | valid loss  2.68 | valid ppl    14.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   200/ 3125 batches | lr 0.0081 | ms/batch 32.47 | loss 1.9072 | ppl   6.7341\n",
      "| epoch   3 |   400/ 3125 batches | lr 0.0081 | ms/batch 32.39 | loss 1.8991 | ppl   6.6802\n",
      "| epoch   3 |   600/ 3125 batches | lr 0.0081 | ms/batch 32.18 | loss 1.9167 | ppl   6.7983\n",
      "| epoch   3 |   800/ 3125 batches | lr 0.0073 | ms/batch 32.17 | loss 1.9391 | ppl   6.9521\n",
      "| epoch   3 |  1000/ 3125 batches | lr 0.0073 | ms/batch 31.99 | loss 1.9193 | ppl   6.8165\n",
      "| epoch   3 |  1200/ 3125 batches | lr 0.0073 | ms/batch 32.32 | loss 1.9297 | ppl   6.8872\n",
      "| epoch   3 |  1400/ 3125 batches | lr 0.0073 | ms/batch 32.32 | loss 1.8874 | ppl   6.6022\n",
      "| epoch   3 |  1600/ 3125 batches | lr 0.0073 | ms/batch 32.18 | loss 1.9371 | ppl   6.9384\n",
      "| epoch   3 |  1800/ 3125 batches | lr 0.0073 | ms/batch 32.15 | loss 1.9180 | ppl   6.8071\n",
      "| epoch   3 |  2000/ 3125 batches | lr 0.0066 | ms/batch 31.97 | loss 1.9084 | ppl   6.7426\n",
      "| epoch   3 |  2200/ 3125 batches | lr 0.0066 | ms/batch 32.41 | loss 1.9061 | ppl   6.7265\n",
      "| epoch   3 |  2400/ 3125 batches | lr 0.0066 | ms/batch 31.98 | loss 1.9161 | ppl   6.7942\n",
      "| epoch   3 |  2600/ 3125 batches | lr 0.0066 | ms/batch 32.59 | loss 1.8634 | ppl   6.4453\n",
      "| epoch   3 |  2800/ 3125 batches | lr 0.0066 | ms/batch 33.20 | loss 1.9741 | ppl   7.2003\n",
      "| epoch   3 |  3000/ 3125 batches | lr 0.0066 | ms/batch 32.30 | loss 1.8740 | ppl   6.5146\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 100.95s | valid loss  2.63 | valid ppl    13.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |   200/ 3125 batches | lr 0.0066 | ms/batch 32.12 | loss 1.9012 | ppl   6.6942\n",
      "| epoch   4 |   400/ 3125 batches | lr 0.0066 | ms/batch 32.56 | loss 1.8978 | ppl   6.6712\n",
      "| epoch   4 |   600/ 3125 batches | lr 0.0066 | ms/batch 32.45 | loss 1.9086 | ppl   6.7437\n",
      "| epoch   4 |   800/ 3125 batches | lr 0.0059 | ms/batch 32.59 | loss 1.9409 | ppl   6.9650\n",
      "| epoch   4 |  1000/ 3125 batches | lr 0.0059 | ms/batch 32.36 | loss 1.9172 | ppl   6.8017\n",
      "| epoch   4 |  1200/ 3125 batches | lr 0.0059 | ms/batch 32.50 | loss 1.9240 | ppl   6.8481\n",
      "| epoch   4 |  1400/ 3125 batches | lr 0.0059 | ms/batch 32.07 | loss 1.8819 | ppl   6.5660\n",
      "| epoch   4 |  1600/ 3125 batches | lr 0.0059 | ms/batch 32.52 | loss 1.9328 | ppl   6.9089\n",
      "| epoch   4 |  1800/ 3125 batches | lr 0.0059 | ms/batch 32.22 | loss 1.9147 | ppl   6.7846\n",
      "| epoch   4 |  2000/ 3125 batches | lr 0.0053 | ms/batch 32.18 | loss 1.9022 | ppl   6.7005\n",
      "| epoch   4 |  2200/ 3125 batches | lr 0.0053 | ms/batch 32.40 | loss 1.9015 | ppl   6.6962\n",
      "| epoch   4 |  2400/ 3125 batches | lr 0.0053 | ms/batch 32.01 | loss 1.9090 | ppl   6.7462\n",
      "| epoch   4 |  2600/ 3125 batches | lr 0.0053 | ms/batch 32.20 | loss 1.8608 | ppl   6.4291\n",
      "| epoch   4 |  2800/ 3125 batches | lr 0.0053 | ms/batch 32.30 | loss 1.9700 | ppl   7.1710\n",
      "| epoch   4 |  3000/ 3125 batches | lr 0.0053 | ms/batch 32.36 | loss 1.8672 | ppl   6.4701\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 100.93s | valid loss  2.56 | valid ppl    12.87\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |   200/ 3125 batches | lr 0.0053 | ms/batch 32.47 | loss 1.8957 | ppl   6.6572\n",
      "| epoch   5 |   400/ 3125 batches | lr 0.0053 | ms/batch 32.32 | loss 1.8922 | ppl   6.6340\n",
      "| epoch   5 |   600/ 3125 batches | lr 0.0053 | ms/batch 32.12 | loss 1.9064 | ppl   6.7291\n",
      "| epoch   5 |   800/ 3125 batches | lr 0.0048 | ms/batch 32.25 | loss 1.9346 | ppl   6.9210\n",
      "| epoch   5 |  1000/ 3125 batches | lr 0.0048 | ms/batch 32.36 | loss 1.9111 | ppl   6.7603\n",
      "| epoch   5 |  1200/ 3125 batches | lr 0.0048 | ms/batch 32.01 | loss 1.9193 | ppl   6.8160\n",
      "| epoch   5 |  1400/ 3125 batches | lr 0.0048 | ms/batch 32.77 | loss 1.8803 | ppl   6.5557\n",
      "| epoch   5 |  1600/ 3125 batches | lr 0.0048 | ms/batch 32.54 | loss 1.9298 | ppl   6.8882\n",
      "| epoch   5 |  1800/ 3125 batches | lr 0.0048 | ms/batch 32.23 | loss 1.9089 | ppl   6.7457\n",
      "| epoch   5 |  2000/ 3125 batches | lr 0.0043 | ms/batch 32.22 | loss 1.8975 | ppl   6.6690\n",
      "| epoch   5 |  2200/ 3125 batches | lr 0.0043 | ms/batch 32.31 | loss 1.8975 | ppl   6.6695\n",
      "| epoch   5 |  2400/ 3125 batches | lr 0.0043 | ms/batch 32.26 | loss 1.9046 | ppl   6.7167\n",
      "| epoch   5 |  2600/ 3125 batches | lr 0.0043 | ms/batch 32.12 | loss 1.8560 | ppl   6.3981\n",
      "| epoch   5 |  2800/ 3125 batches | lr 0.0043 | ms/batch 32.36 | loss 1.9654 | ppl   7.1381\n",
      "| epoch   5 |  3000/ 3125 batches | lr 0.0043 | ms/batch 32.10 | loss 1.8645 | ppl   6.4529\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 100.81s | valid loss  2.63 | valid ppl    13.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |   200/ 3125 batches | lr 0.0043 | ms/batch 32.26 | loss 1.8932 | ppl   6.6405\n",
      "| epoch   6 |   400/ 3125 batches | lr 0.0043 | ms/batch 32.07 | loss 1.8878 | ppl   6.6051\n",
      "| epoch   6 |   600/ 3125 batches | lr 0.0043 | ms/batch 32.46 | loss 1.9050 | ppl   6.7196\n",
      "| epoch   6 |   800/ 3125 batches | lr 0.0039 | ms/batch 32.22 | loss 1.9314 | ppl   6.8994\n",
      "| epoch   6 |  1000/ 3125 batches | lr 0.0039 | ms/batch 32.59 | loss 1.9102 | ppl   6.7545\n",
      "| epoch   6 |  1200/ 3125 batches | lr 0.0039 | ms/batch 32.19 | loss 1.9150 | ppl   6.7867\n",
      "| epoch   6 |  1400/ 3125 batches | lr 0.0039 | ms/batch 32.31 | loss 1.8759 | ppl   6.5269\n",
      "| epoch   6 |  1600/ 3125 batches | lr 0.0039 | ms/batch 32.19 | loss 1.9259 | ppl   6.8614\n",
      "| epoch   6 |  1800/ 3125 batches | lr 0.0039 | ms/batch 32.24 | loss 1.9093 | ppl   6.7486\n",
      "| epoch   6 |  2000/ 3125 batches | lr 0.0035 | ms/batch 32.40 | loss 1.8947 | ppl   6.6506\n",
      "| epoch   6 |  2200/ 3125 batches | lr 0.0035 | ms/batch 32.11 | loss 1.8960 | ppl   6.6592\n",
      "| epoch   6 |  2400/ 3125 batches | lr 0.0035 | ms/batch 32.21 | loss 1.9019 | ppl   6.6989\n",
      "| epoch   6 |  2600/ 3125 batches | lr 0.0035 | ms/batch 32.27 | loss 1.8523 | ppl   6.3744\n",
      "| epoch   6 |  2800/ 3125 batches | lr 0.0035 | ms/batch 32.10 | loss 1.9634 | ppl   7.1236\n",
      "| epoch   6 |  3000/ 3125 batches | lr 0.0035 | ms/batch 32.47 | loss 1.8624 | ppl   6.4390\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 100.87s | valid loss  2.63 | valid ppl    13.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |   200/ 3125 batches | lr 0.0035 | ms/batch 32.53 | loss 1.8906 | ppl   6.6235\n",
      "| epoch   7 |   400/ 3125 batches | lr 0.0035 | ms/batch 32.40 | loss 1.8840 | ppl   6.5800\n",
      "| epoch   7 |   600/ 3125 batches | lr 0.0035 | ms/batch 32.56 | loss 1.9003 | ppl   6.6882\n",
      "| epoch   7 |   800/ 3125 batches | lr 0.0031 | ms/batch 32.50 | loss 1.9262 | ppl   6.8635\n",
      "| epoch   7 |  1000/ 3125 batches | lr 0.0031 | ms/batch 32.40 | loss 1.9062 | ppl   6.7276\n",
      "| epoch   7 |  1200/ 3125 batches | lr 0.0031 | ms/batch 33.42 | loss 1.9131 | ppl   6.7738\n",
      "| epoch   7 |  1400/ 3125 batches | lr 0.0031 | ms/batch 34.84 | loss 1.8746 | ppl   6.5183\n",
      "| epoch   7 |  1600/ 3125 batches | lr 0.0031 | ms/batch 33.49 | loss 1.9223 | ppl   6.8370\n",
      "| epoch   7 |  1800/ 3125 batches | lr 0.0031 | ms/batch 32.51 | loss 1.9068 | ppl   6.7312\n",
      "| epoch   7 |  2000/ 3125 batches | lr 0.0028 | ms/batch 32.17 | loss 1.8909 | ppl   6.6253\n",
      "| epoch   7 |  2200/ 3125 batches | lr 0.0028 | ms/batch 32.11 | loss 1.8950 | ppl   6.6528\n",
      "| epoch   7 |  2400/ 3125 batches | lr 0.0028 | ms/batch 32.11 | loss 1.8988 | ppl   6.6782\n",
      "| epoch   7 |  2600/ 3125 batches | lr 0.0028 | ms/batch 32.04 | loss 1.8516 | ppl   6.3699\n",
      "| epoch   7 |  2800/ 3125 batches | lr 0.0028 | ms/batch 32.25 | loss 1.9621 | ppl   7.1142\n",
      "| epoch   7 |  3000/ 3125 batches | lr 0.0028 | ms/batch 32.40 | loss 1.8597 | ppl   6.4217\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 101.95s | valid loss  2.61 | valid ppl    13.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |   200/ 3125 batches | lr 0.0025 | ms/batch 32.66 | loss 1.8878 | ppl   6.6048\n",
      "| epoch   8 |   400/ 3125 batches | lr 0.0025 | ms/batch 32.09 | loss 1.8832 | ppl   6.5745\n",
      "| epoch   8 |   600/ 3125 batches | lr 0.0025 | ms/batch 32.32 | loss 1.8991 | ppl   6.6802\n",
      "| epoch   8 |   800/ 3125 batches | lr 0.0025 | ms/batch 32.11 | loss 1.9237 | ppl   6.8464\n",
      "| epoch   8 |  1000/ 3125 batches | lr 0.0025 | ms/batch 32.10 | loss 1.9060 | ppl   6.7262\n",
      "| epoch   8 |  1200/ 3125 batches | lr 0.0023 | ms/batch 32.30 | loss 1.9098 | ppl   6.7520\n",
      "| epoch   8 |  1400/ 3125 batches | lr 0.0023 | ms/batch 32.56 | loss 1.8727 | ppl   6.5058\n",
      "| epoch   8 |  1600/ 3125 batches | lr 0.0023 | ms/batch 32.27 | loss 1.9219 | ppl   6.8338\n",
      "| epoch   8 |  1800/ 3125 batches | lr 0.0023 | ms/batch 32.15 | loss 1.9053 | ppl   6.7213\n",
      "| epoch   8 |  2000/ 3125 batches | lr 0.0023 | ms/batch 32.28 | loss 1.8901 | ppl   6.6202\n",
      "| epoch   8 |  2200/ 3125 batches | lr 0.0023 | ms/batch 32.48 | loss 1.8926 | ppl   6.6367\n",
      "| epoch   8 |  2400/ 3125 batches | lr 0.0021 | ms/batch 32.19 | loss 1.8986 | ppl   6.6765\n",
      "| epoch   8 |  2600/ 3125 batches | lr 0.0021 | ms/batch 31.95 | loss 1.8506 | ppl   6.3639\n",
      "| epoch   8 |  2800/ 3125 batches | lr 0.0021 | ms/batch 32.36 | loss 1.9593 | ppl   7.0945\n",
      "| epoch   8 |  3000/ 3125 batches | lr 0.0021 | ms/batch 32.35 | loss 1.8568 | ppl   6.4032\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 100.85s | valid loss  2.62 | valid ppl    13.73\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |   200/ 3125 batches | lr 0.0021 | ms/batch 32.43 | loss 1.8877 | ppl   6.6040\n",
      "| epoch   9 |   400/ 3125 batches | lr 0.0019 | ms/batch 32.26 | loss 1.8813 | ppl   6.5623\n",
      "| epoch   9 |   600/ 3125 batches | lr 0.0019 | ms/batch 32.46 | loss 1.8977 | ppl   6.6705\n",
      "| epoch   9 |   800/ 3125 batches | lr 0.0019 | ms/batch 32.24 | loss 1.9226 | ppl   6.8384\n",
      "| epoch   9 |  1000/ 3125 batches | lr 0.0019 | ms/batch 32.26 | loss 1.9012 | ppl   6.6942\n",
      "| epoch   9 |  1200/ 3125 batches | lr 0.0019 | ms/batch 32.39 | loss 1.9092 | ppl   6.7479\n",
      "| epoch   9 |  1400/ 3125 batches | lr 0.0019 | ms/batch 32.34 | loss 1.8704 | ppl   6.4910\n",
      "| epoch   9 |  1600/ 3125 batches | lr 0.0017 | ms/batch 32.59 | loss 1.9200 | ppl   6.8213\n",
      "| epoch   9 |  1800/ 3125 batches | lr 0.0017 | ms/batch 32.33 | loss 1.8996 | ppl   6.6834\n",
      "| epoch   9 |  2000/ 3125 batches | lr 0.0017 | ms/batch 32.95 | loss 1.8891 | ppl   6.6131\n",
      "| epoch   9 |  2200/ 3125 batches | lr 0.0017 | ms/batch 32.11 | loss 1.8902 | ppl   6.6206\n",
      "| epoch   9 |  2400/ 3125 batches | lr 0.0017 | ms/batch 32.07 | loss 1.8976 | ppl   6.6696\n",
      "| epoch   9 |  2600/ 3125 batches | lr 0.0017 | ms/batch 32.41 | loss 1.8482 | ppl   6.3481\n",
      "| epoch   9 |  2800/ 3125 batches | lr 0.0017 | ms/batch 32.65 | loss 1.9599 | ppl   7.0989\n",
      "| epoch   9 |  3000/ 3125 batches | lr 0.0017 | ms/batch 32.56 | loss 1.8559 | ppl   6.3976\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 101.16s | valid loss  2.66 | valid ppl    14.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |   200/ 3125 batches | lr 0.0017 | ms/batch 32.42 | loss 1.8860 | ppl   6.5931\n",
      "| epoch  10 |   400/ 3125 batches | lr 0.0017 | ms/batch 32.38 | loss 1.8824 | ppl   6.5695\n",
      "| epoch  10 |   600/ 3125 batches | lr 0.0017 | ms/batch 32.20 | loss 1.8965 | ppl   6.6623\n",
      "| epoch  10 |   800/ 3125 batches | lr 0.0015 | ms/batch 32.39 | loss 1.9229 | ppl   6.8406\n",
      "| epoch  10 |  1000/ 3125 batches | lr 0.0015 | ms/batch 31.89 | loss 1.9003 | ppl   6.6878\n",
      "| epoch  10 |  1200/ 3125 batches | lr 0.0015 | ms/batch 32.66 | loss 1.9090 | ppl   6.7465\n",
      "| epoch  10 |  1400/ 3125 batches | lr 0.0015 | ms/batch 32.36 | loss 1.8711 | ppl   6.4956\n",
      "| epoch  10 |  1600/ 3125 batches | lr 0.0015 | ms/batch 32.28 | loss 1.9186 | ppl   6.8115\n",
      "| epoch  10 |  1800/ 3125 batches | lr 0.0015 | ms/batch 32.23 | loss 1.9007 | ppl   6.6904\n",
      "| epoch  10 |  2000/ 3125 batches | lr 0.0014 | ms/batch 32.39 | loss 1.8875 | ppl   6.6028\n",
      "| epoch  10 |  2200/ 3125 batches | lr 0.0014 | ms/batch 32.43 | loss 1.8894 | ppl   6.6153\n",
      "| epoch  10 |  2400/ 3125 batches | lr 0.0014 | ms/batch 32.02 | loss 1.8953 | ppl   6.6545\n",
      "| epoch  10 |  2600/ 3125 batches | lr 0.0014 | ms/batch 32.12 | loss 1.8491 | ppl   6.3539\n",
      "| epoch  10 |  2800/ 3125 batches | lr 0.0014 | ms/batch 32.14 | loss 1.9597 | ppl   7.0970\n",
      "| epoch  10 |  3000/ 3125 batches | lr 0.0014 | ms/batch 32.05 | loss 1.8550 | ppl   6.3920\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 100.73s | valid loss  2.70 | valid ppl    14.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |   200/ 3125 batches | lr 0.0012 | ms/batch 32.27 | loss 1.8856 | ppl   6.5904\n",
      "| epoch  11 |   400/ 3125 batches | lr 0.0012 | ms/batch 32.31 | loss 1.8796 | ppl   6.5511\n",
      "| epoch  11 |   600/ 3125 batches | lr 0.0012 | ms/batch 32.02 | loss 1.8953 | ppl   6.6543\n",
      "| epoch  11 |   800/ 3125 batches | lr 0.0012 | ms/batch 33.03 | loss 1.9202 | ppl   6.8221\n",
      "| epoch  11 |  1000/ 3125 batches | lr 0.0012 | ms/batch 32.80 | loss 1.9009 | ppl   6.6920\n",
      "| epoch  11 |  1200/ 3125 batches | lr 0.0011 | ms/batch 33.26 | loss 1.9074 | ppl   6.7354\n",
      "| epoch  11 |  1400/ 3125 batches | lr 0.0011 | ms/batch 35.25 | loss 1.8702 | ppl   6.4894\n",
      "| epoch  11 |  1600/ 3125 batches | lr 0.0011 | ms/batch 33.19 | loss 1.9171 | ppl   6.8013\n",
      "| epoch  11 |  1800/ 3125 batches | lr 0.0011 | ms/batch 34.01 | loss 1.8994 | ppl   6.6817\n",
      "| epoch  11 |  2000/ 3125 batches | lr 0.0011 | ms/batch 33.01 | loss 1.8860 | ppl   6.5928\n",
      "| epoch  11 |  2200/ 3125 batches | lr 0.0011 | ms/batch 34.54 | loss 1.8877 | ppl   6.6043\n",
      "| epoch  11 |  2400/ 3125 batches | lr 0.0010 | ms/batch 33.33 | loss 1.8941 | ppl   6.6466\n",
      "| epoch  11 |  2600/ 3125 batches | lr 0.0010 | ms/batch 33.21 | loss 1.8470 | ppl   6.3408\n",
      "| epoch  11 |  2800/ 3125 batches | lr 0.0010 | ms/batch 32.58 | loss 1.9612 | ppl   7.1078\n",
      "| epoch  11 |  3000/ 3125 batches | lr 0.0010 | ms/batch 32.83 | loss 1.8563 | ppl   6.4002\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 103.62s | valid loss  2.70 | valid ppl    14.87\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |   200/ 3125 batches | lr 0.0010 | ms/batch 33.24 | loss 1.8851 | ppl   6.5869\n",
      "| epoch  12 |   400/ 3125 batches | lr 0.0009 | ms/batch 33.38 | loss 1.8779 | ppl   6.5398\n",
      "| epoch  12 |   600/ 3125 batches | lr 0.0009 | ms/batch 33.65 | loss 1.8948 | ppl   6.6515\n",
      "| epoch  12 |   800/ 3125 batches | lr 0.0009 | ms/batch 33.90 | loss 1.9197 | ppl   6.8192\n",
      "| epoch  12 |  1000/ 3125 batches | lr 0.0009 | ms/batch 33.32 | loss 1.9000 | ppl   6.6861\n",
      "| epoch  12 |  1200/ 3125 batches | lr 0.0009 | ms/batch 32.70 | loss 1.9077 | ppl   6.7376\n",
      "| epoch  12 |  1400/ 3125 batches | lr 0.0009 | ms/batch 34.35 | loss 1.8694 | ppl   6.4843\n",
      "| epoch  12 |  1600/ 3125 batches | lr 0.0008 | ms/batch 34.88 | loss 1.9180 | ppl   6.8072\n",
      "| epoch  12 |  1800/ 3125 batches | lr 0.0008 | ms/batch 32.73 | loss 1.9008 | ppl   6.6915\n",
      "| epoch  12 |  2000/ 3125 batches | lr 0.0008 | ms/batch 32.92 | loss 1.8871 | ppl   6.6005\n",
      "| epoch  12 |  2200/ 3125 batches | lr 0.0008 | ms/batch 33.02 | loss 1.8881 | ppl   6.6067\n",
      "| epoch  12 |  2400/ 3125 batches | lr 0.0008 | ms/batch 33.37 | loss 1.8942 | ppl   6.6473\n",
      "| epoch  12 |  2600/ 3125 batches | lr 0.0008 | ms/batch 33.22 | loss 1.8469 | ppl   6.3405\n",
      "| epoch  12 |  2800/ 3125 batches | lr 0.0007 | ms/batch 33.04 | loss 1.9577 | ppl   7.0830\n",
      "| epoch  12 |  3000/ 3125 batches | lr 0.0007 | ms/batch 33.16 | loss 1.8553 | ppl   6.3934\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 104.28s | valid loss  2.76 | valid ppl    15.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |   200/ 3125 batches | lr 0.0007 | ms/batch 33.62 | loss 1.8826 | ppl   6.5704\n",
      "| epoch  13 |   400/ 3125 batches | lr 0.0007 | ms/batch 33.56 | loss 1.8797 | ppl   6.5516\n",
      "| epoch  13 |   600/ 3125 batches | lr 0.0007 | ms/batch 33.96 | loss 1.8938 | ppl   6.6448\n",
      "| epoch  13 |   800/ 3125 batches | lr 0.0006 | ms/batch 33.90 | loss 1.9185 | ppl   6.8106\n",
      "| epoch  13 |  1000/ 3125 batches | lr 0.0006 | ms/batch 33.11 | loss 1.9008 | ppl   6.6910\n",
      "| epoch  13 |  1200/ 3125 batches | lr 0.0006 | ms/batch 32.86 | loss 1.9059 | ppl   6.7256\n",
      "| epoch  13 |  1400/ 3125 batches | lr 0.0006 | ms/batch 33.12 | loss 1.8675 | ppl   6.4721\n",
      "| epoch  13 |  1600/ 3125 batches | lr 0.0006 | ms/batch 34.00 | loss 1.9168 | ppl   6.7991\n",
      "| epoch  13 |  1800/ 3125 batches | lr 0.0006 | ms/batch 32.74 | loss 1.8995 | ppl   6.6828\n",
      "| epoch  13 |  2000/ 3125 batches | lr 0.0006 | ms/batch 32.93 | loss 1.8860 | ppl   6.5927\n",
      "| epoch  13 |  2200/ 3125 batches | lr 0.0006 | ms/batch 33.06 | loss 1.8864 | ppl   6.5956\n",
      "| epoch  13 |  2400/ 3125 batches | lr 0.0006 | ms/batch 33.02 | loss 1.8923 | ppl   6.6343\n",
      "| epoch  13 |  2600/ 3125 batches | lr 0.0006 | ms/batch 33.13 | loss 1.8445 | ppl   6.3248\n",
      "| epoch  13 |  2800/ 3125 batches | lr 0.0006 | ms/batch 32.44 | loss 1.9574 | ppl   7.0812\n",
      "| epoch  13 |  3000/ 3125 batches | lr 0.0006 | ms/batch 32.93 | loss 1.8553 | ppl   6.3934\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 103.81s | valid loss  2.75 | valid ppl    15.70\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |   200/ 3125 batches | lr 0.0006 | ms/batch 32.95 | loss 1.8838 | ppl   6.5784\n",
      "| epoch  14 |   400/ 3125 batches | lr 0.0006 | ms/batch 33.28 | loss 1.8782 | ppl   6.5418\n",
      "| epoch  14 |   600/ 3125 batches | lr 0.0006 | ms/batch 32.96 | loss 1.8946 | ppl   6.6500\n",
      "| epoch  14 |   800/ 3125 batches | lr 0.0005 | ms/batch 33.39 | loss 1.9181 | ppl   6.8078\n",
      "| epoch  14 |  1000/ 3125 batches | lr 0.0005 | ms/batch 33.07 | loss 1.9001 | ppl   6.6865\n",
      "| epoch  14 |  1200/ 3125 batches | lr 0.0005 | ms/batch 33.45 | loss 1.9046 | ppl   6.7169\n",
      "| epoch  14 |  1400/ 3125 batches | lr 0.0005 | ms/batch 34.51 | loss 1.8668 | ppl   6.4679\n",
      "| epoch  14 |  1600/ 3125 batches | lr 0.0005 | ms/batch 33.47 | loss 1.9169 | ppl   6.8000\n",
      "| epoch  14 |  1800/ 3125 batches | lr 0.0005 | ms/batch 37.51 | loss 1.8974 | ppl   6.6686\n",
      "| epoch  14 |  2000/ 3125 batches | lr 0.0005 | ms/batch 32.99 | loss 1.8848 | ppl   6.5851\n",
      "| epoch  14 |  2200/ 3125 batches | lr 0.0005 | ms/batch 31.76 | loss 1.8877 | ppl   6.6043\n",
      "| epoch  14 |  2400/ 3125 batches | lr 0.0005 | ms/batch 39.26 | loss 1.8938 | ppl   6.6446\n",
      "| epoch  14 |  2600/ 3125 batches | lr 0.0005 | ms/batch 33.56 | loss 1.8461 | ppl   6.3353\n",
      "| epoch  14 |  2800/ 3125 batches | lr 0.0005 | ms/batch 34.85 | loss 1.9564 | ppl   7.0738\n",
      "| epoch  14 |  3000/ 3125 batches | lr 0.0005 | ms/batch 33.73 | loss 1.8526 | ppl   6.3763\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 107.36s | valid loss  2.80 | valid ppl    16.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |   200/ 3125 batches | lr 0.0004 | ms/batch 36.15 | loss 1.8827 | ppl   6.5714\n",
      "| epoch  15 |   400/ 3125 batches | lr 0.0004 | ms/batch 32.82 | loss 1.8769 | ppl   6.5334\n",
      "| epoch  15 |   600/ 3125 batches | lr 0.0004 | ms/batch 33.15 | loss 1.8952 | ppl   6.6539\n",
      "| epoch  15 |   800/ 3125 batches | lr 0.0004 | ms/batch 35.18 | loss 1.9172 | ppl   6.8020\n",
      "| epoch  15 |  1000/ 3125 batches | lr 0.0004 | ms/batch 33.28 | loss 1.8973 | ppl   6.6678\n",
      "| epoch  15 |  1200/ 3125 batches | lr 0.0004 | ms/batch 33.21 | loss 1.9059 | ppl   6.7257\n",
      "| epoch  15 |  1400/ 3125 batches | lr 0.0004 | ms/batch 35.30 | loss 1.8670 | ppl   6.4687\n",
      "| epoch  15 |  1600/ 3125 batches | lr 0.0004 | ms/batch 34.16 | loss 1.9177 | ppl   6.8051\n",
      "| epoch  15 |  1800/ 3125 batches | lr 0.0004 | ms/batch 34.42 | loss 1.8983 | ppl   6.6744\n",
      "| epoch  15 |  2000/ 3125 batches | lr 0.0004 | ms/batch 33.31 | loss 1.8860 | ppl   6.5928\n",
      "| epoch  15 |  2200/ 3125 batches | lr 0.0004 | ms/batch 35.17 | loss 1.8848 | ppl   6.5850\n",
      "| epoch  15 |  2400/ 3125 batches | lr 0.0003 | ms/batch 32.87 | loss 1.8916 | ppl   6.6301\n",
      "| epoch  15 |  2600/ 3125 batches | lr 0.0003 | ms/batch 33.29 | loss 1.8447 | ppl   6.3260\n",
      "| epoch  15 |  2800/ 3125 batches | lr 0.0003 | ms/batch 32.93 | loss 1.9555 | ppl   7.0677\n",
      "| epoch  15 |  3000/ 3125 batches | lr 0.0003 | ms/batch 33.54 | loss 1.8545 | ppl   6.3885\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 105.79s | valid loss  2.82 | valid ppl    16.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |   200/ 3125 batches | lr 0.0003 | ms/batch 32.86 | loss 1.8838 | ppl   6.5784\n",
      "| epoch  16 |   400/ 3125 batches | lr 0.0003 | ms/batch 33.24 | loss 1.8779 | ppl   6.5399\n",
      "| epoch  16 |   600/ 3125 batches | lr 0.0003 | ms/batch 32.75 | loss 1.8933 | ppl   6.6413\n",
      "| epoch  16 |   800/ 3125 batches | lr 0.0003 | ms/batch 32.03 | loss 1.9169 | ppl   6.7996\n",
      "| epoch  16 |  1000/ 3125 batches | lr 0.0003 | ms/batch 31.79 | loss 1.8973 | ppl   6.6681\n",
      "| epoch  16 |  1200/ 3125 batches | lr 0.0003 | ms/batch 31.93 | loss 1.9063 | ppl   6.7283\n",
      "| epoch  16 |  1400/ 3125 batches | lr 0.0003 | ms/batch 32.92 | loss 1.8681 | ppl   6.4758\n",
      "| epoch  16 |  1600/ 3125 batches | lr 0.0003 | ms/batch 33.50 | loss 1.9148 | ppl   6.7856\n",
      "| epoch  16 |  1800/ 3125 batches | lr 0.0003 | ms/batch 33.24 | loss 1.8985 | ppl   6.6755\n",
      "| epoch  16 |  2000/ 3125 batches | lr 0.0003 | ms/batch 34.42 | loss 1.8845 | ppl   6.5828\n",
      "| epoch  16 |  2200/ 3125 batches | lr 0.0003 | ms/batch 33.09 | loss 1.8854 | ppl   6.5892\n",
      "| epoch  16 |  2400/ 3125 batches | lr 0.0003 | ms/batch 32.35 | loss 1.8926 | ppl   6.6364\n",
      "| epoch  16 |  2600/ 3125 batches | lr 0.0003 | ms/batch 33.21 | loss 1.8447 | ppl   6.3263\n",
      "| epoch  16 |  2800/ 3125 batches | lr 0.0003 | ms/batch 33.35 | loss 1.9550 | ppl   7.0641\n",
      "| epoch  16 |  3000/ 3125 batches | lr 0.0003 | ms/batch 33.01 | loss 1.8538 | ppl   6.3843\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 102.67s | valid loss  2.81 | valid ppl    16.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |   200/ 3125 batches | lr 0.0003 | ms/batch 31.76 | loss 1.8835 | ppl   6.5763\n",
      "| epoch  17 |   400/ 3125 batches | lr 0.0003 | ms/batch 31.79 | loss 1.8781 | ppl   6.5408\n",
      "| epoch  17 |   600/ 3125 batches | lr 0.0003 | ms/batch 32.92 | loss 1.8951 | ppl   6.6535\n",
      "| epoch  17 |   800/ 3125 batches | lr 0.0002 | ms/batch 32.16 | loss 1.9183 | ppl   6.8095\n",
      "| epoch  17 |  1000/ 3125 batches | lr 0.0002 | ms/batch 32.34 | loss 1.8990 | ppl   6.6790\n",
      "| epoch  17 |  1200/ 3125 batches | lr 0.0002 | ms/batch 32.27 | loss 1.9056 | ppl   6.7231\n",
      "| epoch  17 |  1400/ 3125 batches | lr 0.0002 | ms/batch 31.74 | loss 1.8670 | ppl   6.4691\n",
      "| epoch  17 |  1600/ 3125 batches | lr 0.0002 | ms/batch 32.11 | loss 1.9160 | ppl   6.7936\n",
      "| epoch  17 |  1800/ 3125 batches | lr 0.0002 | ms/batch 31.74 | loss 1.8970 | ppl   6.6659\n",
      "| epoch  17 |  2000/ 3125 batches | lr 0.0002 | ms/batch 31.74 | loss 1.8855 | ppl   6.5895\n",
      "| epoch  17 |  2200/ 3125 batches | lr 0.0002 | ms/batch 31.98 | loss 1.8855 | ppl   6.5898\n",
      "| epoch  17 |  2400/ 3125 batches | lr 0.0002 | ms/batch 31.88 | loss 1.8943 | ppl   6.6479\n",
      "| epoch  17 |  2600/ 3125 batches | lr 0.0002 | ms/batch 31.73 | loss 1.8438 | ppl   6.3206\n",
      "| epoch  17 |  2800/ 3125 batches | lr 0.0002 | ms/batch 31.86 | loss 1.9565 | ppl   7.0746\n",
      "| epoch  17 |  3000/ 3125 batches | lr 0.0002 | ms/batch 31.89 | loss 1.8545 | ppl   6.3888\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 99.90s | valid loss  2.82 | valid ppl    16.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |   200/ 3125 batches | lr 0.0002 | ms/batch 32.10 | loss 1.8834 | ppl   6.5761\n",
      "| epoch  18 |   400/ 3125 batches | lr 0.0002 | ms/batch 31.69 | loss 1.8765 | ppl   6.5308\n",
      "| epoch  18 |   600/ 3125 batches | lr 0.0002 | ms/batch 31.95 | loss 1.8919 | ppl   6.6322\n",
      "| epoch  18 |   800/ 3125 batches | lr 0.0002 | ms/batch 31.99 | loss 1.9175 | ppl   6.8037\n",
      "| epoch  18 |  1000/ 3125 batches | lr 0.0002 | ms/batch 31.91 | loss 1.8964 | ppl   6.6616\n",
      "| epoch  18 |  1200/ 3125 batches | lr 0.0002 | ms/batch 31.68 | loss 1.9058 | ppl   6.7251\n",
      "| epoch  18 |  1400/ 3125 batches | lr 0.0002 | ms/batch 32.02 | loss 1.8670 | ppl   6.4686\n",
      "| epoch  18 |  1600/ 3125 batches | lr 0.0002 | ms/batch 31.86 | loss 1.9151 | ppl   6.7878\n",
      "| epoch  18 |  1800/ 3125 batches | lr 0.0002 | ms/batch 31.83 | loss 1.8983 | ppl   6.6742\n",
      "| epoch  18 |  2000/ 3125 batches | lr 0.0002 | ms/batch 31.96 | loss 1.8834 | ppl   6.5758\n",
      "| epoch  18 |  2200/ 3125 batches | lr 0.0002 | ms/batch 32.35 | loss 1.8864 | ppl   6.5953\n",
      "| epoch  18 |  2400/ 3125 batches | lr 0.0001 | ms/batch 31.52 | loss 1.8920 | ppl   6.6329\n",
      "| epoch  18 |  2600/ 3125 batches | lr 0.0001 | ms/batch 31.80 | loss 1.8433 | ppl   6.3175\n",
      "| epoch  18 |  2800/ 3125 batches | lr 0.0001 | ms/batch 31.85 | loss 1.9562 | ppl   7.0725\n",
      "| epoch  18 |  3000/ 3125 batches | lr 0.0001 | ms/batch 31.66 | loss 1.8548 | ppl   6.3905\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 99.55s | valid loss  2.82 | valid ppl    16.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |   200/ 3125 batches | lr 0.0001 | ms/batch 32.06 | loss 1.8813 | ppl   6.5618\n",
      "| epoch  19 |   400/ 3125 batches | lr 0.0001 | ms/batch 31.88 | loss 1.8769 | ppl   6.5334\n",
      "| epoch  19 |   600/ 3125 batches | lr 0.0001 | ms/batch 32.10 | loss 1.8920 | ppl   6.6326\n",
      "| epoch  19 |   800/ 3125 batches | lr 0.0001 | ms/batch 31.69 | loss 1.9174 | ppl   6.8031\n",
      "| epoch  19 |  1000/ 3125 batches | lr 0.0001 | ms/batch 32.10 | loss 1.8973 | ppl   6.6676\n",
      "| epoch  19 |  1200/ 3125 batches | lr 0.0001 | ms/batch 31.75 | loss 1.9042 | ppl   6.7142\n",
      "| epoch  19 |  1400/ 3125 batches | lr 0.0001 | ms/batch 32.37 | loss 1.8682 | ppl   6.4769\n",
      "| epoch  19 |  1600/ 3125 batches | lr 0.0001 | ms/batch 32.01 | loss 1.9147 | ppl   6.7852\n",
      "| epoch  19 |  1800/ 3125 batches | lr 0.0001 | ms/batch 31.88 | loss 1.8983 | ppl   6.6745\n",
      "| epoch  19 |  2000/ 3125 batches | lr 0.0001 | ms/batch 31.90 | loss 1.8831 | ppl   6.5737\n",
      "| epoch  19 |  2200/ 3125 batches | lr 0.0001 | ms/batch 31.95 | loss 1.8850 | ppl   6.5865\n",
      "| epoch  19 |  2400/ 3125 batches | lr 0.0001 | ms/batch 31.82 | loss 1.8915 | ppl   6.6293\n",
      "| epoch  19 |  2600/ 3125 batches | lr 0.0001 | ms/batch 31.94 | loss 1.8449 | ppl   6.3275\n",
      "| epoch  19 |  2800/ 3125 batches | lr 0.0001 | ms/batch 31.51 | loss 1.9555 | ppl   7.0672\n",
      "| epoch  19 |  3000/ 3125 batches | lr 0.0001 | ms/batch 32.01 | loss 1.8531 | ppl   6.3794\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 99.74s | valid loss  2.83 | valid ppl    17.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |   200/ 3125 batches | lr 0.0001 | ms/batch 32.05 | loss 1.8814 | ppl   6.5625\n",
      "| epoch  20 |   400/ 3125 batches | lr 0.0001 | ms/batch 32.12 | loss 1.8781 | ppl   6.5408\n",
      "| epoch  20 |   600/ 3125 batches | lr 0.0001 | ms/batch 31.83 | loss 1.8931 | ppl   6.6396\n",
      "| epoch  20 |   800/ 3125 batches | lr 0.0001 | ms/batch 32.24 | loss 1.9166 | ppl   6.7976\n",
      "| epoch  20 |  1000/ 3125 batches | lr 0.0001 | ms/batch 31.88 | loss 1.8977 | ppl   6.6706\n",
      "| epoch  20 |  1200/ 3125 batches | lr 0.0001 | ms/batch 31.54 | loss 1.9054 | ppl   6.7218\n",
      "| epoch  20 |  1400/ 3125 batches | lr 0.0001 | ms/batch 31.75 | loss 1.8669 | ppl   6.4679\n",
      "| epoch  20 |  1600/ 3125 batches | lr 0.0001 | ms/batch 31.64 | loss 1.9144 | ppl   6.7830\n",
      "| epoch  20 |  1800/ 3125 batches | lr 0.0001 | ms/batch 31.48 | loss 1.8983 | ppl   6.6743\n",
      "| epoch  20 |  2000/ 3125 batches | lr 0.0001 | ms/batch 31.91 | loss 1.8843 | ppl   6.5816\n",
      "| epoch  20 |  2200/ 3125 batches | lr 0.0001 | ms/batch 31.49 | loss 1.8851 | ppl   6.5870\n",
      "| epoch  20 |  2400/ 3125 batches | lr 0.0001 | ms/batch 31.83 | loss 1.8903 | ppl   6.6211\n",
      "| epoch  20 |  2600/ 3125 batches | lr 0.0001 | ms/batch 31.85 | loss 1.8447 | ppl   6.3265\n",
      "| epoch  20 |  2800/ 3125 batches | lr 0.0001 | ms/batch 31.85 | loss 1.9537 | ppl   7.0549\n",
      "| epoch  20 |  3000/ 3125 batches | lr 0.0001 | ms/batch 32.25 | loss 1.8531 | ppl   6.3798\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 99.51s | valid loss  2.84 | valid ppl    17.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  21 |   200/ 3125 batches | lr 0.0001 | ms/batch 31.82 | loss 1.8801 | ppl   6.5542\n",
      "| epoch  21 |   400/ 3125 batches | lr 0.0001 | ms/batch 32.34 | loss 1.8770 | ppl   6.5341\n",
      "| epoch  21 |   600/ 3125 batches | lr 0.0001 | ms/batch 32.04 | loss 1.8926 | ppl   6.6367\n",
      "| epoch  21 |   800/ 3125 batches | lr 0.0001 | ms/batch 31.76 | loss 1.9160 | ppl   6.7938\n",
      "| epoch  21 |  1000/ 3125 batches | lr 0.0001 | ms/batch 31.70 | loss 1.8992 | ppl   6.6807\n",
      "| epoch  21 |  1200/ 3125 batches | lr 0.0001 | ms/batch 31.99 | loss 1.9041 | ppl   6.7136\n",
      "| epoch  21 |  1400/ 3125 batches | lr 0.0001 | ms/batch 32.01 | loss 1.8670 | ppl   6.4689\n",
      "| epoch  21 |  1600/ 3125 batches | lr 0.0001 | ms/batch 32.28 | loss 1.9161 | ppl   6.7942\n",
      "| epoch  21 |  1800/ 3125 batches | lr 0.0001 | ms/batch 32.75 | loss 1.8973 | ppl   6.6680\n",
      "| epoch  21 |  2000/ 3125 batches | lr 0.0001 | ms/batch 32.56 | loss 1.8843 | ppl   6.5817\n",
      "| epoch  21 |  2200/ 3125 batches | lr 0.0001 | ms/batch 31.53 | loss 1.8853 | ppl   6.5882\n",
      "| epoch  21 |  2400/ 3125 batches | lr 0.0001 | ms/batch 31.78 | loss 1.8921 | ppl   6.6334\n",
      "| epoch  21 |  2600/ 3125 batches | lr 0.0001 | ms/batch 31.76 | loss 1.8436 | ppl   6.3193\n",
      "| epoch  21 |  2800/ 3125 batches | lr 0.0001 | ms/batch 31.86 | loss 1.9566 | ppl   7.0750\n",
      "| epoch  21 |  3000/ 3125 batches | lr 0.0001 | ms/batch 32.15 | loss 1.8548 | ppl   6.3906\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 100.01s | valid loss  2.84 | valid ppl    17.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |   200/ 3125 batches | lr 0.0001 | ms/batch 32.04 | loss 1.8809 | ppl   6.5596\n",
      "| epoch  22 |   400/ 3125 batches | lr 0.0001 | ms/batch 32.02 | loss 1.8778 | ppl   6.5391\n",
      "| epoch  22 |   600/ 3125 batches | lr 0.0001 | ms/batch 32.19 | loss 1.8925 | ppl   6.6357\n",
      "| epoch  22 |   800/ 3125 batches | lr 0.0001 | ms/batch 32.07 | loss 1.9171 | ppl   6.8013\n",
      "| epoch  22 |  1000/ 3125 batches | lr 0.0001 | ms/batch 31.61 | loss 1.8968 | ppl   6.6647\n",
      "| epoch  22 |  1200/ 3125 batches | lr 0.0001 | ms/batch 31.57 | loss 1.9059 | ppl   6.7252\n",
      "| epoch  22 |  1400/ 3125 batches | lr 0.0001 | ms/batch 31.87 | loss 1.8670 | ppl   6.4686\n",
      "| epoch  22 |  1600/ 3125 batches | lr 0.0001 | ms/batch 31.91 | loss 1.9145 | ppl   6.7834\n",
      "| epoch  22 |  1800/ 3125 batches | lr 0.0001 | ms/batch 31.82 | loss 1.8981 | ppl   6.6730\n",
      "| epoch  22 |  2000/ 3125 batches | lr 0.0001 | ms/batch 31.99 | loss 1.8835 | ppl   6.5763\n",
      "| epoch  22 |  2200/ 3125 batches | lr 0.0001 | ms/batch 31.99 | loss 1.8856 | ppl   6.5904\n",
      "| epoch  22 |  2400/ 3125 batches | lr 0.0001 | ms/batch 31.80 | loss 1.8927 | ppl   6.6371\n",
      "| epoch  22 |  2600/ 3125 batches | lr 0.0001 | ms/batch 31.76 | loss 1.8433 | ppl   6.3172\n",
      "| epoch  22 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.9560 | ppl   7.0710\n",
      "| epoch  22 |  3000/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.8519 | ppl   6.3719\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 99.61s | valid loss  2.85 | valid ppl    17.36\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  23 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8787 | ppl   6.5448\n",
      "| epoch  23 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8783 | ppl   6.5426\n",
      "| epoch  23 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.8924 | ppl   6.6354\n",
      "| epoch  23 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.79 | loss 1.9165 | ppl   6.7974\n",
      "| epoch  23 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.49 | loss 1.8977 | ppl   6.6705\n",
      "| epoch  23 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.53 | loss 1.9038 | ppl   6.7111\n",
      "| epoch  23 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8663 | ppl   6.4640\n",
      "| epoch  23 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.15 | loss 1.9151 | ppl   6.7876\n",
      "| epoch  23 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.59 | loss 1.8983 | ppl   6.6745\n",
      "| epoch  23 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8845 | ppl   6.5829\n",
      "| epoch  23 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8857 | ppl   6.5908\n",
      "| epoch  23 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8909 | ppl   6.6253\n",
      "| epoch  23 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.43 | loss 1.8440 | ppl   6.3216\n",
      "| epoch  23 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.9556 | ppl   7.0681\n",
      "| epoch  23 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.8527 | ppl   6.3772\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 99.50s | valid loss  2.86 | valid ppl    17.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.8802 | ppl   6.5546\n",
      "| epoch  24 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.8766 | ppl   6.5312\n",
      "| epoch  24 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8908 | ppl   6.6248\n",
      "| epoch  24 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.9163 | ppl   6.7960\n",
      "| epoch  24 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.45 | loss 1.8969 | ppl   6.6649\n",
      "| epoch  24 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.9056 | ppl   6.7234\n",
      "| epoch  24 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8663 | ppl   6.4641\n",
      "| epoch  24 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.14 | loss 1.9140 | ppl   6.7800\n",
      "| epoch  24 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8974 | ppl   6.6688\n",
      "| epoch  24 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.99 | loss 1.8833 | ppl   6.5749\n",
      "| epoch  24 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.47 | loss 1.8838 | ppl   6.5782\n",
      "| epoch  24 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.59 | loss 1.8903 | ppl   6.6212\n",
      "| epoch  24 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.79 | loss 1.8437 | ppl   6.3202\n",
      "| epoch  24 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.64 | loss 1.9543 | ppl   7.0589\n",
      "| epoch  24 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8530 | ppl   6.3792\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 99.50s | valid loss  2.85 | valid ppl    17.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  25 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8811 | ppl   6.5605\n",
      "| epoch  25 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8768 | ppl   6.5324\n",
      "| epoch  25 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.8938 | ppl   6.6446\n",
      "| epoch  25 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.9183 | ppl   6.8091\n",
      "| epoch  25 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8977 | ppl   6.6708\n",
      "| epoch  25 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.97 | loss 1.9045 | ppl   6.7161\n",
      "| epoch  25 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.8670 | ppl   6.4687\n",
      "| epoch  25 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.9143 | ppl   6.7825\n",
      "| epoch  25 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8985 | ppl   6.6759\n",
      "| epoch  25 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.8839 | ppl   6.5788\n",
      "| epoch  25 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.15 | loss 1.8849 | ppl   6.5856\n",
      "| epoch  25 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8908 | ppl   6.6249\n",
      "| epoch  25 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.8442 | ppl   6.3230\n",
      "| epoch  25 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.9554 | ppl   7.0667\n",
      "| epoch  25 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.8543 | ppl   6.3871\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 99.48s | valid loss  2.86 | valid ppl    17.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  26 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8806 | ppl   6.5575\n",
      "| epoch  26 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.48 | loss 1.8777 | ppl   6.5381\n",
      "| epoch  26 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.8906 | ppl   6.6234\n",
      "| epoch  26 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.9168 | ppl   6.7993\n",
      "| epoch  26 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.8985 | ppl   6.6758\n",
      "| epoch  26 |  1200/ 3125 batches | lr 0.0000 | ms/batch 33.25 | loss 1.9042 | ppl   6.7138\n",
      "| epoch  26 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.83 | loss 1.8667 | ppl   6.4670\n",
      "| epoch  26 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.58 | loss 1.9142 | ppl   6.7815\n",
      "| epoch  26 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.76 | loss 1.8985 | ppl   6.6758\n",
      "| epoch  26 |  2000/ 3125 batches | lr 0.0000 | ms/batch 33.52 | loss 1.8838 | ppl   6.5784\n",
      "| epoch  26 |  2200/ 3125 batches | lr 0.0000 | ms/batch 33.19 | loss 1.8845 | ppl   6.5832\n",
      "| epoch  26 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.41 | loss 1.8907 | ppl   6.6240\n",
      "| epoch  26 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.66 | loss 1.8445 | ppl   6.3252\n",
      "| epoch  26 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.49 | loss 1.9549 | ppl   7.0629\n",
      "| epoch  26 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8538 | ppl   6.3838\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 100.83s | valid loss  2.86 | valid ppl    17.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  27 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.8823 | ppl   6.5683\n",
      "| epoch  27 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.8759 | ppl   6.5266\n",
      "| epoch  27 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.03 | loss 1.8923 | ppl   6.6347\n",
      "| epoch  27 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.9155 | ppl   6.7905\n",
      "| epoch  27 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.17 | loss 1.8970 | ppl   6.6661\n",
      "| epoch  27 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.56 | loss 1.9037 | ppl   6.7103\n",
      "| epoch  27 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.49 | loss 1.8670 | ppl   6.4688\n",
      "| epoch  27 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.84 | loss 1.9142 | ppl   6.7818\n",
      "| epoch  27 |  1800/ 3125 batches | lr 0.0000 | ms/batch 33.59 | loss 1.8974 | ppl   6.6687\n",
      "| epoch  27 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.75 | loss 1.8823 | ppl   6.5689\n",
      "| epoch  27 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.72 | loss 1.8837 | ppl   6.5779\n",
      "| epoch  27 |  2400/ 3125 batches | lr 0.0000 | ms/batch 33.07 | loss 1.8899 | ppl   6.6185\n",
      "| epoch  27 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.23 | loss 1.8432 | ppl   6.3169\n",
      "| epoch  27 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.13 | loss 1.9552 | ppl   7.0656\n",
      "| epoch  27 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.8546 | ppl   6.3893\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 100.68s | valid loss  2.86 | valid ppl    17.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  28 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8815 | ppl   6.5630\n",
      "| epoch  28 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.20 | loss 1.8761 | ppl   6.5283\n",
      "| epoch  28 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8919 | ppl   6.6317\n",
      "| epoch  28 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.9175 | ppl   6.8038\n",
      "| epoch  28 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.15 | loss 1.8977 | ppl   6.6704\n",
      "| epoch  28 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.47 | loss 1.9048 | ppl   6.7180\n",
      "| epoch  28 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.8668 | ppl   6.4677\n",
      "| epoch  28 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.9144 | ppl   6.7826\n",
      "| epoch  28 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.8971 | ppl   6.6667\n",
      "| epoch  28 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.44 | loss 1.8841 | ppl   6.5806\n",
      "| epoch  28 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8849 | ppl   6.5856\n",
      "| epoch  28 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.19 | loss 1.8921 | ppl   6.6330\n",
      "| epoch  28 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.8437 | ppl   6.3199\n",
      "| epoch  28 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.03 | loss 1.9546 | ppl   7.0610\n",
      "| epoch  28 |  3000/ 3125 batches | lr 0.0000 | ms/batch 32.33 | loss 1.8521 | ppl   6.3735\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 99.70s | valid loss  2.86 | valid ppl    17.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  29 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8811 | ppl   6.5609\n",
      "| epoch  29 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.8764 | ppl   6.5302\n",
      "| epoch  29 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.40 | loss 1.8932 | ppl   6.6405\n",
      "| epoch  29 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.9165 | ppl   6.7969\n",
      "| epoch  29 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.29 | loss 1.8970 | ppl   6.6661\n",
      "| epoch  29 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.9046 | ppl   6.7165\n",
      "| epoch  29 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8664 | ppl   6.4653\n",
      "| epoch  29 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.9143 | ppl   6.7824\n",
      "| epoch  29 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8989 | ppl   6.6782\n",
      "| epoch  29 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.59 | loss 1.8829 | ppl   6.5723\n",
      "| epoch  29 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8836 | ppl   6.5769\n",
      "| epoch  29 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.8903 | ppl   6.6216\n",
      "| epoch  29 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.64 | loss 1.8449 | ppl   6.3277\n",
      "| epoch  29 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.63 | loss 1.9566 | ppl   7.0753\n",
      "| epoch  29 |  3000/ 3125 batches | lr 0.0000 | ms/batch 32.16 | loss 1.8545 | ppl   6.3885\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 99.41s | valid loss  2.86 | valid ppl    17.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  30 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.8802 | ppl   6.5548\n",
      "| epoch  30 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.8753 | ppl   6.5228\n",
      "| epoch  30 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8927 | ppl   6.6371\n",
      "| epoch  30 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.9165 | ppl   6.7974\n",
      "| epoch  30 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8971 | ppl   6.6668\n",
      "| epoch  30 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.9039 | ppl   6.7123\n",
      "| epoch  30 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.8661 | ppl   6.4633\n",
      "| epoch  30 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.9144 | ppl   6.7831\n",
      "| epoch  30 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.12 | loss 1.8978 | ppl   6.6714\n",
      "| epoch  30 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.8840 | ppl   6.5800\n",
      "| epoch  30 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.79 | loss 1.8850 | ppl   6.5862\n",
      "| epoch  30 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.8912 | ppl   6.6273\n",
      "| epoch  30 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.45 | loss 1.8435 | ppl   6.3187\n",
      "| epoch  30 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.15 | loss 1.9545 | ppl   7.0602\n",
      "| epoch  30 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.95 | loss 1.8528 | ppl   6.3777\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 99.39s | valid loss  2.86 | valid ppl    17.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  31 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8808 | ppl   6.5589\n",
      "| epoch  31 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.8769 | ppl   6.5332\n",
      "| epoch  31 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.8919 | ppl   6.6321\n",
      "| epoch  31 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.95 | loss 1.9161 | ppl   6.7942\n",
      "| epoch  31 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.8962 | ppl   6.6605\n",
      "| epoch  31 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.9038 | ppl   6.7117\n",
      "| epoch  31 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.8666 | ppl   6.4664\n",
      "| epoch  31 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.9147 | ppl   6.7851\n",
      "| epoch  31 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8998 | ppl   6.6844\n",
      "| epoch  31 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.45 | loss 1.8823 | ppl   6.5685\n",
      "| epoch  31 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8841 | ppl   6.5804\n",
      "| epoch  31 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8905 | ppl   6.6224\n",
      "| epoch  31 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.39 | loss 1.8440 | ppl   6.3215\n",
      "| epoch  31 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.14 | loss 1.9546 | ppl   7.0614\n",
      "| epoch  31 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.95 | loss 1.8518 | ppl   6.3714\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 99.27s | valid loss  2.86 | valid ppl    17.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  32 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8802 | ppl   6.5548\n",
      "| epoch  32 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8768 | ppl   6.5324\n",
      "| epoch  32 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.19 | loss 1.8913 | ppl   6.6277\n",
      "| epoch  32 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.45 | loss 1.9158 | ppl   6.7921\n",
      "| epoch  32 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.8973 | ppl   6.6679\n",
      "| epoch  32 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.9053 | ppl   6.7214\n",
      "| epoch  32 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.8665 | ppl   6.4654\n",
      "| epoch  32 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.9155 | ppl   6.7905\n",
      "| epoch  32 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8982 | ppl   6.6741\n",
      "| epoch  32 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.45 | loss 1.8832 | ppl   6.5748\n",
      "| epoch  32 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8850 | ppl   6.5864\n",
      "| epoch  32 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.8911 | ppl   6.6267\n",
      "| epoch  32 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8440 | ppl   6.3215\n",
      "| epoch  32 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.9545 | ppl   7.0601\n",
      "| epoch  32 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.8528 | ppl   6.3774\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 99.35s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  33 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.55 | loss 1.8799 | ppl   6.5527\n",
      "| epoch  33 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8775 | ppl   6.5374\n",
      "| epoch  33 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.54 | loss 1.8917 | ppl   6.6308\n",
      "| epoch  33 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.60 | loss 1.9170 | ppl   6.8007\n",
      "| epoch  33 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.8973 | ppl   6.6680\n",
      "| epoch  33 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.9028 | ppl   6.7043\n",
      "| epoch  33 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.36 | loss 1.8668 | ppl   6.4673\n",
      "| epoch  33 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.9142 | ppl   6.7818\n",
      "| epoch  33 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.08 | loss 1.8984 | ppl   6.6750\n",
      "| epoch  33 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.25 | loss 1.8839 | ppl   6.5788\n",
      "| epoch  33 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.8842 | ppl   6.5814\n",
      "| epoch  33 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.59 | loss 1.8909 | ppl   6.6251\n",
      "| epoch  33 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8437 | ppl   6.3198\n",
      "| epoch  33 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.58 | loss 1.9564 | ppl   7.0737\n",
      "| epoch  33 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8526 | ppl   6.3766\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 99.48s | valid loss  2.85 | valid ppl    17.33\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  34 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.8800 | ppl   6.5534\n",
      "| epoch  34 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8759 | ppl   6.5269\n",
      "| epoch  34 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8938 | ppl   6.6445\n",
      "| epoch  34 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.9173 | ppl   6.8023\n",
      "| epoch  34 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.8975 | ppl   6.6693\n",
      "| epoch  34 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.63 | loss 1.9040 | ppl   6.7128\n",
      "| epoch  34 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.95 | loss 1.8663 | ppl   6.4643\n",
      "| epoch  34 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.54 | loss 1.9159 | ppl   6.7928\n",
      "| epoch  34 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.08 | loss 1.8984 | ppl   6.6750\n",
      "| epoch  34 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.48 | loss 1.8827 | ppl   6.5711\n",
      "| epoch  34 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8851 | ppl   6.5868\n",
      "| epoch  34 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.49 | loss 1.8907 | ppl   6.6238\n",
      "| epoch  34 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.8439 | ppl   6.3208\n",
      "| epoch  34 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.9550 | ppl   7.0638\n",
      "| epoch  34 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.48 | loss 1.8540 | ppl   6.3852\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 99.30s | valid loss  2.85 | valid ppl    17.33\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  35 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.8797 | ppl   6.5514\n",
      "| epoch  35 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8763 | ppl   6.5293\n",
      "| epoch  35 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.8918 | ppl   6.6315\n",
      "| epoch  35 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.9164 | ppl   6.7968\n",
      "| epoch  35 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.60 | loss 1.8979 | ppl   6.6722\n",
      "| epoch  35 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.9050 | ppl   6.7195\n",
      "| epoch  35 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.12 | loss 1.8669 | ppl   6.4681\n",
      "| epoch  35 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.9155 | ppl   6.7902\n",
      "| epoch  35 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.79 | loss 1.8978 | ppl   6.6711\n",
      "| epoch  35 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.8840 | ppl   6.5799\n",
      "| epoch  35 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.59 | loss 1.8846 | ppl   6.5837\n",
      "| epoch  35 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.43 | loss 1.8896 | ppl   6.6166\n",
      "| epoch  35 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.8441 | ppl   6.3224\n",
      "| epoch  35 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.63 | loss 1.9561 | ppl   7.0718\n",
      "| epoch  35 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.55 | loss 1.8523 | ppl   6.3745\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 99.25s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  36 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.8797 | ppl   6.5516\n",
      "| epoch  36 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.34 | loss 1.8771 | ppl   6.5346\n",
      "| epoch  36 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8919 | ppl   6.6320\n",
      "| epoch  36 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.9160 | ppl   6.7935\n",
      "| epoch  36 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8961 | ppl   6.6598\n",
      "| epoch  36 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.9035 | ppl   6.7092\n",
      "| epoch  36 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.8675 | ppl   6.4723\n",
      "| epoch  36 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.55 | loss 1.9145 | ppl   6.7837\n",
      "| epoch  36 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.8975 | ppl   6.6693\n",
      "| epoch  36 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8836 | ppl   6.5773\n",
      "| epoch  36 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.47 | loss 1.8845 | ppl   6.5830\n",
      "| epoch  36 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.99 | loss 1.8906 | ppl   6.6235\n",
      "| epoch  36 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.40 | loss 1.8450 | ppl   6.3279\n",
      "| epoch  36 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.9557 | ppl   7.0685\n",
      "| epoch  36 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8534 | ppl   6.3814\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 99.38s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  37 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8800 | ppl   6.5533\n",
      "| epoch  37 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.59 | loss 1.8762 | ppl   6.5286\n",
      "| epoch  37 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8925 | ppl   6.6363\n",
      "| epoch  37 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.9165 | ppl   6.7969\n",
      "| epoch  37 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.18 | loss 1.8944 | ppl   6.6484\n",
      "| epoch  37 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.50 | loss 1.9055 | ppl   6.7230\n",
      "| epoch  37 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.8687 | ppl   6.4797\n",
      "| epoch  37 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.95 | loss 1.9153 | ppl   6.7888\n",
      "| epoch  37 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.64 | loss 1.8976 | ppl   6.6696\n",
      "| epoch  37 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.98 | loss 1.8837 | ppl   6.5781\n",
      "| epoch  37 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.8832 | ppl   6.5744\n",
      "| epoch  37 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8909 | ppl   6.6256\n",
      "| epoch  37 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.44 | loss 1.8433 | ppl   6.3172\n",
      "| epoch  37 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.9540 | ppl   7.0568\n",
      "| epoch  37 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.8522 | ppl   6.3737\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 99.41s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  38 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.8803 | ppl   6.5552\n",
      "| epoch  38 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.98 | loss 1.8773 | ppl   6.5357\n",
      "| epoch  38 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8920 | ppl   6.6328\n",
      "| epoch  38 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.9180 | ppl   6.8075\n",
      "| epoch  38 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8971 | ppl   6.6668\n",
      "| epoch  38 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.9042 | ppl   6.7143\n",
      "| epoch  38 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.8663 | ppl   6.4645\n",
      "| epoch  38 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.53 | loss 1.9142 | ppl   6.7814\n",
      "| epoch  38 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8973 | ppl   6.6680\n",
      "| epoch  38 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.43 | loss 1.8851 | ppl   6.5870\n",
      "| epoch  38 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8839 | ppl   6.5790\n",
      "| epoch  38 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8904 | ppl   6.6223\n",
      "| epoch  38 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.8441 | ppl   6.3226\n",
      "| epoch  38 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.9552 | ppl   7.0655\n",
      "| epoch  38 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.8539 | ppl   6.3849\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 99.36s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  39 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.8797 | ppl   6.5515\n",
      "| epoch  39 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.8772 | ppl   6.5353\n",
      "| epoch  39 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.60 | loss 1.8919 | ppl   6.6319\n",
      "| epoch  39 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.42 | loss 1.9180 | ppl   6.8072\n",
      "| epoch  39 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8971 | ppl   6.6664\n",
      "| epoch  39 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.9045 | ppl   6.7161\n",
      "| epoch  39 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.40 | loss 1.8657 | ppl   6.4604\n",
      "| epoch  39 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.9153 | ppl   6.7891\n",
      "| epoch  39 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.56 | loss 1.8979 | ppl   6.6722\n",
      "| epoch  39 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.43 | loss 1.8818 | ppl   6.5655\n",
      "| epoch  39 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.8847 | ppl   6.5844\n",
      "| epoch  39 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.16 | loss 1.8908 | ppl   6.6246\n",
      "| epoch  39 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.79 | loss 1.8439 | ppl   6.3214\n",
      "| epoch  39 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.9536 | ppl   7.0539\n",
      "| epoch  39 |  3000/ 3125 batches | lr 0.0000 | ms/batch 32.03 | loss 1.8528 | ppl   6.3776\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 99.83s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  40 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.19 | loss 1.8805 | ppl   6.5566\n",
      "| epoch  40 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.36 | loss 1.8767 | ppl   6.5316\n",
      "| epoch  40 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.8932 | ppl   6.6404\n",
      "| epoch  40 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.9166 | ppl   6.7977\n",
      "| epoch  40 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.8966 | ppl   6.6635\n",
      "| epoch  40 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.15 | loss 1.9044 | ppl   6.7154\n",
      "| epoch  40 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8658 | ppl   6.4614\n",
      "| epoch  40 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.9154 | ppl   6.7895\n",
      "| epoch  40 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.8979 | ppl   6.6720\n",
      "| epoch  40 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.17 | loss 1.8824 | ppl   6.5691\n",
      "| epoch  40 |  2200/ 3125 batches | lr 0.0000 | ms/batch 33.80 | loss 1.8853 | ppl   6.5886\n",
      "| epoch  40 |  2400/ 3125 batches | lr 0.0000 | ms/batch 33.29 | loss 1.8901 | ppl   6.6203\n",
      "| epoch  40 |  2600/ 3125 batches | lr 0.0000 | ms/batch 33.12 | loss 1.8435 | ppl   6.3186\n",
      "| epoch  40 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.97 | loss 1.9555 | ppl   7.0671\n",
      "| epoch  40 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8520 | ppl   6.3728\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 100.59s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  41 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.8810 | ppl   6.5603\n",
      "| epoch  41 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.18 | loss 1.8751 | ppl   6.5216\n",
      "| epoch  41 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.65 | loss 1.8932 | ppl   6.6409\n",
      "| epoch  41 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.99 | loss 1.9166 | ppl   6.7979\n",
      "| epoch  41 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8974 | ppl   6.6686\n",
      "| epoch  41 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.9043 | ppl   6.7150\n",
      "| epoch  41 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8673 | ppl   6.4709\n",
      "| epoch  41 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.9146 | ppl   6.7843\n",
      "| epoch  41 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.06 | loss 1.8969 | ppl   6.6649\n",
      "| epoch  41 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.59 | loss 1.8821 | ppl   6.5674\n",
      "| epoch  41 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8846 | ppl   6.5836\n",
      "| epoch  41 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.8908 | ppl   6.6243\n",
      "| epoch  41 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.79 | loss 1.8443 | ppl   6.3237\n",
      "| epoch  41 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.9562 | ppl   7.0723\n",
      "| epoch  41 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.8524 | ppl   6.3751\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 99.68s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  42 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8802 | ppl   6.5547\n",
      "| epoch  42 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.8761 | ppl   6.5280\n",
      "| epoch  42 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.8916 | ppl   6.6298\n",
      "| epoch  42 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.9170 | ppl   6.8003\n",
      "| epoch  42 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.42 | loss 1.8977 | ppl   6.6703\n",
      "| epoch  42 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.06 | loss 1.9035 | ppl   6.7090\n",
      "| epoch  42 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.35 | loss 1.8664 | ppl   6.4648\n",
      "| epoch  42 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.9148 | ppl   6.7853\n",
      "| epoch  42 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.36 | loss 1.8980 | ppl   6.6728\n",
      "| epoch  42 |  2000/ 3125 batches | lr 0.0000 | ms/batch 33.51 | loss 1.8839 | ppl   6.5790\n",
      "| epoch  42 |  2200/ 3125 batches | lr 0.0000 | ms/batch 33.08 | loss 1.8848 | ppl   6.5848\n",
      "| epoch  42 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.37 | loss 1.8908 | ppl   6.6245\n",
      "| epoch  42 |  2600/ 3125 batches | lr 0.0000 | ms/batch 33.11 | loss 1.8446 | ppl   6.3259\n",
      "| epoch  42 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.20 | loss 1.9558 | ppl   7.0696\n",
      "| epoch  42 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.8540 | ppl   6.3854\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 100.48s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  43 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.8801 | ppl   6.5543\n",
      "| epoch  43 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.8761 | ppl   6.5278\n",
      "| epoch  43 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.33 | loss 1.8945 | ppl   6.6490\n",
      "| epoch  43 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.59 | loss 1.9170 | ppl   6.8008\n",
      "| epoch  43 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.49 | loss 1.8971 | ppl   6.6665\n",
      "| epoch  43 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.9041 | ppl   6.7136\n",
      "| epoch  43 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8656 | ppl   6.4597\n",
      "| epoch  43 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.9149 | ppl   6.7863\n",
      "| epoch  43 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.8969 | ppl   6.6653\n",
      "| epoch  43 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8833 | ppl   6.5752\n",
      "| epoch  43 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8842 | ppl   6.5811\n",
      "| epoch  43 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8904 | ppl   6.6219\n",
      "| epoch  43 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.8439 | ppl   6.3213\n",
      "| epoch  43 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.9545 | ppl   7.0603\n",
      "| epoch  43 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.8537 | ppl   6.3837\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 99.64s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  44 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.98 | loss 1.8812 | ppl   6.5611\n",
      "| epoch  44 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.8775 | ppl   6.5368\n",
      "| epoch  44 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.8932 | ppl   6.6408\n",
      "| epoch  44 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.20 | loss 1.9178 | ppl   6.8060\n",
      "| epoch  44 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.8962 | ppl   6.6609\n",
      "| epoch  44 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.9045 | ppl   6.7161\n",
      "| epoch  44 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.64 | loss 1.8650 | ppl   6.4558\n",
      "| epoch  44 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.9153 | ppl   6.7892\n",
      "| epoch  44 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8964 | ppl   6.6616\n",
      "| epoch  44 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.56 | loss 1.8827 | ppl   6.5710\n",
      "| epoch  44 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.16 | loss 1.8857 | ppl   6.5909\n",
      "| epoch  44 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.52 | loss 1.8899 | ppl   6.6189\n",
      "| epoch  44 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.8423 | ppl   6.3109\n",
      "| epoch  44 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.9562 | ppl   7.0724\n",
      "| epoch  44 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.8534 | ppl   6.3816\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 99.33s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  45 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.8811 | ppl   6.5604\n",
      "| epoch  45 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.32 | loss 1.8763 | ppl   6.5291\n",
      "| epoch  45 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.56 | loss 1.8909 | ppl   6.6251\n",
      "| epoch  45 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.9159 | ppl   6.7930\n",
      "| epoch  45 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.17 | loss 1.8959 | ppl   6.6587\n",
      "| epoch  45 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.9071 | ppl   6.7335\n",
      "| epoch  45 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8683 | ppl   6.4772\n",
      "| epoch  45 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.16 | loss 1.9164 | ppl   6.7964\n",
      "| epoch  45 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.8975 | ppl   6.6692\n",
      "| epoch  45 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.79 | loss 1.8826 | ppl   6.5705\n",
      "| epoch  45 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.8836 | ppl   6.5771\n",
      "| epoch  45 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.8919 | ppl   6.6316\n",
      "| epoch  45 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8436 | ppl   6.3191\n",
      "| epoch  45 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.9553 | ppl   7.0663\n",
      "| epoch  45 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.8531 | ppl   6.3795\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 99.61s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  46 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.8815 | ppl   6.5633\n",
      "| epoch  46 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8760 | ppl   6.5274\n",
      "| epoch  46 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.8929 | ppl   6.6383\n",
      "| epoch  46 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.99 | loss 1.9168 | ppl   6.7990\n",
      "| epoch  46 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.99 | loss 1.8963 | ppl   6.6611\n",
      "| epoch  46 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.9048 | ppl   6.7183\n",
      "| epoch  46 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.21 | loss 1.8673 | ppl   6.4710\n",
      "| epoch  46 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.12 | loss 1.9136 | ppl   6.7776\n",
      "| epoch  46 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.8977 | ppl   6.6707\n",
      "| epoch  46 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.98 | loss 1.8837 | ppl   6.5777\n",
      "| epoch  46 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8850 | ppl   6.5866\n",
      "| epoch  46 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.97 | loss 1.8895 | ppl   6.6161\n",
      "| epoch  46 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.8438 | ppl   6.3207\n",
      "| epoch  46 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.60 | loss 1.9557 | ppl   7.0691\n",
      "| epoch  46 |  3000/ 3125 batches | lr 0.0000 | ms/batch 32.11 | loss 1.8529 | ppl   6.3782\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 99.74s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  47 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.8800 | ppl   6.5537\n",
      "| epoch  47 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8755 | ppl   6.5240\n",
      "| epoch  47 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.8927 | ppl   6.6375\n",
      "| epoch  47 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.9158 | ppl   6.7924\n",
      "| epoch  47 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.08 | loss 1.8988 | ppl   6.6780\n",
      "| epoch  47 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.9058 | ppl   6.7245\n",
      "| epoch  47 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.8675 | ppl   6.4724\n",
      "| epoch  47 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.9154 | ppl   6.7895\n",
      "| epoch  47 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8974 | ppl   6.6684\n",
      "| epoch  47 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8825 | ppl   6.5696\n",
      "| epoch  47 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.8847 | ppl   6.5843\n",
      "| epoch  47 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8898 | ppl   6.6180\n",
      "| epoch  47 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.8445 | ppl   6.3247\n",
      "| epoch  47 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.9546 | ppl   7.0612\n",
      "| epoch  47 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8535 | ppl   6.3823\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 99.48s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  48 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8806 | ppl   6.5575\n",
      "| epoch  48 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.8773 | ppl   6.5355\n",
      "| epoch  48 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.93 | loss 1.8932 | ppl   6.6408\n",
      "| epoch  48 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.16 | loss 1.9175 | ppl   6.8037\n",
      "| epoch  48 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8967 | ppl   6.6638\n",
      "| epoch  48 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.97 | loss 1.9043 | ppl   6.7148\n",
      "| epoch  48 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.8667 | ppl   6.4668\n",
      "| epoch  48 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.9146 | ppl   6.7846\n",
      "| epoch  48 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8977 | ppl   6.6706\n",
      "| epoch  48 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.06 | loss 1.8843 | ppl   6.5816\n",
      "| epoch  48 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.8842 | ppl   6.5810\n",
      "| epoch  48 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.8915 | ppl   6.6292\n",
      "| epoch  48 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8427 | ppl   6.3135\n",
      "| epoch  48 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.15 | loss 1.9540 | ppl   7.0568\n",
      "| epoch  48 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.8540 | ppl   6.3855\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 99.55s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  49 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.21 | loss 1.8806 | ppl   6.5577\n",
      "| epoch  49 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8768 | ppl   6.5323\n",
      "| epoch  49 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.42 | loss 1.8927 | ppl   6.6372\n",
      "| epoch  49 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.9159 | ppl   6.7932\n",
      "| epoch  49 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8984 | ppl   6.6751\n",
      "| epoch  49 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.45 | loss 1.9042 | ppl   6.7141\n",
      "| epoch  49 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8663 | ppl   6.4641\n",
      "| epoch  49 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.60 | loss 1.9141 | ppl   6.7811\n",
      "| epoch  49 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.95 | loss 1.8971 | ppl   6.6662\n",
      "| epoch  49 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8831 | ppl   6.5738\n",
      "| epoch  49 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.98 | loss 1.8854 | ppl   6.5888\n",
      "| epoch  49 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.65 | loss 1.8908 | ppl   6.6249\n",
      "| epoch  49 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8436 | ppl   6.3190\n",
      "| epoch  49 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.9527 | ppl   7.0478\n",
      "| epoch  49 |  3000/ 3125 batches | lr 0.0000 | ms/batch 32.19 | loss 1.8522 | ppl   6.3736\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 99.41s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  50 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8805 | ppl   6.5568\n",
      "| epoch  50 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.63 | loss 1.8763 | ppl   6.5294\n",
      "| epoch  50 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.65 | loss 1.8938 | ppl   6.6444\n",
      "| epoch  50 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.61 | loss 1.9161 | ppl   6.7947\n",
      "| epoch  50 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8966 | ppl   6.6632\n",
      "| epoch  50 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.9040 | ppl   6.7130\n",
      "| epoch  50 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8675 | ppl   6.4720\n",
      "| epoch  50 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.9136 | ppl   6.7775\n",
      "| epoch  50 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.21 | loss 1.8987 | ppl   6.6772\n",
      "| epoch  50 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.8820 | ppl   6.5667\n",
      "| epoch  50 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8828 | ppl   6.5721\n",
      "| epoch  50 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8912 | ppl   6.6275\n",
      "| epoch  50 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.79 | loss 1.8440 | ppl   6.3215\n",
      "| epoch  50 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.22 | loss 1.9554 | ppl   7.0664\n",
      "| epoch  50 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.8521 | ppl   6.3729\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 99.37s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  51 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.20 | loss 1.8800 | ppl   6.5535\n",
      "| epoch  51 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.8772 | ppl   6.5349\n",
      "| epoch  51 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.06 | loss 1.8916 | ppl   6.6302\n",
      "| epoch  51 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.56 | loss 1.9156 | ppl   6.7910\n",
      "| epoch  51 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.8955 | ppl   6.6559\n",
      "| epoch  51 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.64 | loss 1.9040 | ppl   6.7127\n",
      "| epoch  51 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.99 | loss 1.8652 | ppl   6.4569\n",
      "| epoch  51 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.9151 | ppl   6.7874\n",
      "| epoch  51 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.15 | loss 1.8973 | ppl   6.6681\n",
      "| epoch  51 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.64 | loss 1.8843 | ppl   6.5814\n",
      "| epoch  51 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8835 | ppl   6.5767\n",
      "| epoch  51 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8909 | ppl   6.6252\n",
      "| epoch  51 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.18 | loss 1.8448 | ppl   6.3270\n",
      "| epoch  51 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.9548 | ppl   7.0625\n",
      "| epoch  51 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.58 | loss 1.8539 | ppl   6.3848\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time: 99.57s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  52 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.79 | loss 1.8809 | ppl   6.5595\n",
      "| epoch  52 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8768 | ppl   6.5324\n",
      "| epoch  52 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.8916 | ppl   6.6300\n",
      "| epoch  52 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.9164 | ppl   6.7962\n",
      "| epoch  52 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8963 | ppl   6.6610\n",
      "| epoch  52 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.9043 | ppl   6.7147\n",
      "| epoch  52 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.8669 | ppl   6.4682\n",
      "| epoch  52 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.61 | loss 1.9131 | ppl   6.7741\n",
      "| epoch  52 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8982 | ppl   6.6737\n",
      "| epoch  52 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.51 | loss 1.8833 | ppl   6.5753\n",
      "| epoch  52 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.03 | loss 1.8842 | ppl   6.5813\n",
      "| epoch  52 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8904 | ppl   6.6217\n",
      "| epoch  52 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.8428 | ppl   6.3140\n",
      "| epoch  52 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.9548 | ppl   7.0623\n",
      "| epoch  52 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.8532 | ppl   6.3802\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time: 99.31s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  53 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.8796 | ppl   6.5510\n",
      "| epoch  53 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.8773 | ppl   6.5359\n",
      "| epoch  53 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8923 | ppl   6.6345\n",
      "| epoch  53 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.9165 | ppl   6.7972\n",
      "| epoch  53 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.16 | loss 1.8966 | ppl   6.6634\n",
      "| epoch  53 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.9042 | ppl   6.7142\n",
      "| epoch  53 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.8663 | ppl   6.4641\n",
      "| epoch  53 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.9139 | ppl   6.7795\n",
      "| epoch  53 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8981 | ppl   6.6732\n",
      "| epoch  53 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.8837 | ppl   6.5775\n",
      "| epoch  53 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.48 | loss 1.8839 | ppl   6.5791\n",
      "| epoch  53 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.26 | loss 1.8906 | ppl   6.6233\n",
      "| epoch  53 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8434 | ppl   6.3179\n",
      "| epoch  53 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.9556 | ppl   7.0680\n",
      "| epoch  53 |  3000/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.8537 | ppl   6.3831\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time: 99.46s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  54 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.8798 | ppl   6.5520\n",
      "| epoch  54 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8764 | ppl   6.5299\n",
      "| epoch  54 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8923 | ppl   6.6348\n",
      "| epoch  54 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.38 | loss 1.9168 | ppl   6.7992\n",
      "| epoch  54 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8955 | ppl   6.6561\n",
      "| epoch  54 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.9046 | ppl   6.7168\n",
      "| epoch  54 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8657 | ppl   6.4607\n",
      "| epoch  54 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.9154 | ppl   6.7898\n",
      "| epoch  54 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.8990 | ppl   6.6791\n",
      "| epoch  54 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8823 | ppl   6.5684\n",
      "| epoch  54 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.56 | loss 1.8842 | ppl   6.5810\n",
      "| epoch  54 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8916 | ppl   6.6300\n",
      "| epoch  54 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.44 | loss 1.8440 | ppl   6.3219\n",
      "| epoch  54 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.9560 | ppl   7.0713\n",
      "| epoch  54 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.65 | loss 1.8524 | ppl   6.3754\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time: 99.45s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  55 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.34 | loss 1.8812 | ppl   6.5616\n",
      "| epoch  55 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.8758 | ppl   6.5257\n",
      "| epoch  55 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.14 | loss 1.8929 | ppl   6.6383\n",
      "| epoch  55 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.9172 | ppl   6.8017\n",
      "| epoch  55 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8970 | ppl   6.6658\n",
      "| epoch  55 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.9046 | ppl   6.7169\n",
      "| epoch  55 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.06 | loss 1.8661 | ppl   6.4633\n",
      "| epoch  55 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.9152 | ppl   6.7883\n",
      "| epoch  55 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.95 | loss 1.8995 | ppl   6.6824\n",
      "| epoch  55 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.8834 | ppl   6.5760\n",
      "| epoch  55 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.49 | loss 1.8851 | ppl   6.5868\n",
      "| epoch  55 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8884 | ppl   6.6088\n",
      "| epoch  55 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.8441 | ppl   6.3226\n",
      "| epoch  55 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.64 | loss 1.9557 | ppl   7.0689\n",
      "| epoch  55 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.50 | loss 1.8526 | ppl   6.3762\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time: 99.44s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  56 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.40 | loss 1.8804 | ppl   6.5564\n",
      "| epoch  56 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.8758 | ppl   6.5261\n",
      "| epoch  56 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.8914 | ppl   6.6288\n",
      "| epoch  56 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.9169 | ppl   6.8000\n",
      "| epoch  56 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.26 | loss 1.8962 | ppl   6.6605\n",
      "| epoch  56 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.9033 | ppl   6.7079\n",
      "| epoch  56 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.8675 | ppl   6.4722\n",
      "| epoch  56 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.9141 | ppl   6.7810\n",
      "| epoch  56 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8977 | ppl   6.6703\n",
      "| epoch  56 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.99 | loss 1.8823 | ppl   6.5683\n",
      "| epoch  56 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.50 | loss 1.8840 | ppl   6.5796\n",
      "| epoch  56 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.63 | loss 1.8893 | ppl   6.6149\n",
      "| epoch  56 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8438 | ppl   6.3204\n",
      "| epoch  56 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.93 | loss 1.9555 | ppl   7.0671\n",
      "| epoch  56 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.8533 | ppl   6.3808\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time: 99.55s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  57 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.8807 | ppl   6.5578\n",
      "| epoch  57 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8772 | ppl   6.5354\n",
      "| epoch  57 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.08 | loss 1.8917 | ppl   6.6305\n",
      "| epoch  57 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.24 | loss 1.9165 | ppl   6.7970\n",
      "| epoch  57 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.8968 | ppl   6.6647\n",
      "| epoch  57 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.9043 | ppl   6.7146\n",
      "| epoch  57 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8657 | ppl   6.4604\n",
      "| epoch  57 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.9140 | ppl   6.7801\n",
      "| epoch  57 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.55 | loss 1.8973 | ppl   6.6681\n",
      "| epoch  57 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.72 | loss 1.8827 | ppl   6.5712\n",
      "| epoch  57 |  2200/ 3125 batches | lr 0.0000 | ms/batch 33.07 | loss 1.8847 | ppl   6.5846\n",
      "| epoch  57 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.13 | loss 1.8897 | ppl   6.6175\n",
      "| epoch  57 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.30 | loss 1.8432 | ppl   6.3165\n",
      "| epoch  57 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.9562 | ppl   7.0727\n",
      "| epoch  57 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8531 | ppl   6.3794\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time: 100.08s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  58 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8791 | ppl   6.5475\n",
      "| epoch  58 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.8762 | ppl   6.5287\n",
      "| epoch  58 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.65 | loss 1.8929 | ppl   6.6389\n",
      "| epoch  58 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.9159 | ppl   6.7930\n",
      "| epoch  58 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8976 | ppl   6.6699\n",
      "| epoch  58 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.9021 | ppl   6.7000\n",
      "| epoch  58 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.14 | loss 1.8657 | ppl   6.4604\n",
      "| epoch  58 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.9151 | ppl   6.7876\n",
      "| epoch  58 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8980 | ppl   6.6727\n",
      "| epoch  58 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.8839 | ppl   6.5793\n",
      "| epoch  58 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.8854 | ppl   6.5892\n",
      "| epoch  58 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8899 | ppl   6.6188\n",
      "| epoch  58 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.95 | loss 1.8440 | ppl   6.3221\n",
      "| epoch  58 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.65 | loss 1.9535 | ppl   7.0530\n",
      "| epoch  58 |  3000/ 3125 batches | lr 0.0000 | ms/batch 32.06 | loss 1.8540 | ppl   6.3855\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time: 99.46s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  59 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.14 | loss 1.8807 | ppl   6.5578\n",
      "| epoch  59 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8767 | ppl   6.5319\n",
      "| epoch  59 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.39 | loss 1.8920 | ppl   6.6327\n",
      "| epoch  59 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.9172 | ppl   6.8022\n",
      "| epoch  59 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.06 | loss 1.8980 | ppl   6.6728\n",
      "| epoch  59 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.9059 | ppl   6.7253\n",
      "| epoch  59 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8660 | ppl   6.4625\n",
      "| epoch  59 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.9153 | ppl   6.7887\n",
      "| epoch  59 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8970 | ppl   6.6661\n",
      "| epoch  59 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.59 | loss 1.8850 | ppl   6.5863\n",
      "| epoch  59 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8846 | ppl   6.5836\n",
      "| epoch  59 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.8917 | ppl   6.6307\n",
      "| epoch  59 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.65 | loss 1.8433 | ppl   6.3171\n",
      "| epoch  59 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.9549 | ppl   7.0633\n",
      "| epoch  59 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.8540 | ppl   6.3851\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time: 99.53s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  60 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8801 | ppl   6.5544\n",
      "| epoch  60 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.03 | loss 1.8757 | ppl   6.5253\n",
      "| epoch  60 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.31 | loss 1.8923 | ppl   6.6343\n",
      "| epoch  60 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.63 | loss 1.9171 | ppl   6.8011\n",
      "| epoch  60 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.8973 | ppl   6.6679\n",
      "| epoch  60 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.9048 | ppl   6.7181\n",
      "| epoch  60 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.8655 | ppl   6.4594\n",
      "| epoch  60 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.58 | loss 1.9154 | ppl   6.7899\n",
      "| epoch  60 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.8962 | ppl   6.6603\n",
      "| epoch  60 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8835 | ppl   6.5765\n",
      "| epoch  60 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8837 | ppl   6.5777\n",
      "| epoch  60 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.8900 | ppl   6.6194\n",
      "| epoch  60 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8446 | ppl   6.3253\n",
      "| epoch  60 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.9555 | ppl   7.0672\n",
      "| epoch  60 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.59 | loss 1.8535 | ppl   6.3824\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time: 99.31s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  61 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.24 | loss 1.8807 | ppl   6.5581\n",
      "| epoch  61 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.58 | loss 1.8756 | ppl   6.5245\n",
      "| epoch  61 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.61 | loss 1.8902 | ppl   6.6209\n",
      "| epoch  61 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.9175 | ppl   6.8037\n",
      "| epoch  61 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.8964 | ppl   6.6622\n",
      "| epoch  61 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.53 | loss 1.9055 | ppl   6.7225\n",
      "| epoch  61 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.8660 | ppl   6.4626\n",
      "| epoch  61 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.97 | loss 1.9155 | ppl   6.7904\n",
      "| epoch  61 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.8983 | ppl   6.6746\n",
      "| epoch  61 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8849 | ppl   6.5858\n",
      "| epoch  61 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.8824 | ppl   6.5694\n",
      "| epoch  61 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8903 | ppl   6.6211\n",
      "| epoch  61 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.56 | loss 1.8435 | ppl   6.3186\n",
      "| epoch  61 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.65 | loss 1.9544 | ppl   7.0595\n",
      "| epoch  61 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8517 | ppl   6.3709\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time: 99.15s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  62 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.8788 | ppl   6.5453\n",
      "| epoch  62 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.8756 | ppl   6.5245\n",
      "| epoch  62 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.8942 | ppl   6.6472\n",
      "| epoch  62 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.9161 | ppl   6.7944\n",
      "| epoch  62 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8970 | ppl   6.6660\n",
      "| epoch  62 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.9048 | ppl   6.7181\n",
      "| epoch  62 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.25 | loss 1.8660 | ppl   6.4624\n",
      "| epoch  62 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.97 | loss 1.9143 | ppl   6.7824\n",
      "| epoch  62 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.8972 | ppl   6.6674\n",
      "| epoch  62 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8832 | ppl   6.5743\n",
      "| epoch  62 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.95 | loss 1.8856 | ppl   6.5903\n",
      "| epoch  62 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.03 | loss 1.8910 | ppl   6.6261\n",
      "| epoch  62 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.8436 | ppl   6.3194\n",
      "| epoch  62 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.9543 | ppl   7.0590\n",
      "| epoch  62 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.8518 | ppl   6.3711\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time: 99.59s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  63 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8800 | ppl   6.5536\n",
      "| epoch  63 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.8766 | ppl   6.5310\n",
      "| epoch  63 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8917 | ppl   6.6309\n",
      "| epoch  63 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.40 | loss 1.9157 | ppl   6.7919\n",
      "| epoch  63 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.59 | loss 1.8965 | ppl   6.6627\n",
      "| epoch  63 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.9032 | ppl   6.7071\n",
      "| epoch  63 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.95 | loss 1.8672 | ppl   6.4701\n",
      "| epoch  63 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.06 | loss 1.9146 | ppl   6.7843\n",
      "| epoch  63 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.64 | loss 1.8985 | ppl   6.6757\n",
      "| epoch  63 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.22 | loss 1.8824 | ppl   6.5691\n",
      "| epoch  63 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8857 | ppl   6.5910\n",
      "| epoch  63 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.8897 | ppl   6.6175\n",
      "| epoch  63 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8437 | ppl   6.3201\n",
      "| epoch  63 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.9539 | ppl   7.0558\n",
      "| epoch  63 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.8540 | ppl   6.3853\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time: 99.32s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  64 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.8798 | ppl   6.5521\n",
      "| epoch  64 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8764 | ppl   6.5298\n",
      "| epoch  64 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.06 | loss 1.8915 | ppl   6.6294\n",
      "| epoch  64 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.52 | loss 1.9163 | ppl   6.7959\n",
      "| epoch  64 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8970 | ppl   6.6660\n",
      "| epoch  64 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.9063 | ppl   6.7283\n",
      "| epoch  64 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8654 | ppl   6.4588\n",
      "| epoch  64 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.9154 | ppl   6.7894\n",
      "| epoch  64 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8980 | ppl   6.6723\n",
      "| epoch  64 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.11 | loss 1.8844 | ppl   6.5826\n",
      "| epoch  64 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.19 | loss 1.8847 | ppl   6.5844\n",
      "| epoch  64 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.8894 | ppl   6.6153\n",
      "| epoch  64 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8455 | ppl   6.3311\n",
      "| epoch  64 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.9562 | ppl   7.0722\n",
      "| epoch  64 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8532 | ppl   6.3803\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time: 99.47s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  65 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8796 | ppl   6.5506\n",
      "| epoch  65 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8769 | ppl   6.5335\n",
      "| epoch  65 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.8911 | ppl   6.6267\n",
      "| epoch  65 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.9165 | ppl   6.7970\n",
      "| epoch  65 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.8982 | ppl   6.6738\n",
      "| epoch  65 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.9059 | ppl   6.7256\n",
      "| epoch  65 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.8670 | ppl   6.4688\n",
      "| epoch  65 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.53 | loss 1.9133 | ppl   6.7756\n",
      "| epoch  65 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8994 | ppl   6.6818\n",
      "| epoch  65 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.8844 | ppl   6.5822\n",
      "| epoch  65 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.8839 | ppl   6.5793\n",
      "| epoch  65 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.8915 | ppl   6.6295\n",
      "| epoch  65 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8440 | ppl   6.3220\n",
      "| epoch  65 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.9558 | ppl   7.0698\n",
      "| epoch  65 |  3000/ 3125 batches | lr 0.0000 | ms/batch 32.17 | loss 1.8534 | ppl   6.3813\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time: 99.44s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  66 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8801 | ppl   6.5541\n",
      "| epoch  66 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8766 | ppl   6.5311\n",
      "| epoch  66 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8924 | ppl   6.6354\n",
      "| epoch  66 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.18 | loss 1.9156 | ppl   6.7911\n",
      "| epoch  66 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.8967 | ppl   6.6641\n",
      "| epoch  66 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.11 | loss 1.9049 | ppl   6.7189\n",
      "| epoch  66 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8655 | ppl   6.4591\n",
      "| epoch  66 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.98 | loss 1.9162 | ppl   6.7950\n",
      "| epoch  66 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.97 | loss 1.8976 | ppl   6.6698\n",
      "| epoch  66 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.8843 | ppl   6.5820\n",
      "| epoch  66 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8837 | ppl   6.5778\n",
      "| epoch  66 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.33 | loss 1.8884 | ppl   6.6088\n",
      "| epoch  66 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.20 | loss 1.8438 | ppl   6.3206\n",
      "| epoch  66 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.50 | loss 1.9551 | ppl   7.0647\n",
      "| epoch  66 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.8527 | ppl   6.3773\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time: 99.66s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  67 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8807 | ppl   6.5583\n",
      "| epoch  67 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.37 | loss 1.8776 | ppl   6.5380\n",
      "| epoch  67 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.99 | loss 1.8925 | ppl   6.6358\n",
      "| epoch  67 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.9169 | ppl   6.7997\n",
      "| epoch  67 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.64 | loss 1.8975 | ppl   6.6694\n",
      "| epoch  67 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.58 | loss 1.9056 | ppl   6.7231\n",
      "| epoch  67 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.8666 | ppl   6.4660\n",
      "| epoch  67 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.9136 | ppl   6.7776\n",
      "| epoch  67 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.11 | loss 1.8990 | ppl   6.6793\n",
      "| epoch  67 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.8829 | ppl   6.5727\n",
      "| epoch  67 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8850 | ppl   6.5865\n",
      "| epoch  67 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8901 | ppl   6.6203\n",
      "| epoch  67 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.8445 | ppl   6.3248\n",
      "| epoch  67 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.9555 | ppl   7.0678\n",
      "| epoch  67 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.97 | loss 1.8527 | ppl   6.3770\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time: 99.51s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  68 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8803 | ppl   6.5555\n",
      "| epoch  68 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8755 | ppl   6.5240\n",
      "| epoch  68 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8909 | ppl   6.6254\n",
      "| epoch  68 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.21 | loss 1.9160 | ppl   6.7937\n",
      "| epoch  68 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8972 | ppl   6.6669\n",
      "| epoch  68 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.9046 | ppl   6.7170\n",
      "| epoch  68 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.63 | loss 1.8666 | ppl   6.4663\n",
      "| epoch  68 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.52 | loss 1.9155 | ppl   6.7900\n",
      "| epoch  68 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.93 | loss 1.8990 | ppl   6.6790\n",
      "| epoch  68 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8829 | ppl   6.5722\n",
      "| epoch  68 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.8851 | ppl   6.5870\n",
      "| epoch  68 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8894 | ppl   6.6157\n",
      "| epoch  68 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.8437 | ppl   6.3198\n",
      "| epoch  68 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.19 | loss 1.9550 | ppl   7.0641\n",
      "| epoch  68 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.8528 | ppl   6.3777\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time: 99.45s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  69 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.8803 | ppl   6.5556\n",
      "| epoch  69 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.8764 | ppl   6.5302\n",
      "| epoch  69 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.79 | loss 1.8918 | ppl   6.6315\n",
      "| epoch  69 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.9158 | ppl   6.7925\n",
      "| epoch  69 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.8973 | ppl   6.6678\n",
      "| epoch  69 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.9035 | ppl   6.7094\n",
      "| epoch  69 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8665 | ppl   6.4653\n",
      "| epoch  69 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.53 | loss 1.9143 | ppl   6.7824\n",
      "| epoch  69 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.8978 | ppl   6.6712\n",
      "| epoch  69 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.8848 | ppl   6.5850\n",
      "| epoch  69 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.8839 | ppl   6.5793\n",
      "| epoch  69 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.65 | loss 1.8905 | ppl   6.6229\n",
      "| epoch  69 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.34 | loss 1.8442 | ppl   6.3233\n",
      "| epoch  69 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.9560 | ppl   7.0709\n",
      "| epoch  69 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.60 | loss 1.8539 | ppl   6.3846\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time: 99.34s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  70 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8795 | ppl   6.5500\n",
      "| epoch  70 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8771 | ppl   6.5348\n",
      "| epoch  70 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.8935 | ppl   6.6427\n",
      "| epoch  70 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.9157 | ppl   6.7918\n",
      "| epoch  70 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.8965 | ppl   6.6628\n",
      "| epoch  70 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.53 | loss 1.9037 | ppl   6.7107\n",
      "| epoch  70 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.12 | loss 1.8667 | ppl   6.4671\n",
      "| epoch  70 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.9155 | ppl   6.7903\n",
      "| epoch  70 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.8977 | ppl   6.6702\n",
      "| epoch  70 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8834 | ppl   6.5759\n",
      "| epoch  70 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.98 | loss 1.8848 | ppl   6.5851\n",
      "| epoch  70 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.54 | loss 1.8902 | ppl   6.6207\n",
      "| epoch  70 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8436 | ppl   6.3191\n",
      "| epoch  70 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.9553 | ppl   7.0662\n",
      "| epoch  70 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8528 | ppl   6.3777\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time: 99.31s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  71 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.8807 | ppl   6.5580\n",
      "| epoch  71 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.8754 | ppl   6.5233\n",
      "| epoch  71 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.8902 | ppl   6.6205\n",
      "| epoch  71 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.9156 | ppl   6.7911\n",
      "| epoch  71 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.8975 | ppl   6.6695\n",
      "| epoch  71 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.9036 | ppl   6.7101\n",
      "| epoch  71 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.47 | loss 1.8675 | ppl   6.4722\n",
      "| epoch  71 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.50 | loss 1.9154 | ppl   6.7895\n",
      "| epoch  71 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.11 | loss 1.8984 | ppl   6.6755\n",
      "| epoch  71 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8851 | ppl   6.5867\n",
      "| epoch  71 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8853 | ppl   6.5884\n",
      "| epoch  71 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.8915 | ppl   6.6290\n",
      "| epoch  71 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.8434 | ppl   6.3179\n",
      "| epoch  71 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.9544 | ppl   7.0598\n",
      "| epoch  71 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.63 | loss 1.8518 | ppl   6.3711\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time: 99.42s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  72 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8816 | ppl   6.5638\n",
      "| epoch  72 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.63 | loss 1.8758 | ppl   6.5262\n",
      "| epoch  72 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8923 | ppl   6.6348\n",
      "| epoch  72 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.9169 | ppl   6.8000\n",
      "| epoch  72 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.8961 | ppl   6.6597\n",
      "| epoch  72 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.9046 | ppl   6.7169\n",
      "| epoch  72 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.55 | loss 1.8661 | ppl   6.4630\n",
      "| epoch  72 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.9134 | ppl   6.7764\n",
      "| epoch  72 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8979 | ppl   6.6720\n",
      "| epoch  72 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.23 | loss 1.8831 | ppl   6.5738\n",
      "| epoch  72 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.16 | loss 1.8849 | ppl   6.5860\n",
      "| epoch  72 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.30 | loss 1.8914 | ppl   6.6285\n",
      "| epoch  72 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.22 | loss 1.8434 | ppl   6.3181\n",
      "| epoch  72 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.9555 | ppl   7.0673\n",
      "| epoch  72 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8535 | ppl   6.3824\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time: 99.70s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  73 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.11 | loss 1.8799 | ppl   6.5528\n",
      "| epoch  73 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8772 | ppl   6.5351\n",
      "| epoch  73 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8926 | ppl   6.6369\n",
      "| epoch  73 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.9157 | ppl   6.7916\n",
      "| epoch  73 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.8974 | ppl   6.6685\n",
      "| epoch  73 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.9040 | ppl   6.7130\n",
      "| epoch  73 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.8651 | ppl   6.4565\n",
      "| epoch  73 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.52 | loss 1.9159 | ppl   6.7928\n",
      "| epoch  73 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8968 | ppl   6.6647\n",
      "| epoch  73 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.93 | loss 1.8827 | ppl   6.5710\n",
      "| epoch  73 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.8844 | ppl   6.5825\n",
      "| epoch  73 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8904 | ppl   6.6218\n",
      "| epoch  73 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.8429 | ppl   6.3150\n",
      "| epoch  73 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.9554 | ppl   7.0670\n",
      "| epoch  73 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.8527 | ppl   6.3773\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time: 99.36s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  74 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.16 | loss 1.8794 | ppl   6.5496\n",
      "| epoch  74 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.41 | loss 1.8763 | ppl   6.5294\n",
      "| epoch  74 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.8933 | ppl   6.6414\n",
      "| epoch  74 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.9177 | ppl   6.8056\n",
      "| epoch  74 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8962 | ppl   6.6605\n",
      "| epoch  74 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.9041 | ppl   6.7133\n",
      "| epoch  74 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8659 | ppl   6.4615\n",
      "| epoch  74 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.9149 | ppl   6.7865\n",
      "| epoch  74 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8986 | ppl   6.6764\n",
      "| epoch  74 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.8834 | ppl   6.5756\n",
      "| epoch  74 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8847 | ppl   6.5841\n",
      "| epoch  74 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.8897 | ppl   6.6172\n",
      "| epoch  74 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.51 | loss 1.8440 | ppl   6.3220\n",
      "| epoch  74 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.9551 | ppl   7.0650\n",
      "| epoch  74 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.8530 | ppl   6.3789\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time: 99.37s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  75 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8793 | ppl   6.5486\n",
      "| epoch  75 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.8769 | ppl   6.5330\n",
      "| epoch  75 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.61 | loss 1.8910 | ppl   6.6263\n",
      "| epoch  75 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.9163 | ppl   6.7959\n",
      "| epoch  75 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.8971 | ppl   6.6663\n",
      "| epoch  75 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.9055 | ppl   6.7230\n",
      "| epoch  75 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8670 | ppl   6.4687\n",
      "| epoch  75 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.9148 | ppl   6.7859\n",
      "| epoch  75 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8966 | ppl   6.6632\n",
      "| epoch  75 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8827 | ppl   6.5712\n",
      "| epoch  75 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8839 | ppl   6.5792\n",
      "| epoch  75 |  2400/ 3125 batches | lr 0.0000 | ms/batch 33.27 | loss 1.8910 | ppl   6.6262\n",
      "| epoch  75 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.14 | loss 1.8446 | ppl   6.3253\n",
      "| epoch  75 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.11 | loss 1.9559 | ppl   7.0705\n",
      "| epoch  75 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.8522 | ppl   6.3739\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time: 99.90s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  76 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8797 | ppl   6.5516\n",
      "| epoch  76 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.08 | loss 1.8755 | ppl   6.5242\n",
      "| epoch  76 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.26 | loss 1.8914 | ppl   6.6286\n",
      "| epoch  76 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.63 | loss 1.9168 | ppl   6.7991\n",
      "| epoch  76 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.60 | loss 1.8963 | ppl   6.6615\n",
      "| epoch  76 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.95 | loss 1.9049 | ppl   6.7188\n",
      "| epoch  76 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.79 | loss 1.8661 | ppl   6.4630\n",
      "| epoch  76 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.44 | loss 1.9142 | ppl   6.7815\n",
      "| epoch  76 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8981 | ppl   6.6733\n",
      "| epoch  76 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8831 | ppl   6.5737\n",
      "| epoch  76 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.13 | loss 1.8831 | ppl   6.5737\n",
      "| epoch  76 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.61 | loss 1.8924 | ppl   6.6351\n",
      "| epoch  76 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.08 | loss 1.8451 | ppl   6.3285\n",
      "| epoch  76 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.9552 | ppl   7.0655\n",
      "| epoch  76 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.75 | loss 1.8520 | ppl   6.3726\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time: 99.40s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  77 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.8800 | ppl   6.5532\n",
      "| epoch  77 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.8758 | ppl   6.5259\n",
      "| epoch  77 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.8919 | ppl   6.6322\n",
      "| epoch  77 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.08 | loss 1.9162 | ppl   6.7949\n",
      "| epoch  77 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.8990 | ppl   6.6791\n",
      "| epoch  77 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.60 | loss 1.9048 | ppl   6.7181\n",
      "| epoch  77 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.8652 | ppl   6.4570\n",
      "| epoch  77 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.9156 | ppl   6.7909\n",
      "| epoch  77 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8971 | ppl   6.6668\n",
      "| epoch  77 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.56 | loss 1.8833 | ppl   6.5749\n",
      "| epoch  77 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.8845 | ppl   6.5832\n",
      "| epoch  77 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.32 | loss 1.8908 | ppl   6.6246\n",
      "| epoch  77 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8442 | ppl   6.3229\n",
      "| epoch  77 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.9551 | ppl   7.0645\n",
      "| epoch  77 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8526 | ppl   6.3764\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time: 99.44s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  78 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.12 | loss 1.8806 | ppl   6.5573\n",
      "| epoch  78 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8754 | ppl   6.5232\n",
      "| epoch  78 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.8919 | ppl   6.6320\n",
      "| epoch  78 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.9165 | ppl   6.7972\n",
      "| epoch  78 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8968 | ppl   6.6648\n",
      "| epoch  78 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.9039 | ppl   6.7117\n",
      "| epoch  78 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.63 | loss 1.8666 | ppl   6.4663\n",
      "| epoch  78 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.9152 | ppl   6.7884\n",
      "| epoch  78 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.52 | loss 1.8978 | ppl   6.6711\n",
      "| epoch  78 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.97 | loss 1.8831 | ppl   6.5741\n",
      "| epoch  78 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.8847 | ppl   6.5845\n",
      "| epoch  78 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8894 | ppl   6.6151\n",
      "| epoch  78 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.98 | loss 1.8426 | ppl   6.3130\n",
      "| epoch  78 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.9559 | ppl   7.0700\n",
      "| epoch  78 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8527 | ppl   6.3771\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time: 99.47s | valid loss  2.85 | valid ppl    17.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  79 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.54 | loss 1.8812 | ppl   6.5616\n",
      "| epoch  79 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8756 | ppl   6.5247\n",
      "| epoch  79 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8922 | ppl   6.6338\n",
      "| epoch  79 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.9169 | ppl   6.7997\n",
      "| epoch  79 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.8957 | ppl   6.6571\n",
      "| epoch  79 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.9026 | ppl   6.7030\n",
      "| epoch  79 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.8671 | ppl   6.4697\n",
      "| epoch  79 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.9130 | ppl   6.7733\n",
      "| epoch  79 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.56 | loss 1.8978 | ppl   6.6713\n",
      "| epoch  79 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.59 | loss 1.8823 | ppl   6.5687\n",
      "| epoch  79 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.8828 | ppl   6.5719\n",
      "| epoch  79 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8905 | ppl   6.6225\n",
      "| epoch  79 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8431 | ppl   6.3160\n",
      "| epoch  79 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.20 | loss 1.9531 | ppl   7.0506\n",
      "| epoch  79 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.8538 | ppl   6.3842\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time: 99.16s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  80 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8809 | ppl   6.5596\n",
      "| epoch  80 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8761 | ppl   6.5277\n",
      "| epoch  80 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8924 | ppl   6.6350\n",
      "| epoch  80 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.53 | loss 1.9158 | ppl   6.7925\n",
      "| epoch  80 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.13 | loss 1.8967 | ppl   6.6640\n",
      "| epoch  80 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.9052 | ppl   6.7206\n",
      "| epoch  80 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.61 | loss 1.8675 | ppl   6.4724\n",
      "| epoch  80 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.9143 | ppl   6.7823\n",
      "| epoch  80 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.55 | loss 1.8964 | ppl   6.6617\n",
      "| epoch  80 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.8833 | ppl   6.5749\n",
      "| epoch  80 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.8856 | ppl   6.5903\n",
      "| epoch  80 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.8914 | ppl   6.6286\n",
      "| epoch  80 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8460 | ppl   6.3347\n",
      "| epoch  80 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.52 | loss 1.9551 | ppl   7.0649\n",
      "| epoch  80 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8544 | ppl   6.3877\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time: 99.46s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  81 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.26 | loss 1.8804 | ppl   6.5564\n",
      "| epoch  81 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8771 | ppl   6.5347\n",
      "| epoch  81 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8912 | ppl   6.6271\n",
      "| epoch  81 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.11 | loss 1.9168 | ppl   6.7992\n",
      "| epoch  81 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8967 | ppl   6.6639\n",
      "| epoch  81 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.43 | loss 1.9042 | ppl   6.7139\n",
      "| epoch  81 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8654 | ppl   6.4586\n",
      "| epoch  81 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.9160 | ppl   6.7936\n",
      "| epoch  81 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8962 | ppl   6.6607\n",
      "| epoch  81 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.8839 | ppl   6.5790\n",
      "| epoch  81 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.8838 | ppl   6.5784\n",
      "| epoch  81 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.48 | loss 1.8895 | ppl   6.6161\n",
      "| epoch  81 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.8432 | ppl   6.3168\n",
      "| epoch  81 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.65 | loss 1.9551 | ppl   7.0648\n",
      "| epoch  81 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8532 | ppl   6.3800\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time: 99.50s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  82 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8799 | ppl   6.5529\n",
      "| epoch  82 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8760 | ppl   6.5271\n",
      "| epoch  82 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.8923 | ppl   6.6344\n",
      "| epoch  82 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.32 | loss 1.9182 | ppl   6.8085\n",
      "| epoch  82 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8962 | ppl   6.6607\n",
      "| epoch  82 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.9023 | ppl   6.7014\n",
      "| epoch  82 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.98 | loss 1.8666 | ppl   6.4662\n",
      "| epoch  82 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.99 | loss 1.9147 | ppl   6.7846\n",
      "| epoch  82 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.52 | loss 1.8967 | ppl   6.6636\n",
      "| epoch  82 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8835 | ppl   6.5766\n",
      "| epoch  82 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.97 | loss 1.8850 | ppl   6.5865\n",
      "| epoch  82 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.30 | loss 1.8897 | ppl   6.6176\n",
      "| epoch  82 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.99 | loss 1.8438 | ppl   6.3203\n",
      "| epoch  82 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.64 | loss 1.9547 | ppl   7.0620\n",
      "| epoch  82 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.50 | loss 1.8532 | ppl   6.3803\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time: 99.43s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  83 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.53 | loss 1.8799 | ppl   6.5530\n",
      "| epoch  83 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.24 | loss 1.8768 | ppl   6.5327\n",
      "| epoch  83 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8930 | ppl   6.6392\n",
      "| epoch  83 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.9159 | ppl   6.7927\n",
      "| epoch  83 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.48 | loss 1.8970 | ppl   6.6662\n",
      "| epoch  83 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.34 | loss 1.9050 | ppl   6.7193\n",
      "| epoch  83 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.8664 | ppl   6.4648\n",
      "| epoch  83 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.9161 | ppl   6.7946\n",
      "| epoch  83 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.8971 | ppl   6.6668\n",
      "| epoch  83 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.8836 | ppl   6.5769\n",
      "| epoch  83 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.8844 | ppl   6.5825\n",
      "| epoch  83 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.8905 | ppl   6.6225\n",
      "| epoch  83 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.17 | loss 1.8432 | ppl   6.3168\n",
      "| epoch  83 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.9552 | ppl   7.0653\n",
      "| epoch  83 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8536 | ppl   6.3829\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time: 99.59s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  84 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8804 | ppl   6.5562\n",
      "| epoch  84 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.8756 | ppl   6.5245\n",
      "| epoch  84 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8926 | ppl   6.6368\n",
      "| epoch  84 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.9177 | ppl   6.8054\n",
      "| epoch  84 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.49 | loss 1.8966 | ppl   6.6630\n",
      "| epoch  84 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.9027 | ppl   6.7037\n",
      "| epoch  84 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8671 | ppl   6.4698\n",
      "| epoch  84 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.9144 | ppl   6.7830\n",
      "| epoch  84 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.06 | loss 1.8982 | ppl   6.6740\n",
      "| epoch  84 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8839 | ppl   6.5788\n",
      "| epoch  84 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8834 | ppl   6.5755\n",
      "| epoch  84 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8905 | ppl   6.6226\n",
      "| epoch  84 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.56 | loss 1.8426 | ppl   6.3128\n",
      "| epoch  84 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.9530 | ppl   7.0495\n",
      "| epoch  84 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8528 | ppl   6.3774\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time: 99.53s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  85 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8808 | ppl   6.5588\n",
      "| epoch  85 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8748 | ppl   6.5194\n",
      "| epoch  85 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.8906 | ppl   6.6235\n",
      "| epoch  85 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.21 | loss 1.9155 | ppl   6.7903\n",
      "| epoch  85 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8963 | ppl   6.6610\n",
      "| epoch  85 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.9056 | ppl   6.7237\n",
      "| epoch  85 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.8661 | ppl   6.4628\n",
      "| epoch  85 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.9144 | ppl   6.7831\n",
      "| epoch  85 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8978 | ppl   6.6713\n",
      "| epoch  85 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.99 | loss 1.8823 | ppl   6.5688\n",
      "| epoch  85 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.59 | loss 1.8846 | ppl   6.5836\n",
      "| epoch  85 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.8901 | ppl   6.6199\n",
      "| epoch  85 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.15 | loss 1.8431 | ppl   6.3163\n",
      "| epoch  85 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.58 | loss 1.9545 | ppl   7.0607\n",
      "| epoch  85 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.93 | loss 1.8520 | ppl   6.3723\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time: 99.51s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  86 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.27 | loss 1.8798 | ppl   6.5524\n",
      "| epoch  86 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.06 | loss 1.8759 | ppl   6.5266\n",
      "| epoch  86 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8924 | ppl   6.6353\n",
      "| epoch  86 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.9176 | ppl   6.8047\n",
      "| epoch  86 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.42 | loss 1.8956 | ppl   6.6566\n",
      "| epoch  86 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.9048 | ppl   6.7181\n",
      "| epoch  86 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.8670 | ppl   6.4691\n",
      "| epoch  86 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.9165 | ppl   6.7971\n",
      "| epoch  86 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.93 | loss 1.8983 | ppl   6.6747\n",
      "| epoch  86 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.35 | loss 1.8830 | ppl   6.5733\n",
      "| epoch  86 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.8852 | ppl   6.5875\n",
      "| epoch  86 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.98 | loss 1.8906 | ppl   6.6236\n",
      "| epoch  86 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8440 | ppl   6.3218\n",
      "| epoch  86 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.9548 | ppl   7.0622\n",
      "| epoch  86 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8509 | ppl   6.3653\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time: 99.39s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  87 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.19 | loss 1.8794 | ppl   6.5498\n",
      "| epoch  87 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8772 | ppl   6.5355\n",
      "| epoch  87 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.58 | loss 1.8907 | ppl   6.6237\n",
      "| epoch  87 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.9169 | ppl   6.7997\n",
      "| epoch  87 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.8981 | ppl   6.6730\n",
      "| epoch  87 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.65 | loss 1.9054 | ppl   6.7218\n",
      "| epoch  87 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8657 | ppl   6.4603\n",
      "| epoch  87 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.03 | loss 1.9150 | ppl   6.7872\n",
      "| epoch  87 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8979 | ppl   6.6715\n",
      "| epoch  87 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8845 | ppl   6.5829\n",
      "| epoch  87 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.8846 | ppl   6.5836\n",
      "| epoch  87 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.45 | loss 1.8912 | ppl   6.6274\n",
      "| epoch  87 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.8438 | ppl   6.3206\n",
      "| epoch  87 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.9551 | ppl   7.0643\n",
      "| epoch  87 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8524 | ppl   6.3753\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time: 99.48s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  88 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.8808 | ppl   6.5587\n",
      "| epoch  88 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8758 | ppl   6.5262\n",
      "| epoch  88 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.60 | loss 1.8916 | ppl   6.6299\n",
      "| epoch  88 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.9164 | ppl   6.7968\n",
      "| epoch  88 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.98 | loss 1.8977 | ppl   6.6703\n",
      "| epoch  88 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.9036 | ppl   6.7103\n",
      "| epoch  88 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.61 | loss 1.8682 | ppl   6.4766\n",
      "| epoch  88 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.9147 | ppl   6.7849\n",
      "| epoch  88 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.95 | loss 1.8982 | ppl   6.6736\n",
      "| epoch  88 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8854 | ppl   6.5891\n",
      "| epoch  88 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8863 | ppl   6.5948\n",
      "| epoch  88 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.18 | loss 1.8923 | ppl   6.6343\n",
      "| epoch  88 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.22 | loss 1.8433 | ppl   6.3171\n",
      "| epoch  88 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.9549 | ppl   7.0633\n",
      "| epoch  88 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.44 | loss 1.8530 | ppl   6.3789\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time: 99.49s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  89 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8791 | ppl   6.5478\n",
      "| epoch  89 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8764 | ppl   6.5301\n",
      "| epoch  89 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.8923 | ppl   6.6349\n",
      "| epoch  89 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.95 | loss 1.9162 | ppl   6.7950\n",
      "| epoch  89 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.61 | loss 1.8966 | ppl   6.6632\n",
      "| epoch  89 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.9056 | ppl   6.7233\n",
      "| epoch  89 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.8663 | ppl   6.4645\n",
      "| epoch  89 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.93 | loss 1.9144 | ppl   6.7832\n",
      "| epoch  89 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.8986 | ppl   6.6764\n",
      "| epoch  89 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.99 | loss 1.8832 | ppl   6.5743\n",
      "| epoch  89 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8849 | ppl   6.5857\n",
      "| epoch  89 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8901 | ppl   6.6202\n",
      "| epoch  89 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8422 | ppl   6.3105\n",
      "| epoch  89 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.60 | loss 1.9554 | ppl   7.0666\n",
      "| epoch  89 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.8526 | ppl   6.3766\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time: 99.44s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  90 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.22 | loss 1.8808 | ppl   6.5587\n",
      "| epoch  90 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.8763 | ppl   6.5295\n",
      "| epoch  90 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.8918 | ppl   6.6315\n",
      "| epoch  90 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.9176 | ppl   6.8043\n",
      "| epoch  90 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8959 | ppl   6.6586\n",
      "| epoch  90 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.9055 | ppl   6.7230\n",
      "| epoch  90 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.8669 | ppl   6.4680\n",
      "| epoch  90 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.48 | loss 1.9136 | ppl   6.7777\n",
      "| epoch  90 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.8981 | ppl   6.6733\n",
      "| epoch  90 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.8835 | ppl   6.5763\n",
      "| epoch  90 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.05 | loss 1.8844 | ppl   6.5822\n",
      "| epoch  90 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.8909 | ppl   6.6253\n",
      "| epoch  90 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8442 | ppl   6.3229\n",
      "| epoch  90 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.9561 | ppl   7.0719\n",
      "| epoch  90 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.63 | loss 1.8528 | ppl   6.3774\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time: 99.49s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  91 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.34 | loss 1.8795 | ppl   6.5505\n",
      "| epoch  91 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.60 | loss 1.8756 | ppl   6.5249\n",
      "| epoch  91 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.53 | loss 1.8915 | ppl   6.6292\n",
      "| epoch  91 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.9146 | ppl   6.7839\n",
      "| epoch  91 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8964 | ppl   6.6617\n",
      "| epoch  91 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.9055 | ppl   6.7226\n",
      "| epoch  91 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.34 | loss 1.8656 | ppl   6.4599\n",
      "| epoch  91 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.71 | loss 1.9151 | ppl   6.7875\n",
      "| epoch  91 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8974 | ppl   6.6685\n",
      "| epoch  91 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8837 | ppl   6.5779\n",
      "| epoch  91 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8850 | ppl   6.5861\n",
      "| epoch  91 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.84 | loss 1.8908 | ppl   6.6250\n",
      "| epoch  91 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8428 | ppl   6.3143\n",
      "| epoch  91 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.01 | loss 1.9548 | ppl   7.0626\n",
      "| epoch  91 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8524 | ppl   6.3751\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time: 99.62s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  92 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.97 | loss 1.8808 | ppl   6.5590\n",
      "| epoch  92 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8781 | ppl   6.5408\n",
      "| epoch  92 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8933 | ppl   6.6413\n",
      "| epoch  92 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.9164 | ppl   6.7967\n",
      "| epoch  92 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.74 | loss 1.8966 | ppl   6.6630\n",
      "| epoch  92 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.97 | loss 1.9047 | ppl   6.7173\n",
      "| epoch  92 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.07 | loss 1.8659 | ppl   6.4620\n",
      "| epoch  92 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.9147 | ppl   6.7850\n",
      "| epoch  92 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.8973 | ppl   6.6681\n",
      "| epoch  92 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8831 | ppl   6.5737\n",
      "| epoch  92 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.8845 | ppl   6.5828\n",
      "| epoch  92 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.62 | loss 1.8901 | ppl   6.6203\n",
      "| epoch  92 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8427 | ppl   6.3135\n",
      "| epoch  92 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.9540 | ppl   7.0570\n",
      "| epoch  92 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.44 | loss 1.8546 | ppl   6.3891\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time: 99.47s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  93 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8806 | ppl   6.5575\n",
      "| epoch  93 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.83 | loss 1.8770 | ppl   6.5338\n",
      "| epoch  93 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.79 | loss 1.8925 | ppl   6.6357\n",
      "| epoch  93 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.9158 | ppl   6.7922\n",
      "| epoch  93 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.8969 | ppl   6.6652\n",
      "| epoch  93 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.99 | loss 1.9064 | ppl   6.7290\n",
      "| epoch  93 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8665 | ppl   6.4659\n",
      "| epoch  93 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.65 | loss 1.9152 | ppl   6.7882\n",
      "| epoch  93 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.22 | loss 1.8975 | ppl   6.6692\n",
      "| epoch  93 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.08 | loss 1.8834 | ppl   6.5759\n",
      "| epoch  93 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.23 | loss 1.8856 | ppl   6.5902\n",
      "| epoch  93 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.8896 | ppl   6.6165\n",
      "| epoch  93 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.64 | loss 1.8426 | ppl   6.3129\n",
      "| epoch  93 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.65 | loss 1.9566 | ppl   7.0752\n",
      "| epoch  93 |  3000/ 3125 batches | lr 0.0000 | ms/batch 32.53 | loss 1.8512 | ppl   6.3673\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time: 100.15s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  94 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.14 | loss 1.8821 | ppl   6.5676\n",
      "| epoch  94 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.8754 | ppl   6.5237\n",
      "| epoch  94 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8920 | ppl   6.6326\n",
      "| epoch  94 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.16 | loss 1.9160 | ppl   6.7940\n",
      "| epoch  94 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.94 | loss 1.8953 | ppl   6.6545\n",
      "| epoch  94 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.10 | loss 1.9045 | ppl   6.7160\n",
      "| epoch  94 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.8673 | ppl   6.4709\n",
      "| epoch  94 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.82 | loss 1.9146 | ppl   6.7841\n",
      "| epoch  94 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8968 | ppl   6.6646\n",
      "| epoch  94 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.8817 | ppl   6.5649\n",
      "| epoch  94 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.89 | loss 1.8850 | ppl   6.5865\n",
      "| epoch  94 |  2400/ 3125 batches | lr 0.0000 | ms/batch 31.77 | loss 1.8905 | ppl   6.6225\n",
      "| epoch  94 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8436 | ppl   6.3192\n",
      "| epoch  94 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.32 | loss 1.9555 | ppl   7.0672\n",
      "| epoch  94 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.81 | loss 1.8532 | ppl   6.3799\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time: 99.68s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  95 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.98 | loss 1.8809 | ppl   6.5595\n",
      "| epoch  95 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.04 | loss 1.8757 | ppl   6.5253\n",
      "| epoch  95 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.8928 | ppl   6.6378\n",
      "| epoch  95 |   800/ 3125 batches | lr 0.0000 | ms/batch 33.58 | loss 1.9173 | ppl   6.8024\n",
      "| epoch  95 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.62 | loss 1.8964 | ppl   6.6617\n",
      "| epoch  95 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.72 | loss 1.9047 | ppl   6.7172\n",
      "| epoch  95 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8662 | ppl   6.4635\n",
      "| epoch  95 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.9144 | ppl   6.7831\n",
      "| epoch  95 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.14 | loss 1.8980 | ppl   6.6727\n",
      "| epoch  95 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.27 | loss 1.8839 | ppl   6.5789\n",
      "| epoch  95 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.17 | loss 1.8842 | ppl   6.5814\n",
      "| epoch  95 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.27 | loss 1.8895 | ppl   6.6161\n",
      "| epoch  95 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.8430 | ppl   6.3154\n",
      "| epoch  95 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.96 | loss 1.9547 | ppl   7.0621\n",
      "| epoch  95 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.51 | loss 1.8530 | ppl   6.3790\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time: 100.27s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  96 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.67 | loss 1.8790 | ppl   6.5469\n",
      "| epoch  96 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.86 | loss 1.8776 | ppl   6.5379\n",
      "| epoch  96 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.8920 | ppl   6.6328\n",
      "| epoch  96 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.44 | loss 1.9174 | ppl   6.8031\n",
      "| epoch  96 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.8986 | ppl   6.6764\n",
      "| epoch  96 |  1200/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.9053 | ppl   6.7214\n",
      "| epoch  96 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.87 | loss 1.8653 | ppl   6.4576\n",
      "| epoch  96 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.78 | loss 1.9144 | ppl   6.7828\n",
      "| epoch  96 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.8984 | ppl   6.6749\n",
      "| epoch  96 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.02 | loss 1.8847 | ppl   6.5841\n",
      "| epoch  96 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.61 | loss 1.8840 | ppl   6.5800\n",
      "| epoch  96 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.31 | loss 1.8901 | ppl   6.6202\n",
      "| epoch  96 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.76 | loss 1.8433 | ppl   6.3172\n",
      "| epoch  96 |  2800/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.9566 | ppl   7.0752\n",
      "| epoch  96 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8525 | ppl   6.3760\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time: 99.44s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  97 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8814 | ppl   6.5628\n",
      "| epoch  97 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.70 | loss 1.8764 | ppl   6.5297\n",
      "| epoch  97 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.8930 | ppl   6.6390\n",
      "| epoch  97 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.91 | loss 1.9158 | ppl   6.7927\n",
      "| epoch  97 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.28 | loss 1.8974 | ppl   6.6687\n",
      "| epoch  97 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.15 | loss 1.9034 | ppl   6.7085\n",
      "| epoch  97 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8668 | ppl   6.4673\n",
      "| epoch  97 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.9141 | ppl   6.7807\n",
      "| epoch  97 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.8987 | ppl   6.6770\n",
      "| epoch  97 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.46 | loss 1.8843 | ppl   6.5820\n",
      "| epoch  97 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.8841 | ppl   6.5805\n",
      "| epoch  97 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.17 | loss 1.8918 | ppl   6.6315\n",
      "| epoch  97 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.44 | loss 1.8425 | ppl   6.3125\n",
      "| epoch  97 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.9531 | ppl   7.0507\n",
      "| epoch  97 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.73 | loss 1.8532 | ppl   6.3803\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time: 99.32s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  98 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.23 | loss 1.8790 | ppl   6.5469\n",
      "| epoch  98 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.18 | loss 1.8767 | ppl   6.5321\n",
      "| epoch  98 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.03 | loss 1.8918 | ppl   6.6311\n",
      "| epoch  98 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.9174 | ppl   6.8031\n",
      "| epoch  98 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.68 | loss 1.8974 | ppl   6.6683\n",
      "| epoch  98 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.27 | loss 1.9054 | ppl   6.7221\n",
      "| epoch  98 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.66 | loss 1.8667 | ppl   6.4670\n",
      "| epoch  98 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.92 | loss 1.9133 | ppl   6.7757\n",
      "| epoch  98 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.00 | loss 1.8980 | ppl   6.6723\n",
      "| epoch  98 |  2000/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8835 | ppl   6.5766\n",
      "| epoch  98 |  2200/ 3125 batches | lr 0.0000 | ms/batch 31.44 | loss 1.8842 | ppl   6.5808\n",
      "| epoch  98 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.03 | loss 1.8900 | ppl   6.6196\n",
      "| epoch  98 |  2600/ 3125 batches | lr 0.0000 | ms/batch 31.53 | loss 1.8435 | ppl   6.3187\n",
      "| epoch  98 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.9549 | ppl   7.0629\n",
      "| epoch  98 |  3000/ 3125 batches | lr 0.0000 | ms/batch 31.79 | loss 1.8537 | ppl   6.3835\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time: 99.67s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  99 |   200/ 3125 batches | lr 0.0000 | ms/batch 31.65 | loss 1.8814 | ppl   6.5630\n",
      "| epoch  99 |   400/ 3125 batches | lr 0.0000 | ms/batch 31.61 | loss 1.8766 | ppl   6.5313\n",
      "| epoch  99 |   600/ 3125 batches | lr 0.0000 | ms/batch 31.88 | loss 1.8927 | ppl   6.6370\n",
      "| epoch  99 |   800/ 3125 batches | lr 0.0000 | ms/batch 31.80 | loss 1.9164 | ppl   6.7965\n",
      "| epoch  99 |  1000/ 3125 batches | lr 0.0000 | ms/batch 31.69 | loss 1.8957 | ppl   6.6574\n",
      "| epoch  99 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.09 | loss 1.9033 | ppl   6.7077\n",
      "| epoch  99 |  1400/ 3125 batches | lr 0.0000 | ms/batch 31.85 | loss 1.8660 | ppl   6.4626\n",
      "| epoch  99 |  1600/ 3125 batches | lr 0.0000 | ms/batch 31.90 | loss 1.9151 | ppl   6.7878\n",
      "| epoch  99 |  1800/ 3125 batches | lr 0.0000 | ms/batch 31.57 | loss 1.8974 | ppl   6.6683\n",
      "| epoch  99 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.13 | loss 1.8832 | ppl   6.5745\n",
      "| epoch  99 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.76 | loss 1.8846 | ppl   6.5837\n",
      "| epoch  99 |  2400/ 3125 batches | lr 0.0000 | ms/batch 33.30 | loss 1.8898 | ppl   6.6179\n",
      "| epoch  99 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.79 | loss 1.8443 | ppl   6.3236\n",
      "| epoch  99 |  2800/ 3125 batches | lr 0.0000 | ms/batch 31.53 | loss 1.9537 | ppl   7.0549\n",
      "| epoch  99 |  3000/ 3125 batches | lr 0.0000 | ms/batch 33.13 | loss 1.8516 | ppl   6.3699\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  99 | time: 100.53s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 100 |   200/ 3125 batches | lr 0.0000 | ms/batch 32.63 | loss 1.8799 | ppl   6.5527\n",
      "| epoch 100 |   400/ 3125 batches | lr 0.0000 | ms/batch 32.69 | loss 1.8767 | ppl   6.5322\n",
      "| epoch 100 |   600/ 3125 batches | lr 0.0000 | ms/batch 32.72 | loss 1.8923 | ppl   6.6347\n",
      "| epoch 100 |   800/ 3125 batches | lr 0.0000 | ms/batch 32.62 | loss 1.9164 | ppl   6.7968\n",
      "| epoch 100 |  1000/ 3125 batches | lr 0.0000 | ms/batch 32.78 | loss 1.8972 | ppl   6.6669\n",
      "| epoch 100 |  1200/ 3125 batches | lr 0.0000 | ms/batch 32.74 | loss 1.9047 | ppl   6.7177\n",
      "| epoch 100 |  1400/ 3125 batches | lr 0.0000 | ms/batch 32.39 | loss 1.8660 | ppl   6.4622\n",
      "| epoch 100 |  1600/ 3125 batches | lr 0.0000 | ms/batch 32.96 | loss 1.9143 | ppl   6.7821\n",
      "| epoch 100 |  1800/ 3125 batches | lr 0.0000 | ms/batch 32.36 | loss 1.8983 | ppl   6.6742\n",
      "| epoch 100 |  2000/ 3125 batches | lr 0.0000 | ms/batch 32.38 | loss 1.8828 | ppl   6.5716\n",
      "| epoch 100 |  2200/ 3125 batches | lr 0.0000 | ms/batch 32.34 | loss 1.8858 | ppl   6.5916\n",
      "| epoch 100 |  2400/ 3125 batches | lr 0.0000 | ms/batch 32.40 | loss 1.8900 | ppl   6.6192\n",
      "| epoch 100 |  2600/ 3125 batches | lr 0.0000 | ms/batch 32.81 | loss 1.8449 | ppl   6.3277\n",
      "| epoch 100 |  2800/ 3125 batches | lr 0.0000 | ms/batch 33.33 | loss 1.9550 | ppl   7.0638\n",
      "| epoch 100 |  3000/ 3125 batches | lr 0.0000 | ms/batch 32.86 | loss 1.8538 | ppl   6.3842\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time: 102.16s | valid loss  2.85 | valid ppl    17.35\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 100\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss = evaluate(model, val_data)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step(best_val_loss)\n",
    "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0b8fdc8c-af2f-4bc4-994d-57863eea0e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict,\"trans4rec.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955ca9d-01ef-4cf4-93fb-512d72f34ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluate(model, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1a3f0761-a838-4c23-9c29-3dd0e27ffe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = get_batch(train_data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "974fa341-60f5-4b14-a62e-8484c3a6a069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[37,  4,  2, 11,  1, 34, 10, 23, 49, 26, 11, 24,  1,  1, 38,  6, 46,  1,\n",
       "          2,  7, 47, 12,  4,  2, 28, 17,  2, 42,  8, 15,  1, 16],\n",
       "        [31,  0,  0,  5,  0,  6,  0,  0,  0,  0, 38,  0,  0,  0,  0, 39,  0,  4,\n",
       "          6,  5,  2,  0, 34, 16,  0,  4,  0,  0,  0, 47,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0, 28,  0,  0,  0,  0,  6,  0,  0,  0,  0,  0,  0,  6,\n",
       "         31,  0,  0,  0, 21, 21,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         37,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0, 25,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         40,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "20807db1-d536-427b-8db7-c00dc0dd90d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 32])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7577027a-f321-429f-80f5-fc8e162906b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4e8235a8-f9ee-4243-a891-db8943bb10a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.zeros(20).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d39212aa-c5a6-4522-bf2b-37b3459554ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "input[0] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9c77d51c-fcc8-4610-989a-daac67c80e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = input.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "248cc6ad-8aad-455f-8850-b28da0cad45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4e04b812-6e57-4d5b-92cb-ea44fc0c787d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20, 51])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "22edae43-f541-4c4c-a0aa-8ff11f6c3c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5e130b50-5696-407f-92a6-b222127c74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_flat = output.view(-1, ntokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "99086120-cf65-440c-8f73-50bea2716879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 51])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_flat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e67cb8a2-b386-45db-b464-310fecab7166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3, device='cuda:0')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(output_flat[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
